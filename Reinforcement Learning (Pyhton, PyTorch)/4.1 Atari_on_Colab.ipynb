{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKevL7MMqhfs"
      },
      "outputs": [],
      "source": [
        "##-----degraded-----##\n",
        "# !pip install -Iv gym==0.17.1\n",
        "# !apt-get install python-opengl -y\n",
        "# !apt install xvfb -y\n",
        "# !pip install gym[atari]\n",
        "# !pip install pyvirtualdisplay\n",
        "# !conda install piglet\n",
        "# !pip install pystan\n",
        "# !conda install swig\n",
        "# #!pip install box2d-py\n",
        "# !pip install box2d-py\n",
        "# !pip install gym[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBbKJBtWqwGk",
        "outputId": "3dfb3051-5565-4ab1-b0d7-ce089fc7a73a"
      },
      "outputs": [],
      "source": [
        "# Upload 'HC ROMS.zip' and 'ROMS.zip' online.\n",
        "!python -m atari_py.import_roms .\n",
        "import gym\n",
        "env = gym.make('PongNoFrameskip-v4')\n",
        "print(env.observation_space.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMMc0Hpaiagm"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import math, random\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd \n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "from collections import deque\n",
        "from common.old_atari_wrappers import wrap_pytorch, make_atari, wrap_deepmind\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpw85T4eieh8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def init_weights(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_in',nonlinearity='relu')\n",
        "        torch.nn.init.zeros_(m.bias)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_in', a=0.2, nonlinearity='leaky_relu')\n",
        "        torch.nn.init.zeros_(m.bias)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bzdR8gwif5W"
      },
      "outputs": [],
      "source": [
        "\n",
        "class QNetwork(nn.Module):    \n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(4, 32, 8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.features.apply(init_weights)\n",
        "\n",
        "        self.fc1 = nn.Linear(64*7*7, 256)\n",
        "        self.fc1.apply(init_weights)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "        self.fc2 = nn.Linear(256, num_actions)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, state):\n",
        "        state = torch.div(state, 255)\n",
        "        state = state.cuda()\n",
        "        \n",
        "        feats = self.features(state)\n",
        "        fc1 = self.fc1(feats.view(feats.size(0),-1))\n",
        "        leaky_relu = self.leaky_relu(fc1)\n",
        "\n",
        "        return self.fc2(leaky_relu).cuda()\n",
        "\n",
        "    def feature_size(self):\n",
        "        with torch.no_grad():\n",
        "            return self.features(torch.zeros(1, *self.input_shape)).view(1, -1).size(1)\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QlPZsByih-d"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LearningAgent: \n",
        "    def __init__(self, **kwargs):      \n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(\"Using {} for training the algorithm.\".format(self.device))        \n",
        "        self.env = kwargs.get('training_env',None)\n",
        "        self.gamma = kwargs.get('gamma', 0.99)\n",
        "        self.hard_update_interval = kwargs.get('target network update interval', 10000)\n",
        "        \n",
        "        self.update_step = 0\n",
        "        \n",
        "        # ---- initialize networks ----\n",
        "        self.q_net1 = QNetwork(env.observation_space.shape, env.action_space.n).to(self.device)\n",
        "        self.target_q_net1 = QNetwork(env.observation_space.shape, env.action_space.n).to(self.device)\n",
        "\n",
        "\n",
        "        # initialize optimizers using Adam optimizer.\n",
        "        self.q1_optimizer = optim.Adam(self.q_net1.parameters(), kwargs.get('learning rate', 1e-4))\n",
        "        # initialize the loss function (Huberloss) \n",
        "        self.criterion = nn.SmoothL1Loss(reduction='mean')\n",
        "        \n",
        "        self.replay_buffer = ReplayBuffer(kwargs.get('memory size',1000000), env.observation_space.shape)\n",
        "        \n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "        # implement epsilon-greedy, \n",
        "        state = torch.tensor(state)\n",
        "        if state.size(0) == 4:\n",
        "          state = state.unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          # Epsilon-Greedy action selection\n",
        "          if np.random.random() > self.epsilon: # Exploit\n",
        "            action = self.q_net1.forward(state)\n",
        "            act = torch.argmax(action).item()\n",
        "          else:  # Explore\n",
        "            act = env.action_space.sample()\n",
        "        return act\n",
        "\n",
        "\n",
        "    def test_act(self, state):\n",
        "        state = torch.tensor(state)\n",
        "        if state.size(0) == 4:\n",
        "          state = state.unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          action = self.q_net1.forward(state)\n",
        "          act = torch.argmax(action).item()\n",
        "        return act\n",
        "    \n",
        "   \n",
        "    def update(self, batch_size):       \n",
        "       # Very similar to previous DDQN, except for the loss definition and update manner of target network\n",
        "        self.q_net1.train()\n",
        "        \n",
        "        transitions = self.replay_buffer.sample(batch_size)        \n",
        "        states, actions, rewards, next_states, dones = transitions\n",
        "        states = torch.FloatTensor(states).to(self.device)\n",
        "        actions = torch.LongTensor(actions).to(self.device)\n",
        "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
        "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
        "        dones = torch.FloatTensor(dones).to(self.device)\n",
        "        \n",
        "        # Implement DDQN here, should be similar/same as DDQN in previous task.\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          #DDQN\n",
        "          act_idx = self.q_net1(next_states).argmax(1).unsqueeze(1)\n",
        "          next_state_act_vals = self.target_q_net1(next_states).gather(1, act_idx)\n",
        "          y_i = (1 - dones)*(next_state_act_vals.squeeze(1) * self.gamma) + rewards#DDQN\n",
        "\n",
        "        state_action_values = self.q_net1(states).gather(1, actions.unsqueeze(1)) #self.q_net1(states).gather(1, act_idx)\n",
        "\n",
        "\n",
        "        # q loss using self.criterion\n",
        "        q1_loss = self.criterion(state_action_values, y_i.detach().unsqueeze(1))       \n",
        "\n",
        "        # update q networks        \n",
        "        self.q1_optimizer.zero_grad()\n",
        "        q1_loss.backward()\n",
        "        self.q1_optimizer.step()\n",
        "\n",
        "        # --------Perform Hard update of target networks every self.hard_update_interval-----------     \n",
        "        if self.update_step % self.hard_update_interval == 0:    \n",
        "          for target_param, param in zip(self.target_q_net1.parameters(), self.q_net1.parameters()):\n",
        "            target_param.data.copy_(param.data)\n",
        "        \n",
        "        self.update_step += 1\n",
        "        \n",
        "        # just for monitoring Q loss, in case of wrong implementation, this could diverge to insane values.\n",
        "        if self.update_step % 1000 == 999:\n",
        "            print(\"Q loss: {}\".format(q1_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiLkcqjlikJN"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ReplayBuffer(object):\n",
        "    \n",
        "    def __init__(self, max_size, state_dim):\n",
        "        self.buffer = deque(maxlen=max_size)\n",
        "        self.state_dim = state_dim\n",
        "    \n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        experience = (state, action, reward, next_state, done)\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    \n",
        "    def sample(self, batch_size):\n",
        "\n",
        "        state_batch = np.empty([batch_size,self.state_dim[0], self.state_dim[1], self.state_dim[2]])\n",
        "        action_batch = np.empty([batch_size])\n",
        "        reward_batch = np.empty([batch_size])\n",
        "        next_state_batch = np.empty([batch_size,self.state_dim[0], self.state_dim[1], self.state_dim[2]])\n",
        "        done_batch = np.empty([batch_size])\n",
        "        # Take #batch_size samples from the replay buffer and write into different arrays.        \n",
        "        batch = random.sample(range(len(self)),batch_size)\n",
        "        for n in range(batch_size):\n",
        "          (state, action, reward, next_state, done) = self.buffer[batch[n]]\n",
        "          state_batch[n,:,:] = state\n",
        "          action_batch[n] = action\n",
        "          reward_batch[n] = reward\n",
        "          next_state_batch[n,:,:] = next_state\n",
        "          done_batch[n] = done\n",
        "          \n",
        "        \n",
        "        return state_batch, action_batch, reward_batch, next_state_batch, done_batch\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "\n",
        "def learn(agent, **kwargs):   \n",
        "    #save the statistics here\n",
        "    update_step = 0\n",
        "    train_start = kwargs.get('number of pre-interactions to start training', 50000)\n",
        "    batch_size = kwargs.get('batch size', 32)\n",
        "    try:\n",
        "        max_steps = env._max_episode_steps# \n",
        "    except:\n",
        "        max_steps = kwargs.get('max steps per episode', 27500)   \n",
        "    max_episodes = kwargs.get('max episodes', 1000000)   \n",
        "    update_every_n_step = kwargs.get('update every n steps', 4)   \n",
        "    n_frame = 0\n",
        "    running_100_mean = np.zeros(100)    \n",
        "    epsilon_start = 1\n",
        "    epsilon_final = 0.1\n",
        "\n",
        "    \n",
        "    epi_returns = [] # save this statistics for plotting\n",
        "    test_phase_avg_returns = []\n",
        "\n",
        "    for episode in range(max_episodes):    \n",
        "                \n",
        "        state = env.reset()\n",
        "        epi_return = 0\n",
        "        for step in itertools.count():\n",
        "            # Implement linearly-decaying epsilon\n",
        "            agent.epsilon = max(epsilon_final, epsilon_start - (epsilon_start - epsilon_final)* n_frame/500000. )\n",
        "            action= agent.act(state)                            \n",
        "            next_state, reward, done, _ = env.step(action)            \n",
        "            n_frame+=1        \n",
        "            # Push the experience into replay buffer                                                              \n",
        "            agent.replay_buffer.push(state, action, reward, next_state, done)\n",
        "            epi_return += reward\n",
        "            \n",
        "            # gent collects enough experience () and performs an update every 4 interactions.\n",
        "            if (len(agent.replay_buffer) > train_start) and ((n_frame % update_every_n_step) == 0): \n",
        "                agent.update(batch_size)\n",
        "                update_step += 1\n",
        "            state = next_state\n",
        "            \n",
        "            if done == True or step >= max_steps:\n",
        "                running_100_mean[episode%100] = epi_return\n",
        "                epi_returns.append(epi_return)\n",
        "                print('Episode : {} , episodic length : {}, return: {}, exp_count :{}, averged returnover past 100 episodes : {}'.format(episode , step, epi_return, n_frame, np.mean(running_100_mean[:min(100,episode+1)]))) \n",
        "                break\n",
        "\n",
        "        #---------------Save the satistics of ----------------\n",
        "        if episode%50 == 49: # you can change here\n",
        "            epi_returns_np = np.array(epi_returns)\n",
        "            # ---save the statistics for plotting ---\n",
        "            np.save(\"epi_returns.npy\", epi_returns_np)\n",
        "        #----------------------------Testing-----------------------\n",
        "        if episode%100 == 99:\n",
        "            test_returns = np.zeros(15)\n",
        "            print ('-----start Testing------')\n",
        "            epi_return = 0       \n",
        "            state = test_env.reset()  \n",
        "            for i in range(15): # test for 15 episodes\n",
        "                state = test_env.reset()  \n",
        "                for t in range(max_steps):\n",
        "                    # env.render()\n",
        "                    action = agent.test_act(state)\n",
        "                    next_state, reward, done, _ = test_env.step(action)\n",
        "                    state = next_state\n",
        "                    epi_return += reward                  \n",
        "                    if done or (t == max_steps - 1):\n",
        "                        test_returns[i] = epi_return\n",
        "                        epi_return = 0\n",
        "                        break           \n",
        "            test_phase_avg_returns.append(np.mean(test_returns))        \n",
        "            print('Testing result, Returns: {}'.format(test_returns))\n",
        "            test_phase_avg_returns_np = np.array(test_phase_avg_returns)\n",
        "            # ---IMPORTNT: To do: save the statistics here for plotting ---\n",
        "            np.save(\"test_phase_avg_returns.npy\", test_phase_avg_returns_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdiyOZA6iMwP",
        "outputId": "7d2943be-b733-4de5-ff57-a682cac7d9d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 84, 84)\n",
            "Using cuda for training the algorithm.\n",
            "Episode : 0 , episodic length : 964, return: -19.0, exp_count :965, averged returnover past 100 episodes : -19.0\n",
            "Episode : 1 , episodic length : 938, return: -21.0, exp_count :1904, averged returnover past 100 episodes : -20.0\n",
            "Episode : 2 , episodic length : 905, return: -21.0, exp_count :2810, averged returnover past 100 episodes : -20.333333333333332\n",
            "Episode : 3 , episodic length : 867, return: -21.0, exp_count :3678, averged returnover past 100 episodes : -20.5\n",
            "Episode : 4 , episodic length : 926, return: -20.0, exp_count :4605, averged returnover past 100 episodes : -20.4\n",
            "Episode : 5 , episodic length : 847, return: -21.0, exp_count :5453, averged returnover past 100 episodes : -20.5\n",
            "Episode : 6 , episodic length : 1047, return: -20.0, exp_count :6501, averged returnover past 100 episodes : -20.428571428571427\n",
            "Episode : 7 , episodic length : 936, return: -21.0, exp_count :7438, averged returnover past 100 episodes : -20.5\n",
            "Episode : 8 , episodic length : 1032, return: -21.0, exp_count :8471, averged returnover past 100 episodes : -20.555555555555557\n",
            "Episode : 9 , episodic length : 974, return: -19.0, exp_count :9446, averged returnover past 100 episodes : -20.4\n",
            "Episode : 10 , episodic length : 1308, return: -18.0, exp_count :10755, averged returnover past 100 episodes : -20.181818181818183\n",
            "Episode : 11 , episodic length : 815, return: -21.0, exp_count :11571, averged returnover past 100 episodes : -20.25\n",
            "Episode : 12 , episodic length : 845, return: -21.0, exp_count :12417, averged returnover past 100 episodes : -20.307692307692307\n",
            "Episode : 13 , episodic length : 924, return: -20.0, exp_count :13342, averged returnover past 100 episodes : -20.285714285714285\n",
            "Q loss: 0.014848520047962666\n",
            "Episode : 14 , episodic length : 956, return: -20.0, exp_count :14299, averged returnover past 100 episodes : -20.266666666666666\n",
            "Episode : 15 , episodic length : 998, return: -20.0, exp_count :15298, averged returnover past 100 episodes : -20.25\n",
            "Episode : 16 , episodic length : 798, return: -21.0, exp_count :16097, averged returnover past 100 episodes : -20.294117647058822\n",
            "Episode : 17 , episodic length : 909, return: -21.0, exp_count :17007, averged returnover past 100 episodes : -20.333333333333332\n",
            "Episode : 18 , episodic length : 789, return: -21.0, exp_count :17797, averged returnover past 100 episodes : -20.36842105263158\n",
            "Q loss: 0.0024568315129727125\n",
            "Episode : 19 , episodic length : 877, return: -21.0, exp_count :18675, averged returnover past 100 episodes : -20.4\n",
            "Episode : 20 , episodic length : 891, return: -21.0, exp_count :19567, averged returnover past 100 episodes : -20.428571428571427\n",
            "Episode : 21 , episodic length : 1002, return: -19.0, exp_count :20570, averged returnover past 100 episodes : -20.363636363636363\n",
            "Episode : 22 , episodic length : 1026, return: -19.0, exp_count :21597, averged returnover past 100 episodes : -20.304347826086957\n",
            "Q loss: 0.0002828865544870496\n",
            "Episode : 23 , episodic length : 917, return: -20.0, exp_count :22515, averged returnover past 100 episodes : -20.291666666666668\n",
            "Episode : 24 , episodic length : 820, return: -21.0, exp_count :23336, averged returnover past 100 episodes : -20.32\n",
            "Episode : 25 , episodic length : 1055, return: -20.0, exp_count :24392, averged returnover past 100 episodes : -20.307692307692307\n",
            "Episode : 26 , episodic length : 940, return: -21.0, exp_count :25333, averged returnover past 100 episodes : -20.333333333333332\n",
            "Q loss: 0.0010283641749992967\n",
            "Episode : 27 , episodic length : 847, return: -21.0, exp_count :26181, averged returnover past 100 episodes : -20.357142857142858\n",
            "Episode : 28 , episodic length : 1014, return: -19.0, exp_count :27196, averged returnover past 100 episodes : -20.310344827586206\n",
            "Episode : 29 , episodic length : 895, return: -20.0, exp_count :28092, averged returnover past 100 episodes : -20.3\n",
            "Episode : 30 , episodic length : 881, return: -21.0, exp_count :28974, averged returnover past 100 episodes : -20.322580645161292\n",
            "Episode : 31 , episodic length : 980, return: -20.0, exp_count :29955, averged returnover past 100 episodes : -20.3125\n",
            "Q loss: 0.0016057973261922598\n",
            "Episode : 32 , episodic length : 942, return: -19.0, exp_count :30898, averged returnover past 100 episodes : -20.272727272727273\n",
            "Episode : 33 , episodic length : 879, return: -20.0, exp_count :31778, averged returnover past 100 episodes : -20.264705882352942\n",
            "Episode : 34 , episodic length : 879, return: -20.0, exp_count :32658, averged returnover past 100 episodes : -20.257142857142856\n",
            "Episode : 35 , episodic length : 899, return: -21.0, exp_count :33558, averged returnover past 100 episodes : -20.27777777777778\n",
            "Q loss: 0.0002630944363772869\n",
            "Episode : 36 , episodic length : 1054, return: -20.0, exp_count :34613, averged returnover past 100 episodes : -20.27027027027027\n",
            "Episode : 37 , episodic length : 1207, return: -17.0, exp_count :35821, averged returnover past 100 episodes : -20.18421052631579\n",
            "Episode : 38 , episodic length : 1021, return: -19.0, exp_count :36843, averged returnover past 100 episodes : -20.153846153846153\n",
            "Episode : 39 , episodic length : 963, return: -21.0, exp_count :37807, averged returnover past 100 episodes : -20.175\n",
            "Q loss: 0.0007200331892818213\n",
            "Episode : 40 , episodic length : 919, return: -21.0, exp_count :38727, averged returnover past 100 episodes : -20.195121951219512\n",
            "Episode : 41 , episodic length : 757, return: -21.0, exp_count :39485, averged returnover past 100 episodes : -20.214285714285715\n",
            "Episode : 42 , episodic length : 998, return: -20.0, exp_count :40484, averged returnover past 100 episodes : -20.209302325581394\n",
            "Episode : 43 , episodic length : 989, return: -20.0, exp_count :41474, averged returnover past 100 episodes : -20.204545454545453\n",
            "Q loss: 0.000395215000025928\n",
            "Episode : 44 , episodic length : 837, return: -21.0, exp_count :42312, averged returnover past 100 episodes : -20.22222222222222\n",
            "Episode : 45 , episodic length : 955, return: -20.0, exp_count :43268, averged returnover past 100 episodes : -20.217391304347824\n",
            "Episode : 46 , episodic length : 977, return: -19.0, exp_count :44246, averged returnover past 100 episodes : -20.19148936170213\n",
            "Episode : 47 , episodic length : 884, return: -21.0, exp_count :45131, averged returnover past 100 episodes : -20.208333333333332\n",
            "Q loss: 0.0002686937805265188\n",
            "Episode : 48 , episodic length : 951, return: -21.0, exp_count :46083, averged returnover past 100 episodes : -20.224489795918366\n",
            "Episode : 49 , episodic length : 845, return: -21.0, exp_count :46929, averged returnover past 100 episodes : -20.24\n",
            "Episode : 50 , episodic length : 821, return: -21.0, exp_count :47751, averged returnover past 100 episodes : -20.254901960784313\n",
            "Episode : 51 , episodic length : 1035, return: -18.0, exp_count :48787, averged returnover past 100 episodes : -20.21153846153846\n",
            "Episode : 52 , episodic length : 829, return: -20.0, exp_count :49617, averged returnover past 100 episodes : -20.20754716981132\n",
            "Q loss: 0.0004094082396477461\n",
            "Episode : 53 , episodic length : 920, return: -20.0, exp_count :50538, averged returnover past 100 episodes : -20.203703703703702\n",
            "Episode : 54 , episodic length : 874, return: -21.0, exp_count :51413, averged returnover past 100 episodes : -20.21818181818182\n",
            "Episode : 55 , episodic length : 989, return: -20.0, exp_count :52403, averged returnover past 100 episodes : -20.214285714285715\n",
            "Episode : 56 , episodic length : 897, return: -21.0, exp_count :53301, averged returnover past 100 episodes : -20.228070175438596\n",
            "Q loss: 0.0013211544137448072\n",
            "Episode : 57 , episodic length : 814, return: -21.0, exp_count :54116, averged returnover past 100 episodes : -20.24137931034483\n",
            "Episode : 58 , episodic length : 945, return: -21.0, exp_count :55062, averged returnover past 100 episodes : -20.25423728813559\n",
            "Episode : 59 , episodic length : 841, return: -21.0, exp_count :55904, averged returnover past 100 episodes : -20.266666666666666\n",
            "Episode : 60 , episodic length : 985, return: -19.0, exp_count :56890, averged returnover past 100 episodes : -20.24590163934426\n",
            "Episode : 61 , episodic length : 957, return: -20.0, exp_count :57848, averged returnover past 100 episodes : -20.241935483870968\n",
            "Q loss: 0.00017441358068026602\n",
            "Episode : 62 , episodic length : 927, return: -20.0, exp_count :58776, averged returnover past 100 episodes : -20.238095238095237\n",
            "Episode : 63 , episodic length : 973, return: -19.0, exp_count :59750, averged returnover past 100 episodes : -20.21875\n",
            "Episode : 64 , episodic length : 1020, return: -19.0, exp_count :60771, averged returnover past 100 episodes : -20.2\n",
            "Episode : 65 , episodic length : 921, return: -20.0, exp_count :61693, averged returnover past 100 episodes : -20.196969696969695\n",
            "Q loss: 0.0017904089763760567\n",
            "Episode : 66 , episodic length : 756, return: -21.0, exp_count :62450, averged returnover past 100 episodes : -20.208955223880597\n",
            "Episode : 67 , episodic length : 881, return: -21.0, exp_count :63332, averged returnover past 100 episodes : -20.220588235294116\n",
            "Episode : 68 , episodic length : 784, return: -21.0, exp_count :64117, averged returnover past 100 episodes : -20.231884057971016\n",
            "Episode : 69 , episodic length : 901, return: -20.0, exp_count :65019, averged returnover past 100 episodes : -20.228571428571428\n",
            "Episode : 70 , episodic length : 904, return: -21.0, exp_count :65924, averged returnover past 100 episodes : -20.239436619718308\n",
            "Q loss: 0.0038072008173912764\n",
            "Episode : 71 , episodic length : 777, return: -21.0, exp_count :66702, averged returnover past 100 episodes : -20.25\n",
            "Episode : 72 , episodic length : 966, return: -20.0, exp_count :67669, averged returnover past 100 episodes : -20.246575342465754\n",
            "Episode : 73 , episodic length : 905, return: -21.0, exp_count :68575, averged returnover past 100 episodes : -20.256756756756758\n",
            "Episode : 74 , episodic length : 927, return: -21.0, exp_count :69503, averged returnover past 100 episodes : -20.266666666666666\n",
            "Q loss: 0.0007850133115425706\n",
            "Episode : 75 , episodic length : 838, return: -20.0, exp_count :70342, averged returnover past 100 episodes : -20.263157894736842\n",
            "Episode : 76 , episodic length : 1099, return: -20.0, exp_count :71442, averged returnover past 100 episodes : -20.25974025974026\n",
            "Episode : 77 , episodic length : 997, return: -20.0, exp_count :72440, averged returnover past 100 episodes : -20.256410256410255\n",
            "Episode : 78 , episodic length : 935, return: -21.0, exp_count :73376, averged returnover past 100 episodes : -20.265822784810126\n",
            "Q loss: 0.0025737532414495945\n",
            "Episode : 79 , episodic length : 902, return: -21.0, exp_count :74279, averged returnover past 100 episodes : -20.275\n",
            "Episode : 80 , episodic length : 801, return: -21.0, exp_count :75081, averged returnover past 100 episodes : -20.28395061728395\n",
            "Episode : 81 , episodic length : 1014, return: -20.0, exp_count :76096, averged returnover past 100 episodes : -20.28048780487805\n",
            "Episode : 82 , episodic length : 785, return: -21.0, exp_count :76882, averged returnover past 100 episodes : -20.289156626506024\n",
            "Episode : 83 , episodic length : 942, return: -20.0, exp_count :77825, averged returnover past 100 episodes : -20.285714285714285\n",
            "Q loss: 8.461317338515073e-05\n",
            "Episode : 84 , episodic length : 925, return: -20.0, exp_count :78751, averged returnover past 100 episodes : -20.28235294117647\n",
            "Episode : 85 , episodic length : 1078, return: -20.0, exp_count :79830, averged returnover past 100 episodes : -20.27906976744186\n",
            "Episode : 86 , episodic length : 912, return: -20.0, exp_count :80743, averged returnover past 100 episodes : -20.275862068965516\n",
            "Episode : 87 , episodic length : 808, return: -21.0, exp_count :81552, averged returnover past 100 episodes : -20.28409090909091\n",
            "Q loss: 0.00792631134390831\n",
            "Episode : 88 , episodic length : 924, return: -20.0, exp_count :82477, averged returnover past 100 episodes : -20.280898876404493\n",
            "Episode : 89 , episodic length : 860, return: -20.0, exp_count :83338, averged returnover past 100 episodes : -20.27777777777778\n",
            "Episode : 90 , episodic length : 758, return: -21.0, exp_count :84097, averged returnover past 100 episodes : -20.285714285714285\n",
            "Episode : 91 , episodic length : 1089, return: -19.0, exp_count :85187, averged returnover past 100 episodes : -20.27173913043478\n",
            "Q loss: 0.0011008806759491563\n",
            "Episode : 92 , episodic length : 815, return: -21.0, exp_count :86003, averged returnover past 100 episodes : -20.27956989247312\n",
            "Episode : 93 , episodic length : 978, return: -20.0, exp_count :86982, averged returnover past 100 episodes : -20.27659574468085\n",
            "Episode : 94 , episodic length : 969, return: -21.0, exp_count :87952, averged returnover past 100 episodes : -20.28421052631579\n",
            "Episode : 95 , episodic length : 932, return: -19.0, exp_count :88885, averged returnover past 100 episodes : -20.270833333333332\n",
            "Episode : 96 , episodic length : 1083, return: -20.0, exp_count :89969, averged returnover past 100 episodes : -20.2680412371134\n",
            "Q loss: 0.0018330825259909034\n",
            "Episode : 97 , episodic length : 994, return: -20.0, exp_count :90964, averged returnover past 100 episodes : -20.26530612244898\n",
            "Episode : 98 , episodic length : 1125, return: -19.0, exp_count :92090, averged returnover past 100 episodes : -20.252525252525253\n",
            "Episode : 99 , episodic length : 1012, return: -19.0, exp_count :93103, averged returnover past 100 episodes : -20.24\n",
            "-----start Testing------\n",
            "Testing result, Returns: [-21. -21. -21. -21. -21. -21. -20. -21. -20. -20. -21. -21. -21. -21.\n",
            " -20.]\n",
            "Episode : 100 , episodic length : 755, return: -21.0, exp_count :93859, averged returnover past 100 episodes : -20.26\n",
            "Q loss: 0.0010798081057146192\n",
            "Episode : 101 , episodic length : 992, return: -19.0, exp_count :94852, averged returnover past 100 episodes : -20.24\n",
            "Episode : 102 , episodic length : 1129, return: -19.0, exp_count :95982, averged returnover past 100 episodes : -20.22\n",
            "Episode : 103 , episodic length : 858, return: -20.0, exp_count :96841, averged returnover past 100 episodes : -20.21\n",
            "Episode : 104 , episodic length : 1085, return: -18.0, exp_count :97927, averged returnover past 100 episodes : -20.19\n",
            "Q loss: 0.00166588113643229\n",
            "Episode : 105 , episodic length : 754, return: -21.0, exp_count :98682, averged returnover past 100 episodes : -20.19\n",
            "Episode : 106 , episodic length : 879, return: -21.0, exp_count :99562, averged returnover past 100 episodes : -20.2\n",
            "Episode : 107 , episodic length : 756, return: -21.0, exp_count :100319, averged returnover past 100 episodes : -20.2\n",
            "Episode : 108 , episodic length : 816, return: -21.0, exp_count :101136, averged returnover past 100 episodes : -20.2\n",
            "Q loss: 0.004040460102260113\n",
            "Episode : 109 , episodic length : 987, return: -21.0, exp_count :102124, averged returnover past 100 episodes : -20.22\n",
            "Episode : 110 , episodic length : 806, return: -21.0, exp_count :102931, averged returnover past 100 episodes : -20.25\n",
            "Episode : 111 , episodic length : 849, return: -21.0, exp_count :103781, averged returnover past 100 episodes : -20.25\n",
            "Episode : 112 , episodic length : 919, return: -20.0, exp_count :104701, averged returnover past 100 episodes : -20.24\n",
            "Episode : 113 , episodic length : 779, return: -21.0, exp_count :105481, averged returnover past 100 episodes : -20.25\n",
            "Q loss: 0.0021772393956780434\n",
            "Episode : 114 , episodic length : 1020, return: -20.0, exp_count :106502, averged returnover past 100 episodes : -20.25\n",
            "Episode : 115 , episodic length : 867, return: -20.0, exp_count :107370, averged returnover past 100 episodes : -20.25\n",
            "Episode : 116 , episodic length : 880, return: -21.0, exp_count :108251, averged returnover past 100 episodes : -20.25\n",
            "Episode : 117 , episodic length : 1020, return: -19.0, exp_count :109272, averged returnover past 100 episodes : -20.23\n",
            "Q loss: 0.0032974928617477417\n",
            "Episode : 118 , episodic length : 926, return: -20.0, exp_count :110199, averged returnover past 100 episodes : -20.22\n",
            "Episode : 119 , episodic length : 1047, return: -20.0, exp_count :111247, averged returnover past 100 episodes : -20.21\n",
            "Episode : 120 , episodic length : 871, return: -21.0, exp_count :112119, averged returnover past 100 episodes : -20.21\n",
            "Episode : 121 , episodic length : 969, return: -20.0, exp_count :113089, averged returnover past 100 episodes : -20.22\n",
            "Episode : 122 , episodic length : 822, return: -21.0, exp_count :113912, averged returnover past 100 episodes : -20.24\n",
            "Q loss: 0.0013644121354445815\n",
            "Episode : 123 , episodic length : 1301, return: -17.0, exp_count :115214, averged returnover past 100 episodes : -20.21\n",
            "Episode : 124 , episodic length : 890, return: -21.0, exp_count :116105, averged returnover past 100 episodes : -20.21\n",
            "Episode : 125 , episodic length : 1040, return: -19.0, exp_count :117146, averged returnover past 100 episodes : -20.2\n",
            "Q loss: 0.0008074295474216342\n",
            "Episode : 126 , episodic length : 891, return: -21.0, exp_count :118038, averged returnover past 100 episodes : -20.2\n",
            "Episode : 127 , episodic length : 963, return: -20.0, exp_count :119002, averged returnover past 100 episodes : -20.19\n",
            "Episode : 128 , episodic length : 840, return: -21.0, exp_count :119843, averged returnover past 100 episodes : -20.21\n",
            "Episode : 129 , episodic length : 924, return: -21.0, exp_count :120768, averged returnover past 100 episodes : -20.22\n",
            "Episode : 130 , episodic length : 773, return: -21.0, exp_count :121542, averged returnover past 100 episodes : -20.22\n",
            "Q loss: 0.002158705610781908\n",
            "Episode : 131 , episodic length : 964, return: -19.0, exp_count :122507, averged returnover past 100 episodes : -20.21\n",
            "Episode : 132 , episodic length : 844, return: -21.0, exp_count :123352, averged returnover past 100 episodes : -20.23\n",
            "Episode : 133 , episodic length : 840, return: -20.0, exp_count :124193, averged returnover past 100 episodes : -20.23\n",
            "Episode : 134 , episodic length : 925, return: -20.0, exp_count :125119, averged returnover past 100 episodes : -20.23\n",
            "Q loss: 0.002579463180154562\n",
            "Episode : 135 , episodic length : 1140, return: -19.0, exp_count :126260, averged returnover past 100 episodes : -20.21\n",
            "Episode : 136 , episodic length : 839, return: -21.0, exp_count :127100, averged returnover past 100 episodes : -20.22\n",
            "Episode : 137 , episodic length : 913, return: -20.0, exp_count :128014, averged returnover past 100 episodes : -20.25\n",
            "Episode : 138 , episodic length : 865, return: -21.0, exp_count :128880, averged returnover past 100 episodes : -20.27\n",
            "Episode : 139 , episodic length : 939, return: -20.0, exp_count :129820, averged returnover past 100 episodes : -20.26\n",
            "Q loss: 0.001008028513751924\n",
            "Episode : 140 , episodic length : 1058, return: -21.0, exp_count :130879, averged returnover past 100 episodes : -20.26\n",
            "Episode : 141 , episodic length : 1108, return: -20.0, exp_count :131988, averged returnover past 100 episodes : -20.25\n",
            "Episode : 142 , episodic length : 951, return: -20.0, exp_count :132940, averged returnover past 100 episodes : -20.25\n",
            "Episode : 143 , episodic length : 992, return: -21.0, exp_count :133933, averged returnover past 100 episodes : -20.26\n",
            "Q loss: 0.0002025902213063091\n",
            "Episode : 144 , episodic length : 1347, return: -16.0, exp_count :135281, averged returnover past 100 episodes : -20.21\n",
            "Episode : 145 , episodic length : 1124, return: -19.0, exp_count :136406, averged returnover past 100 episodes : -20.2\n",
            "Episode : 146 , episodic length : 1045, return: -20.0, exp_count :137452, averged returnover past 100 episodes : -20.21\n",
            "Q loss: 0.0026283226907253265\n",
            "Episode : 147 , episodic length : 1175, return: -19.0, exp_count :138628, averged returnover past 100 episodes : -20.19\n",
            "Episode : 148 , episodic length : 797, return: -21.0, exp_count :139426, averged returnover past 100 episodes : -20.19\n",
            "Episode : 149 , episodic length : 865, return: -21.0, exp_count :140292, averged returnover past 100 episodes : -20.19\n",
            "Episode : 150 , episodic length : 908, return: -21.0, exp_count :141201, averged returnover past 100 episodes : -20.19\n",
            "Q loss: 0.0006805966841056943\n",
            "Episode : 151 , episodic length : 984, return: -20.0, exp_count :142186, averged returnover past 100 episodes : -20.21\n",
            "Episode : 152 , episodic length : 893, return: -20.0, exp_count :143080, averged returnover past 100 episodes : -20.21\n",
            "Episode : 153 , episodic length : 1064, return: -20.0, exp_count :144145, averged returnover past 100 episodes : -20.21\n",
            "Episode : 154 , episodic length : 1031, return: -20.0, exp_count :145177, averged returnover past 100 episodes : -20.2\n",
            "Q loss: 0.0007003057980909944\n",
            "Episode : 155 , episodic length : 899, return: -20.0, exp_count :146077, averged returnover past 100 episodes : -20.2\n",
            "Episode : 156 , episodic length : 844, return: -21.0, exp_count :146922, averged returnover past 100 episodes : -20.2\n",
            "Episode : 157 , episodic length : 1045, return: -18.0, exp_count :147968, averged returnover past 100 episodes : -20.17\n",
            "Episode : 158 , episodic length : 1092, return: -20.0, exp_count :149061, averged returnover past 100 episodes : -20.16\n",
            "Episode : 159 , episodic length : 877, return: -21.0, exp_count :149939, averged returnover past 100 episodes : -20.16\n",
            "Q loss: 0.0009184369118884206\n",
            "Episode : 160 , episodic length : 989, return: -19.0, exp_count :150929, averged returnover past 100 episodes : -20.16\n",
            "Episode : 161 , episodic length : 1028, return: -20.0, exp_count :151958, averged returnover past 100 episodes : -20.16\n",
            "Episode : 162 , episodic length : 834, return: -20.0, exp_count :152793, averged returnover past 100 episodes : -20.16\n",
            "Episode : 163 , episodic length : 921, return: -20.0, exp_count :153715, averged returnover past 100 episodes : -20.17\n",
            "Q loss: 0.0023949784226715565\n",
            "Episode : 164 , episodic length : 1082, return: -17.0, exp_count :154798, averged returnover past 100 episodes : -20.15\n",
            "Episode : 165 , episodic length : 995, return: -21.0, exp_count :155794, averged returnover past 100 episodes : -20.16\n",
            "Episode : 166 , episodic length : 1042, return: -20.0, exp_count :156837, averged returnover past 100 episodes : -20.15\n",
            "Episode : 167 , episodic length : 997, return: -20.0, exp_count :157835, averged returnover past 100 episodes : -20.14\n",
            "Q loss: 0.0015093841357156634\n",
            "Episode : 168 , episodic length : 931, return: -21.0, exp_count :158767, averged returnover past 100 episodes : -20.14\n",
            "Episode : 169 , episodic length : 968, return: -20.0, exp_count :159736, averged returnover past 100 episodes : -20.14\n",
            "Episode : 170 , episodic length : 838, return: -21.0, exp_count :160575, averged returnover past 100 episodes : -20.14\n",
            "Episode : 171 , episodic length : 972, return: -20.0, exp_count :161548, averged returnover past 100 episodes : -20.13\n",
            "Q loss: 0.002135541755706072\n",
            "Episode : 172 , episodic length : 1044, return: -19.0, exp_count :162593, averged returnover past 100 episodes : -20.12\n",
            "Episode : 173 , episodic length : 1025, return: -20.0, exp_count :163619, averged returnover past 100 episodes : -20.11\n",
            "Episode : 174 , episodic length : 950, return: -21.0, exp_count :164570, averged returnover past 100 episodes : -20.11\n",
            "Episode : 175 , episodic length : 934, return: -21.0, exp_count :165505, averged returnover past 100 episodes : -20.12\n",
            "Q loss: 0.0014037354849278927\n",
            "Episode : 176 , episodic length : 815, return: -21.0, exp_count :166321, averged returnover past 100 episodes : -20.13\n",
            "Episode : 177 , episodic length : 1014, return: -20.0, exp_count :167336, averged returnover past 100 episodes : -20.13\n",
            "Episode : 178 , episodic length : 1005, return: -19.0, exp_count :168342, averged returnover past 100 episodes : -20.11\n",
            "Episode : 179 , episodic length : 1316, return: -19.0, exp_count :169659, averged returnover past 100 episodes : -20.09\n",
            "Q loss: 0.00045580120058730245\n",
            "Episode : 180 , episodic length : 1187, return: -20.0, exp_count :170847, averged returnover past 100 episodes : -20.08\n",
            "Episode : 181 , episodic length : 936, return: -21.0, exp_count :171784, averged returnover past 100 episodes : -20.09\n",
            "Episode : 182 , episodic length : 977, return: -20.0, exp_count :172762, averged returnover past 100 episodes : -20.08\n",
            "Episode : 183 , episodic length : 1137, return: -19.0, exp_count :173900, averged returnover past 100 episodes : -20.07\n",
            "Q loss: 0.001354917767457664\n",
            "Episode : 184 , episodic length : 1133, return: -20.0, exp_count :175034, averged returnover past 100 episodes : -20.07\n",
            "Episode : 185 , episodic length : 807, return: -21.0, exp_count :175842, averged returnover past 100 episodes : -20.08\n",
            "Episode : 186 , episodic length : 840, return: -21.0, exp_count :176683, averged returnover past 100 episodes : -20.09\n",
            "Episode : 187 , episodic length : 1085, return: -19.0, exp_count :177769, averged returnover past 100 episodes : -20.07\n",
            "Q loss: 0.0016879333416000009\n",
            "Episode : 188 , episodic length : 858, return: -20.0, exp_count :178628, averged returnover past 100 episodes : -20.07\n",
            "Episode : 189 , episodic length : 1007, return: -21.0, exp_count :179636, averged returnover past 100 episodes : -20.08\n",
            "Episode : 190 , episodic length : 1056, return: -19.0, exp_count :180693, averged returnover past 100 episodes : -20.06\n",
            "Episode : 191 , episodic length : 983, return: -21.0, exp_count :181677, averged returnover past 100 episodes : -20.08\n",
            "Q loss: 0.002247639698907733\n",
            "Episode : 192 , episodic length : 997, return: -21.0, exp_count :182675, averged returnover past 100 episodes : -20.08\n",
            "Episode : 193 , episodic length : 1122, return: -20.0, exp_count :183798, averged returnover past 100 episodes : -20.08\n",
            "Episode : 194 , episodic length : 1133, return: -20.0, exp_count :184932, averged returnover past 100 episodes : -20.07\n",
            "Episode : 195 , episodic length : 896, return: -20.0, exp_count :185829, averged returnover past 100 episodes : -20.08\n",
            "Q loss: 0.001397909363731742\n",
            "Episode : 196 , episodic length : 915, return: -20.0, exp_count :186745, averged returnover past 100 episodes : -20.08\n",
            "Episode : 197 , episodic length : 1106, return: -19.0, exp_count :187852, averged returnover past 100 episodes : -20.07\n",
            "Episode : 198 , episodic length : 1266, return: -20.0, exp_count :189119, averged returnover past 100 episodes : -20.08\n",
            "Q loss: 0.0056619648821651936\n",
            "Episode : 199 , episodic length : 952, return: -21.0, exp_count :190072, averged returnover past 100 episodes : -20.1\n",
            "-----start Testing------\n",
            "Testing result, Returns: [-21. -21. -21. -21. -21. -21. -21. -21. -21. -21. -21. -21. -21. -21.\n",
            " -21.]\n",
            "Episode : 200 , episodic length : 832, return: -20.0, exp_count :190905, averged returnover past 100 episodes : -20.09\n",
            "Episode : 201 , episodic length : 1083, return: -20.0, exp_count :191989, averged returnover past 100 episodes : -20.1\n",
            "Episode : 202 , episodic length : 849, return: -21.0, exp_count :192839, averged returnover past 100 episodes : -20.12\n",
            "Episode : 203 , episodic length : 1003, return: -21.0, exp_count :193843, averged returnover past 100 episodes : -20.13\n",
            "Q loss: 0.0023283332120627165\n",
            "Episode : 204 , episodic length : 1212, return: -18.0, exp_count :195056, averged returnover past 100 episodes : -20.13\n",
            "Episode : 205 , episodic length : 1314, return: -17.0, exp_count :196371, averged returnover past 100 episodes : -20.09\n",
            "Episode : 206 , episodic length : 1026, return: -21.0, exp_count :197398, averged returnover past 100 episodes : -20.09\n",
            "Q loss: 0.0010417124722152948\n",
            "Episode : 207 , episodic length : 1039, return: -20.0, exp_count :198438, averged returnover past 100 episodes : -20.08\n",
            "Episode : 208 , episodic length : 939, return: -21.0, exp_count :199378, averged returnover past 100 episodes : -20.08\n",
            "Episode : 209 , episodic length : 1218, return: -20.0, exp_count :200597, averged returnover past 100 episodes : -20.07\n",
            "Episode : 210 , episodic length : 943, return: -20.0, exp_count :201541, averged returnover past 100 episodes : -20.06\n",
            "Q loss: 0.004000519867986441\n",
            "Episode : 211 , episodic length : 1163, return: -20.0, exp_count :202705, averged returnover past 100 episodes : -20.05\n",
            "Episode : 212 , episodic length : 996, return: -21.0, exp_count :203702, averged returnover past 100 episodes : -20.06\n",
            "Episode : 213 , episodic length : 956, return: -20.0, exp_count :204659, averged returnover past 100 episodes : -20.05\n",
            "Episode : 214 , episodic length : 1295, return: -19.0, exp_count :205955, averged returnover past 100 episodes : -20.04\n",
            "Q loss: 0.004513334482908249\n",
            "Episode : 215 , episodic length : 1174, return: -19.0, exp_count :207130, averged returnover past 100 episodes : -20.03\n",
            "Episode : 216 , episodic length : 1298, return: -19.0, exp_count :208429, averged returnover past 100 episodes : -20.01\n",
            "Episode : 217 , episodic length : 1276, return: -18.0, exp_count :209706, averged returnover past 100 episodes : -20.0\n",
            "Q loss: 0.007768346928060055\n",
            "Episode : 218 , episodic length : 1211, return: -19.0, exp_count :210918, averged returnover past 100 episodes : -19.99\n",
            "Episode : 219 , episodic length : 1188, return: -19.0, exp_count :212107, averged returnover past 100 episodes : -19.98\n",
            "Episode : 220 , episodic length : 907, return: -21.0, exp_count :213015, averged returnover past 100 episodes : -19.98\n",
            "Q loss: 0.0018882106523960829\n",
            "Episode : 221 , episodic length : 1097, return: -20.0, exp_count :214113, averged returnover past 100 episodes : -19.98\n",
            "Episode : 222 , episodic length : 1245, return: -20.0, exp_count :215359, averged returnover past 100 episodes : -19.97\n",
            "Episode : 223 , episodic length : 1205, return: -21.0, exp_count :216565, averged returnover past 100 episodes : -20.01\n",
            "Episode : 224 , episodic length : 1182, return: -20.0, exp_count :217748, averged returnover past 100 episodes : -20.0\n",
            "Q loss: 0.004061882849782705\n",
            "Episode : 225 , episodic length : 1229, return: -19.0, exp_count :218978, averged returnover past 100 episodes : -20.0\n",
            "Episode : 226 , episodic length : 1414, return: -18.0, exp_count :220393, averged returnover past 100 episodes : -19.97\n",
            "Episode : 227 , episodic length : 1185, return: -19.0, exp_count :221579, averged returnover past 100 episodes : -19.96\n",
            "Q loss: 0.0006913691177032888\n",
            "Episode : 228 , episodic length : 1159, return: -19.0, exp_count :222739, averged returnover past 100 episodes : -19.94\n",
            "Episode : 229 , episodic length : 1300, return: -17.0, exp_count :224040, averged returnover past 100 episodes : -19.9\n",
            "Episode : 230 , episodic length : 1198, return: -18.0, exp_count :225239, averged returnover past 100 episodes : -19.87\n",
            "Q loss: 0.0016090314602479339\n",
            "Episode : 231 , episodic length : 1273, return: -18.0, exp_count :226513, averged returnover past 100 episodes : -19.86\n",
            "Episode : 232 , episodic length : 1530, return: -19.0, exp_count :228044, averged returnover past 100 episodes : -19.84\n",
            "Episode : 233 , episodic length : 1228, return: -19.0, exp_count :229273, averged returnover past 100 episodes : -19.83\n",
            "Q loss: 0.003759886370971799\n",
            "Episode : 234 , episodic length : 1076, return: -21.0, exp_count :230350, averged returnover past 100 episodes : -19.84\n",
            "Episode : 235 , episodic length : 1227, return: -20.0, exp_count :231578, averged returnover past 100 episodes : -19.85\n",
            "Episode : 236 , episodic length : 1136, return: -19.0, exp_count :232715, averged returnover past 100 episodes : -19.83\n",
            "Episode : 237 , episodic length : 1165, return: -20.0, exp_count :233881, averged returnover past 100 episodes : -19.83\n",
            "Q loss: 0.0067168730311095715\n",
            "Episode : 238 , episodic length : 1287, return: -19.0, exp_count :235169, averged returnover past 100 episodes : -19.81\n",
            "Episode : 239 , episodic length : 1027, return: -21.0, exp_count :236197, averged returnover past 100 episodes : -19.82\n",
            "Episode : 240 , episodic length : 1190, return: -20.0, exp_count :237388, averged returnover past 100 episodes : -19.81\n",
            "Q loss: 0.005494552664458752\n",
            "Episode : 241 , episodic length : 1073, return: -21.0, exp_count :238462, averged returnover past 100 episodes : -19.82\n",
            "Episode : 242 , episodic length : 1340, return: -18.0, exp_count :239803, averged returnover past 100 episodes : -19.8\n",
            "Episode : 243 , episodic length : 1207, return: -20.0, exp_count :241011, averged returnover past 100 episodes : -19.79\n",
            "Q loss: 0.0014356839237734675\n",
            "Episode : 244 , episodic length : 1171, return: -20.0, exp_count :242183, averged returnover past 100 episodes : -19.83\n",
            "Episode : 245 , episodic length : 1614, return: -18.0, exp_count :243798, averged returnover past 100 episodes : -19.82\n",
            "Episode : 246 , episodic length : 1375, return: -18.0, exp_count :245174, averged returnover past 100 episodes : -19.8\n",
            "Q loss: 0.0013153948821127415\n",
            "Episode : 247 , episodic length : 1088, return: -20.0, exp_count :246263, averged returnover past 100 episodes : -19.81\n",
            "Episode : 248 , episodic length : 1441, return: -18.0, exp_count :247705, averged returnover past 100 episodes : -19.78\n",
            "Episode : 249 , episodic length : 1271, return: -18.0, exp_count :248977, averged returnover past 100 episodes : -19.75\n",
            "Q loss: 0.002248359378427267\n",
            "Episode : 250 , episodic length : 1603, return: -20.0, exp_count :250581, averged returnover past 100 episodes : -19.74\n",
            "Episode : 251 , episodic length : 1415, return: -20.0, exp_count :251997, averged returnover past 100 episodes : -19.74\n",
            "Episode : 252 , episodic length : 1382, return: -18.0, exp_count :253380, averged returnover past 100 episodes : -19.72\n",
            "Q loss: 0.00578936655074358\n",
            "Episode : 253 , episodic length : 1243, return: -19.0, exp_count :254624, averged returnover past 100 episodes : -19.71\n",
            "Episode : 254 , episodic length : 1491, return: -20.0, exp_count :256116, averged returnover past 100 episodes : -19.71\n",
            "Episode : 255 , episodic length : 1110, return: -21.0, exp_count :257227, averged returnover past 100 episodes : -19.72\n",
            "Q loss: 0.006536068394780159\n",
            "Episode : 256 , episodic length : 1232, return: -20.0, exp_count :258460, averged returnover past 100 episodes : -19.71\n",
            "Episode : 257 , episodic length : 1399, return: -18.0, exp_count :259860, averged returnover past 100 episodes : -19.71\n",
            "Episode : 258 , episodic length : 1658, return: -18.0, exp_count :261519, averged returnover past 100 episodes : -19.69\n",
            "Q loss: 0.004009922966361046\n",
            "Episode : 259 , episodic length : 1310, return: -21.0, exp_count :262830, averged returnover past 100 episodes : -19.69\n",
            "Episode : 260 , episodic length : 1324, return: -20.0, exp_count :264155, averged returnover past 100 episodes : -19.7\n",
            "Episode : 261 , episodic length : 1420, return: -19.0, exp_count :265576, averged returnover past 100 episodes : -19.69\n",
            "Q loss: 0.002951637841761112\n",
            "Episode : 262 , episodic length : 1272, return: -21.0, exp_count :266849, averged returnover past 100 episodes : -19.7\n",
            "Episode : 263 , episodic length : 1373, return: -19.0, exp_count :268223, averged returnover past 100 episodes : -19.69\n",
            "Episode : 264 , episodic length : 1204, return: -20.0, exp_count :269428, averged returnover past 100 episodes : -19.72\n",
            "Q loss: 0.0014311057748273015\n",
            "Episode : 265 , episodic length : 1692, return: -15.0, exp_count :271121, averged returnover past 100 episodes : -19.66\n",
            "Episode : 266 , episodic length : 1304, return: -20.0, exp_count :272426, averged returnover past 100 episodes : -19.66\n",
            "Episode : 267 , episodic length : 1404, return: -20.0, exp_count :273831, averged returnover past 100 episodes : -19.66\n",
            "Q loss: 0.0022604844998568296\n",
            "Episode : 268 , episodic length : 1242, return: -20.0, exp_count :275074, averged returnover past 100 episodes : -19.65\n",
            "Episode : 269 , episodic length : 1364, return: -20.0, exp_count :276439, averged returnover past 100 episodes : -19.65\n",
            "Episode : 270 , episodic length : 1475, return: -18.0, exp_count :277915, averged returnover past 100 episodes : -19.62\n",
            "Q loss: 0.0020569460466504097\n",
            "Episode : 271 , episodic length : 1386, return: -17.0, exp_count :279302, averged returnover past 100 episodes : -19.59\n",
            "Episode : 272 , episodic length : 1033, return: -21.0, exp_count :280336, averged returnover past 100 episodes : -19.61\n",
            "Episode : 273 , episodic length : 1244, return: -18.0, exp_count :281581, averged returnover past 100 episodes : -19.59\n",
            "Q loss: 0.001421956461854279\n",
            "Episode : 274 , episodic length : 1446, return: -19.0, exp_count :283028, averged returnover past 100 episodes : -19.57\n",
            "Episode : 275 , episodic length : 1352, return: -19.0, exp_count :284381, averged returnover past 100 episodes : -19.55\n",
            "Episode : 276 , episodic length : 1157, return: -21.0, exp_count :285539, averged returnover past 100 episodes : -19.55\n",
            "Q loss: 0.0030904156155884266\n",
            "Episode : 277 , episodic length : 1503, return: -18.0, exp_count :287043, averged returnover past 100 episodes : -19.53\n",
            "Episode : 278 , episodic length : 1608, return: -14.0, exp_count :288652, averged returnover past 100 episodes : -19.48\n",
            "Q loss: 0.004547450225800276\n",
            "Episode : 279 , episodic length : 1591, return: -18.0, exp_count :290244, averged returnover past 100 episodes : -19.47\n",
            "Episode : 280 , episodic length : 1261, return: -20.0, exp_count :291506, averged returnover past 100 episodes : -19.47\n",
            "Episode : 281 , episodic length : 1317, return: -20.0, exp_count :292824, averged returnover past 100 episodes : -19.46\n",
            "Q loss: 0.004415471106767654\n",
            "Episode : 282 , episodic length : 1461, return: -18.0, exp_count :294286, averged returnover past 100 episodes : -19.44\n",
            "Episode : 283 , episodic length : 1434, return: -17.0, exp_count :295721, averged returnover past 100 episodes : -19.42\n",
            "Episode : 284 , episodic length : 1350, return: -19.0, exp_count :297072, averged returnover past 100 episodes : -19.41\n",
            "Q loss: 0.001787432935088873\n",
            "Episode : 285 , episodic length : 1177, return: -20.0, exp_count :298250, averged returnover past 100 episodes : -19.4\n",
            "Episode : 286 , episodic length : 1286, return: -20.0, exp_count :299537, averged returnover past 100 episodes : -19.39\n",
            "Episode : 287 , episodic length : 1178, return: -21.0, exp_count :300716, averged returnover past 100 episodes : -19.41\n",
            "Episode : 288 , episodic length : 1113, return: -21.0, exp_count :301830, averged returnover past 100 episodes : -19.42\n",
            "Q loss: 0.0012891239020973444\n",
            "Episode : 289 , episodic length : 1372, return: -20.0, exp_count :303203, averged returnover past 100 episodes : -19.41\n",
            "Episode : 290 , episodic length : 1636, return: -19.0, exp_count :304840, averged returnover past 100 episodes : -19.41\n",
            "Q loss: 0.004013197962194681\n",
            "Episode : 291 , episodic length : 1473, return: -19.0, exp_count :306314, averged returnover past 100 episodes : -19.39\n",
            "Episode : 292 , episodic length : 1453, return: -19.0, exp_count :307768, averged returnover past 100 episodes : -19.37\n",
            "Episode : 293 , episodic length : 1483, return: -18.0, exp_count :309252, averged returnover past 100 episodes : -19.35\n",
            "Q loss: 0.0015725003322586417\n",
            "Episode : 294 , episodic length : 1199, return: -21.0, exp_count :310452, averged returnover past 100 episodes : -19.36\n",
            "Episode : 295 , episodic length : 1605, return: -19.0, exp_count :312058, averged returnover past 100 episodes : -19.35\n",
            "Episode : 296 , episodic length : 1160, return: -20.0, exp_count :313219, averged returnover past 100 episodes : -19.35\n",
            "Q loss: 0.0025588900316506624\n",
            "Episode : 297 , episodic length : 1415, return: -20.0, exp_count :314635, averged returnover past 100 episodes : -19.36\n",
            "Episode : 298 , episodic length : 1503, return: -19.0, exp_count :316139, averged returnover past 100 episodes : -19.35\n",
            "Episode : 299 , episodic length : 1687, return: -20.0, exp_count :317827, averged returnover past 100 episodes : -19.34\n",
            "-----start Testing------\n",
            "Testing result, Returns: [-21. -21. -20. -21. -21. -20. -20. -21. -20. -20. -20. -20. -20. -21.\n",
            " -21.]\n",
            "Q loss: 0.0017327836249023676\n",
            "Episode : 300 , episodic length : 1398, return: -20.0, exp_count :319226, averged returnover past 100 episodes : -19.34\n",
            "Episode : 301 , episodic length : 1269, return: -20.0, exp_count :320496, averged returnover past 100 episodes : -19.34\n",
            "Episode : 302 , episodic length : 1418, return: -17.0, exp_count :321915, averged returnover past 100 episodes : -19.3\n",
            "Q loss: 0.004948423244059086\n",
            "Episode : 303 , episodic length : 2135, return: -12.0, exp_count :324051, averged returnover past 100 episodes : -19.21\n",
            "Episode : 304 , episodic length : 1625, return: -17.0, exp_count :325677, averged returnover past 100 episodes : -19.2\n",
            "Q loss: 0.00251645315438509\n",
            "Episode : 305 , episodic length : 1406, return: -20.0, exp_count :327084, averged returnover past 100 episodes : -19.23\n",
            "Episode : 306 , episodic length : 1596, return: -18.0, exp_count :328681, averged returnover past 100 episodes : -19.2\n",
            "Q loss: 0.0023386464454233646\n",
            "Episode : 307 , episodic length : 1837, return: -15.0, exp_count :330519, averged returnover past 100 episodes : -19.15\n",
            "Episode : 308 , episodic length : 1435, return: -21.0, exp_count :331955, averged returnover past 100 episodes : -19.15\n",
            "Episode : 309 , episodic length : 1287, return: -20.0, exp_count :333243, averged returnover past 100 episodes : -19.15\n",
            "Q loss: 0.0032165891025215387\n",
            "Episode : 310 , episodic length : 1419, return: -18.0, exp_count :334663, averged returnover past 100 episodes : -19.13\n",
            "Episode : 311 , episodic length : 1860, return: -18.0, exp_count :336524, averged returnover past 100 episodes : -19.11\n",
            "Q loss: 0.0016091109719127417\n",
            "Episode : 312 , episodic length : 1738, return: -19.0, exp_count :338263, averged returnover past 100 episodes : -19.09\n",
            "Episode : 313 , episodic length : 1291, return: -20.0, exp_count :339555, averged returnover past 100 episodes : -19.09\n",
            "Episode : 314 , episodic length : 1402, return: -18.0, exp_count :340958, averged returnover past 100 episodes : -19.08\n",
            "Q loss: 0.0015152879059314728\n",
            "Episode : 315 , episodic length : 1433, return: -20.0, exp_count :342392, averged returnover past 100 episodes : -19.09\n",
            "Episode : 316 , episodic length : 1610, return: -18.0, exp_count :344003, averged returnover past 100 episodes : -19.08\n",
            "Episode : 317 , episodic length : 1514, return: -17.0, exp_count :345518, averged returnover past 100 episodes : -19.07\n",
            "Q loss: 0.0009209051495417953\n",
            "Episode : 318 , episodic length : 1360, return: -19.0, exp_count :346879, averged returnover past 100 episodes : -19.07\n",
            "Episode : 319 , episodic length : 1353, return: -19.0, exp_count :348233, averged returnover past 100 episodes : -19.07\n",
            "Episode : 320 , episodic length : 1416, return: -21.0, exp_count :349650, averged returnover past 100 episodes : -19.07\n",
            "Q loss: 0.0028295235242694616\n",
            "Episode : 321 , episodic length : 1501, return: -19.0, exp_count :351152, averged returnover past 100 episodes : -19.06\n",
            "Episode : 322 , episodic length : 1902, return: -18.0, exp_count :353055, averged returnover past 100 episodes : -19.04\n",
            "Q loss: 0.00215148669667542\n",
            "Episode : 323 , episodic length : 1300, return: -19.0, exp_count :354356, averged returnover past 100 episodes : -19.02\n",
            "Episode : 324 , episodic length : 1361, return: -20.0, exp_count :355718, averged returnover past 100 episodes : -19.02\n",
            "Episode : 325 , episodic length : 1719, return: -16.0, exp_count :357438, averged returnover past 100 episodes : -18.99\n",
            "Q loss: 0.0025083189830183983\n",
            "Episode : 326 , episodic length : 1724, return: -18.0, exp_count :359163, averged returnover past 100 episodes : -18.99\n",
            "Episode : 327 , episodic length : 1360, return: -17.0, exp_count :360524, averged returnover past 100 episodes : -18.97\n",
            "Q loss: 0.005436969920992851\n",
            "Episode : 328 , episodic length : 1748, return: -18.0, exp_count :362273, averged returnover past 100 episodes : -18.96\n",
            "Episode : 329 , episodic length : 1644, return: -20.0, exp_count :363918, averged returnover past 100 episodes : -18.99\n",
            "Episode : 330 , episodic length : 1541, return: -19.0, exp_count :365460, averged returnover past 100 episodes : -19.0\n",
            "Q loss: 0.002821700181812048\n",
            "Episode : 331 , episodic length : 1810, return: -19.0, exp_count :367271, averged returnover past 100 episodes : -19.01\n",
            "Episode : 332 , episodic length : 2150, return: -16.0, exp_count :369422, averged returnover past 100 episodes : -18.98\n",
            "Q loss: 0.004329272545874119\n",
            "Episode : 333 , episodic length : 1414, return: -19.0, exp_count :370837, averged returnover past 100 episodes : -18.98\n",
            "Episode : 334 , episodic length : 1885, return: -17.0, exp_count :372723, averged returnover past 100 episodes : -18.94\n",
            "Q loss: 0.003098796121776104\n",
            "Episode : 335 , episodic length : 1981, return: -18.0, exp_count :374705, averged returnover past 100 episodes : -18.92\n",
            "Episode : 336 , episodic length : 1971, return: -15.0, exp_count :376677, averged returnover past 100 episodes : -18.88\n",
            "Q loss: 0.0018803387647494674\n",
            "Episode : 337 , episodic length : 1389, return: -19.0, exp_count :378067, averged returnover past 100 episodes : -18.87\n",
            "Episode : 338 , episodic length : 1579, return: -20.0, exp_count :379647, averged returnover past 100 episodes : -18.88\n",
            "Episode : 339 , episodic length : 1814, return: -20.0, exp_count :381462, averged returnover past 100 episodes : -18.87\n",
            "Q loss: 0.005540837068110704\n",
            "Episode : 340 , episodic length : 1787, return: -19.0, exp_count :383250, averged returnover past 100 episodes : -18.86\n",
            "Episode : 341 , episodic length : 1351, return: -20.0, exp_count :384602, averged returnover past 100 episodes : -18.85\n",
            "Q loss: 0.020890068262815475\n",
            "Episode : 342 , episodic length : 1688, return: -19.0, exp_count :386291, averged returnover past 100 episodes : -18.86\n",
            "Episode : 343 , episodic length : 1615, return: -19.0, exp_count :387907, averged returnover past 100 episodes : -18.85\n",
            "Episode : 344 , episodic length : 1573, return: -18.0, exp_count :389481, averged returnover past 100 episodes : -18.83\n",
            "Q loss: 0.0033426580484956503\n",
            "Episode : 345 , episodic length : 1619, return: -19.0, exp_count :391101, averged returnover past 100 episodes : -18.84\n",
            "Episode : 346 , episodic length : 2117, return: -16.0, exp_count :393219, averged returnover past 100 episodes : -18.82\n",
            "Q loss: 0.00485906982794404\n",
            "Episode : 347 , episodic length : 1623, return: -18.0, exp_count :394843, averged returnover past 100 episodes : -18.8\n",
            "Episode : 348 , episodic length : 1434, return: -20.0, exp_count :396278, averged returnover past 100 episodes : -18.82\n",
            "Q loss: 0.004267221782356501\n",
            "Episode : 349 , episodic length : 1897, return: -17.0, exp_count :398176, averged returnover past 100 episodes : -18.81\n",
            "Episode : 350 , episodic length : 1724, return: -16.0, exp_count :399901, averged returnover past 100 episodes : -18.77\n",
            "Episode : 351 , episodic length : 1510, return: -19.0, exp_count :401412, averged returnover past 100 episodes : -18.76\n",
            "Q loss: 0.0026997425593435764\n",
            "Episode : 352 , episodic length : 1810, return: -17.0, exp_count :403223, averged returnover past 100 episodes : -18.75\n",
            "Episode : 353 , episodic length : 1725, return: -17.0, exp_count :404949, averged returnover past 100 episodes : -18.73\n",
            "Q loss: 0.0017452911706641316\n",
            "Episode : 354 , episodic length : 1656, return: -17.0, exp_count :406606, averged returnover past 100 episodes : -18.7\n",
            "Episode : 355 , episodic length : 1881, return: -17.0, exp_count :408488, averged returnover past 100 episodes : -18.66\n",
            "Q loss: 0.01162300631403923\n",
            "Episode : 356 , episodic length : 2150, return: -17.0, exp_count :410639, averged returnover past 100 episodes : -18.63\n",
            "Episode : 357 , episodic length : 1917, return: -18.0, exp_count :412557, averged returnover past 100 episodes : -18.63\n",
            "Q loss: 0.004176391288638115\n",
            "Episode : 358 , episodic length : 1907, return: -19.0, exp_count :414465, averged returnover past 100 episodes : -18.64\n",
            "Episode : 359 , episodic length : 2110, return: -15.0, exp_count :416576, averged returnover past 100 episodes : -18.58\n",
            "Q loss: 0.00361102307215333\n",
            "Episode : 360 , episodic length : 2097, return: -17.0, exp_count :418674, averged returnover past 100 episodes : -18.55\n",
            "Episode : 361 , episodic length : 1662, return: -17.0, exp_count :420337, averged returnover past 100 episodes : -18.53\n",
            "Q loss: 0.004717017058283091\n",
            "Episode : 362 , episodic length : 1878, return: -13.0, exp_count :422216, averged returnover past 100 episodes : -18.45\n",
            "Episode : 363 , episodic length : 1875, return: -18.0, exp_count :424092, averged returnover past 100 episodes : -18.44\n",
            "Episode : 364 , episodic length : 1766, return: -17.0, exp_count :425859, averged returnover past 100 episodes : -18.41\n",
            "Q loss: 0.0016698789549991488\n",
            "Episode : 365 , episodic length : 1497, return: -16.0, exp_count :427357, averged returnover past 100 episodes : -18.42\n",
            "Episode : 366 , episodic length : 1789, return: -18.0, exp_count :429147, averged returnover past 100 episodes : -18.4\n",
            "Q loss: 0.004747957922518253\n",
            "Episode : 367 , episodic length : 1410, return: -18.0, exp_count :430558, averged returnover past 100 episodes : -18.38\n",
            "Episode : 368 , episodic length : 1658, return: -18.0, exp_count :432217, averged returnover past 100 episodes : -18.36\n",
            "Episode : 369 , episodic length : 1591, return: -17.0, exp_count :433809, averged returnover past 100 episodes : -18.33\n",
            "Q loss: 0.004536151885986328\n",
            "Episode : 370 , episodic length : 2402, return: -12.0, exp_count :436212, averged returnover past 100 episodes : -18.27\n",
            "Q loss: 0.0028106458485126495\n",
            "Episode : 371 , episodic length : 1868, return: -20.0, exp_count :438081, averged returnover past 100 episodes : -18.3\n",
            "Episode : 372 , episodic length : 1762, return: -21.0, exp_count :439844, averged returnover past 100 episodes : -18.3\n",
            "Episode : 373 , episodic length : 1799, return: -17.0, exp_count :441644, averged returnover past 100 episodes : -18.29\n",
            "Q loss: 0.00529772974550724\n",
            "Episode : 374 , episodic length : 1948, return: -19.0, exp_count :443593, averged returnover past 100 episodes : -18.29\n",
            "Episode : 375 , episodic length : 2146, return: -17.0, exp_count :445740, averged returnover past 100 episodes : -18.27\n",
            "Q loss: 0.0058455877006053925\n",
            "Episode : 376 , episodic length : 1832, return: -15.0, exp_count :447573, averged returnover past 100 episodes : -18.21\n",
            "Episode : 377 , episodic length : 1753, return: -20.0, exp_count :449327, averged returnover past 100 episodes : -18.23\n",
            "Q loss: 0.0007667504833079875\n",
            "Episode : 378 , episodic length : 2154, return: -12.0, exp_count :451482, averged returnover past 100 episodes : -18.21\n",
            "Episode : 379 , episodic length : 2444, return: -14.0, exp_count :453927, averged returnover past 100 episodes : -18.17\n",
            "Q loss: 0.0046844482421875\n",
            "Episode : 380 , episodic length : 2032, return: -18.0, exp_count :455960, averged returnover past 100 episodes : -18.15\n",
            "Q loss: 0.001957190688699484\n",
            "Episode : 381 , episodic length : 2212, return: -17.0, exp_count :458173, averged returnover past 100 episodes : -18.12\n",
            "Episode : 382 , episodic length : 1898, return: -18.0, exp_count :460072, averged returnover past 100 episodes : -18.12\n",
            "Q loss: 0.0039055885281413794\n",
            "Episode : 383 , episodic length : 2275, return: -13.0, exp_count :462348, averged returnover past 100 episodes : -18.08\n",
            "Episode : 384 , episodic length : 1766, return: -19.0, exp_count :464115, averged returnover past 100 episodes : -18.08\n",
            "Q loss: 0.0029209479689598083\n",
            "Episode : 385 , episodic length : 1922, return: -18.0, exp_count :466038, averged returnover past 100 episodes : -18.06\n",
            "Episode : 386 , episodic length : 2093, return: -16.0, exp_count :468132, averged returnover past 100 episodes : -18.02\n",
            "Q loss: 0.006033867597579956\n",
            "Episode : 387 , episodic length : 1931, return: -16.0, exp_count :470064, averged returnover past 100 episodes : -17.97\n",
            "Episode : 388 , episodic length : 2319, return: -16.0, exp_count :472384, averged returnover past 100 episodes : -17.92\n",
            "Q loss: 0.012739529833197594\n",
            "Episode : 389 , episodic length : 1929, return: -16.0, exp_count :474314, averged returnover past 100 episodes : -17.88\n",
            "Episode : 390 , episodic length : 2443, return: -13.0, exp_count :476758, averged returnover past 100 episodes : -17.82\n",
            "Q loss: 0.002565189730376005\n",
            "Episode : 391 , episodic length : 2549, return: -14.0, exp_count :479308, averged returnover past 100 episodes : -17.77\n",
            "Episode : 392 , episodic length : 1841, return: -16.0, exp_count :481150, averged returnover past 100 episodes : -17.74\n",
            "Q loss: 0.003848544554784894\n",
            "Episode : 393 , episodic length : 2214, return: -14.0, exp_count :483365, averged returnover past 100 episodes : -17.7\n",
            "Episode : 394 , episodic length : 2251, return: -14.0, exp_count :485617, averged returnover past 100 episodes : -17.63\n",
            "Q loss: 0.0019752327352762222\n",
            "Episode : 395 , episodic length : 2854, return: -13.0, exp_count :488472, averged returnover past 100 episodes : -17.57\n",
            "Q loss: 0.0018850688356906176\n",
            "Episode : 396 , episodic length : 2145, return: -13.0, exp_count :490618, averged returnover past 100 episodes : -17.5\n",
            "Episode : 397 , episodic length : 2163, return: -13.0, exp_count :492782, averged returnover past 100 episodes : -17.43\n",
            "Q loss: 0.005121335387229919\n",
            "Episode : 398 , episodic length : 1782, return: -16.0, exp_count :494565, averged returnover past 100 episodes : -17.4\n",
            "Episode : 399 , episodic length : 1896, return: -16.0, exp_count :496462, averged returnover past 100 episodes : -17.36\n",
            "-----start Testing------\n",
            "Testing result, Returns: [-14. -18. -14.  -5. -14. -18. -18.  -5. -14. -18. -14. -14.  -5. -14.\n",
            " -14.]\n",
            "Q loss: 0.002606977242976427\n",
            "Episode : 400 , episodic length : 2114, return: -11.0, exp_count :498577, averged returnover past 100 episodes : -17.27\n",
            "Episode : 401 , episodic length : 2573, return: -11.0, exp_count :501151, averged returnover past 100 episodes : -17.18\n",
            "Q loss: 0.0014710270334035158\n",
            "Episode : 402 , episodic length : 2048, return: -17.0, exp_count :503200, averged returnover past 100 episodes : -17.18\n",
            "Episode : 403 , episodic length : 1691, return: -17.0, exp_count :504892, averged returnover past 100 episodes : -17.23\n",
            "Q loss: 0.0012164893560111523\n",
            "Episode : 404 , episodic length : 2150, return: -16.0, exp_count :507043, averged returnover past 100 episodes : -17.22\n",
            "Episode : 405 , episodic length : 1972, return: -17.0, exp_count :509016, averged returnover past 100 episodes : -17.19\n",
            "Q loss: 0.004503039643168449\n",
            "Episode : 406 , episodic length : 1874, return: -16.0, exp_count :510891, averged returnover past 100 episodes : -17.17\n",
            "Episode : 407 , episodic length : 2402, return: -12.0, exp_count :513294, averged returnover past 100 episodes : -17.14\n",
            "Q loss: 0.00415223091840744\n",
            "Episode : 408 , episodic length : 2186, return: -16.0, exp_count :515481, averged returnover past 100 episodes : -17.09\n",
            "Episode : 409 , episodic length : 2172, return: -13.0, exp_count :517654, averged returnover past 100 episodes : -17.02\n",
            "Q loss: 0.0022572437301278114\n",
            "Episode : 410 , episodic length : 2071, return: -12.0, exp_count :519726, averged returnover past 100 episodes : -16.96\n",
            "Episode : 411 , episodic length : 2106, return: -15.0, exp_count :521833, averged returnover past 100 episodes : -16.93\n",
            "Q loss: 0.011119605973362923\n",
            "Episode : 412 , episodic length : 2189, return: -18.0, exp_count :524023, averged returnover past 100 episodes : -16.92\n",
            "Q loss: 0.012266261503100395\n",
            "Episode : 413 , episodic length : 2412, return: -14.0, exp_count :526436, averged returnover past 100 episodes : -16.86\n",
            "Episode : 414 , episodic length : 2551, return: -9.0, exp_count :528988, averged returnover past 100 episodes : -16.77\n",
            "Q loss: 0.0018250151770189404\n",
            "Episode : 415 , episodic length : 2265, return: -13.0, exp_count :531254, averged returnover past 100 episodes : -16.7\n",
            "Episode : 416 , episodic length : 1680, return: -18.0, exp_count :532935, averged returnover past 100 episodes : -16.7\n",
            "Q loss: 0.007347955368459225\n",
            "Episode : 417 , episodic length : 2357, return: -12.0, exp_count :535293, averged returnover past 100 episodes : -16.65\n",
            "Episode : 418 , episodic length : 1315, return: -20.0, exp_count :536609, averged returnover past 100 episodes : -16.66\n",
            "Q loss: 0.00485068466514349\n",
            "Episode : 419 , episodic length : 2271, return: -10.0, exp_count :538881, averged returnover past 100 episodes : -16.57\n",
            "Episode : 420 , episodic length : 2451, return: -10.0, exp_count :541333, averged returnover past 100 episodes : -16.46\n",
            "Q loss: 0.005155694670975208\n",
            "Episode : 421 , episodic length : 1731, return: -17.0, exp_count :543065, averged returnover past 100 episodes : -16.44\n",
            "Episode : 422 , episodic length : 1611, return: -16.0, exp_count :544677, averged returnover past 100 episodes : -16.42\n",
            "Q loss: 0.003887489903718233\n",
            "Episode : 423 , episodic length : 1844, return: -16.0, exp_count :546522, averged returnover past 100 episodes : -16.39\n",
            "Episode : 424 , episodic length : 2586, return: -12.0, exp_count :549109, averged returnover past 100 episodes : -16.31\n",
            "Q loss: 0.00831788033246994\n",
            "Episode : 425 , episodic length : 1834, return: -16.0, exp_count :550944, averged returnover past 100 episodes : -16.31\n",
            "Episode : 426 , episodic length : 1851, return: -16.0, exp_count :552796, averged returnover past 100 episodes : -16.29\n",
            "Q loss: 0.006862339098006487\n",
            "Episode : 427 , episodic length : 2198, return: -14.0, exp_count :554995, averged returnover past 100 episodes : -16.26\n",
            "Episode : 428 , episodic length : 2434, return: -8.0, exp_count :557430, averged returnover past 100 episodes : -16.16\n",
            "Q loss: 0.00992222223430872\n",
            "Episode : 429 , episodic length : 1745, return: -20.0, exp_count :559176, averged returnover past 100 episodes : -16.16\n",
            "Episode : 430 , episodic length : 2285, return: -12.0, exp_count :561462, averged returnover past 100 episodes : -16.09\n",
            "Q loss: 0.010049186646938324\n",
            "Episode : 431 , episodic length : 2006, return: -14.0, exp_count :563469, averged returnover past 100 episodes : -16.04\n",
            "Episode : 432 , episodic length : 2337, return: -12.0, exp_count :565807, averged returnover past 100 episodes : -16.0\n",
            "Q loss: 0.005400999914854765\n",
            "Episode : 433 , episodic length : 2129, return: -11.0, exp_count :567937, averged returnover past 100 episodes : -15.92\n",
            "Episode : 434 , episodic length : 1637, return: -19.0, exp_count :569575, averged returnover past 100 episodes : -15.94\n",
            "Q loss: 0.002205014694482088\n",
            "Episode : 435 , episodic length : 2255, return: -13.0, exp_count :571831, averged returnover past 100 episodes : -15.89\n",
            "Episode : 436 , episodic length : 1510, return: -20.0, exp_count :573342, averged returnover past 100 episodes : -15.94\n",
            "Q loss: 0.0025036553852260113\n",
            "Episode : 437 , episodic length : 1692, return: -17.0, exp_count :575035, averged returnover past 100 episodes : -15.92\n",
            "Episode : 438 , episodic length : 1555, return: -19.0, exp_count :576591, averged returnover past 100 episodes : -15.91\n",
            "Q loss: 0.006560267880558968\n",
            "Episode : 439 , episodic length : 2111, return: -14.0, exp_count :578703, averged returnover past 100 episodes : -15.85\n",
            "Episode : 440 , episodic length : 2092, return: -15.0, exp_count :580796, averged returnover past 100 episodes : -15.81\n",
            "Q loss: 0.006904195994138718\n",
            "Episode : 441 , episodic length : 1521, return: -19.0, exp_count :582318, averged returnover past 100 episodes : -15.8\n",
            "Episode : 442 , episodic length : 1925, return: -14.0, exp_count :584244, averged returnover past 100 episodes : -15.75\n",
            "Episode : 443 , episodic length : 1719, return: -17.0, exp_count :585964, averged returnover past 100 episodes : -15.73\n",
            "Q loss: 0.013747738674283028\n",
            "Episode : 444 , episodic length : 2255, return: -13.0, exp_count :588220, averged returnover past 100 episodes : -15.68\n",
            "Q loss: 0.008013132959604263\n",
            "Episode : 445 , episodic length : 2053, return: -15.0, exp_count :590274, averged returnover past 100 episodes : -15.64\n",
            "Episode : 446 , episodic length : 2840, return: -8.0, exp_count :593115, averged returnover past 100 episodes : -15.56\n",
            "Q loss: 0.0034646897111088037\n",
            "Episode : 447 , episodic length : 1806, return: -14.0, exp_count :594922, averged returnover past 100 episodes : -15.52\n",
            "Episode : 448 , episodic length : 2842, return: -9.0, exp_count :597765, averged returnover past 100 episodes : -15.41\n",
            "Q loss: 0.002749653998762369\n",
            "Episode : 449 , episodic length : 1593, return: -18.0, exp_count :599359, averged returnover past 100 episodes : -15.42\n",
            "Episode : 450 , episodic length : 1849, return: -14.0, exp_count :601209, averged returnover past 100 episodes : -15.4\n",
            "Q loss: 0.0060785748064517975\n",
            "Episode : 451 , episodic length : 1516, return: -19.0, exp_count :602726, averged returnover past 100 episodes : -15.4\n",
            "Episode : 452 , episodic length : 1652, return: -17.0, exp_count :604379, averged returnover past 100 episodes : -15.4\n",
            "Q loss: 0.028778111562132835\n",
            "Episode : 453 , episodic length : 2612, return: -11.0, exp_count :606992, averged returnover past 100 episodes : -15.34\n",
            "Episode : 454 , episodic length : 2369, return: -9.0, exp_count :609362, averged returnover past 100 episodes : -15.26\n",
            "Q loss: 0.003507679095491767\n",
            "Episode : 455 , episodic length : 1649, return: -18.0, exp_count :611012, averged returnover past 100 episodes : -15.27\n",
            "Episode : 456 , episodic length : 2620, return: -8.0, exp_count :613633, averged returnover past 100 episodes : -15.18\n",
            "Q loss: 0.003409211291000247\n",
            "Episode : 457 , episodic length : 1593, return: -18.0, exp_count :615227, averged returnover past 100 episodes : -15.18\n",
            "Episode : 458 , episodic length : 2450, return: -11.0, exp_count :617678, averged returnover past 100 episodes : -15.1\n",
            "Q loss: 0.00484685692936182\n",
            "Episode : 459 , episodic length : 1953, return: -14.0, exp_count :619632, averged returnover past 100 episodes : -15.09\n",
            "Q loss: 0.004660138860344887\n",
            "Episode : 460 , episodic length : 2658, return: -7.0, exp_count :622291, averged returnover past 100 episodes : -14.99\n",
            "Episode : 461 , episodic length : 2045, return: -14.0, exp_count :624337, averged returnover past 100 episodes : -14.96\n",
            "Q loss: 0.002957245334982872\n",
            "Episode : 462 , episodic length : 1858, return: -13.0, exp_count :626196, averged returnover past 100 episodes : -14.96\n",
            "Episode : 463 , episodic length : 1783, return: -14.0, exp_count :627980, averged returnover past 100 episodes : -14.92\n",
            "Episode : 464 , episodic length : 975, return: -20.0, exp_count :628956, averged returnover past 100 episodes : -14.95\n",
            "Q loss: 0.0028463611379265785\n",
            "Episode : 465 , episodic length : 1226, return: -18.0, exp_count :630183, averged returnover past 100 episodes : -14.97\n",
            "Episode : 466 , episodic length : 1456, return: -18.0, exp_count :631640, averged returnover past 100 episodes : -14.97\n",
            "Episode : 467 , episodic length : 1811, return: -18.0, exp_count :633452, averged returnover past 100 episodes : -14.97\n",
            "Q loss: 0.002321519423276186\n",
            "Episode : 468 , episodic length : 2072, return: -16.0, exp_count :635525, averged returnover past 100 episodes : -14.95\n",
            "Episode : 469 , episodic length : 2239, return: -15.0, exp_count :637765, averged returnover past 100 episodes : -14.93\n",
            "Q loss: 0.012600301764905453\n",
            "Episode : 470 , episodic length : 2131, return: -13.0, exp_count :639897, averged returnover past 100 episodes : -14.94\n",
            "Q loss: 0.0023524530697613955\n",
            "Episode : 471 , episodic length : 2495, return: -9.0, exp_count :642393, averged returnover past 100 episodes : -14.83\n",
            "Episode : 472 , episodic length : 2051, return: -16.0, exp_count :644445, averged returnover past 100 episodes : -14.78\n",
            "Q loss: 0.003490082686766982\n",
            "Episode : 473 , episodic length : 2237, return: -13.0, exp_count :646683, averged returnover past 100 episodes : -14.74\n",
            "Episode : 474 , episodic length : 2101, return: -12.0, exp_count :648785, averged returnover past 100 episodes : -14.67\n",
            "Q loss: 0.0010833601700142026\n",
            "Episode : 475 , episodic length : 1996, return: -17.0, exp_count :650782, averged returnover past 100 episodes : -14.67\n",
            "Q loss: 0.004793922882527113\n",
            "Episode : 476 , episodic length : 3461, return: -3.0, exp_count :654244, averged returnover past 100 episodes : -14.55\n",
            "Episode : 477 , episodic length : 1398, return: -20.0, exp_count :655643, averged returnover past 100 episodes : -14.55\n",
            "Episode : 478 , episodic length : 1756, return: -18.0, exp_count :657400, averged returnover past 100 episodes : -14.61\n",
            "Q loss: 0.003818137338384986\n",
            "Episode : 479 , episodic length : 2443, return: -9.0, exp_count :659844, averged returnover past 100 episodes : -14.56\n",
            "Q loss: 0.0018515769625082612\n",
            "Episode : 480 , episodic length : 2384, return: -9.0, exp_count :662229, averged returnover past 100 episodes : -14.47\n",
            "Episode : 481 , episodic length : 1860, return: -16.0, exp_count :664090, averged returnover past 100 episodes : -14.46\n",
            "Episode : 482 , episodic length : 1558, return: -17.0, exp_count :665649, averged returnover past 100 episodes : -14.45\n",
            "Q loss: 0.0023831052239984274\n",
            "Episode : 483 , episodic length : 2848, return: -11.0, exp_count :668498, averged returnover past 100 episodes : -14.43\n",
            "Q loss: 0.004986957646906376\n",
            "Episode : 484 , episodic length : 2893, return: -10.0, exp_count :671392, averged returnover past 100 episodes : -14.34\n",
            "Episode : 485 , episodic length : 2311, return: -15.0, exp_count :673704, averged returnover past 100 episodes : -14.31\n",
            "Q loss: 0.0023599015548825264\n",
            "Episode : 486 , episodic length : 2008, return: -18.0, exp_count :675713, averged returnover past 100 episodes : -14.33\n",
            "Q loss: 0.0009827285539358854\n",
            "Episode : 487 , episodic length : 2836, return: -7.0, exp_count :678550, averged returnover past 100 episodes : -14.24\n",
            "Episode : 488 , episodic length : 2776, return: -3.0, exp_count :681327, averged returnover past 100 episodes : -14.11\n",
            "Q loss: 0.004099489189684391\n",
            "Episode : 489 , episodic length : 2642, return: -11.0, exp_count :683970, averged returnover past 100 episodes : -14.06\n",
            "Q loss: 0.006761442869901657\n",
            "Episode : 490 , episodic length : 3043, return: -10.0, exp_count :687014, averged returnover past 100 episodes : -14.03\n",
            "Q loss: 0.0021155639551579952\n",
            "Episode : 491 , episodic length : 3328, return: -2.0, exp_count :690343, averged returnover past 100 episodes : -13.91\n",
            "Episode : 492 , episodic length : 2663, return: -8.0, exp_count :693007, averged returnover past 100 episodes : -13.83\n",
            "Q loss: 0.006131004076451063\n",
            "Episode : 493 , episodic length : 2122, return: -13.0, exp_count :695130, averged returnover past 100 episodes : -13.82\n",
            "Episode : 494 , episodic length : 2622, return: -12.0, exp_count :697753, averged returnover past 100 episodes : -13.8\n",
            "Q loss: 0.0024888156913220882\n",
            "Episode : 495 , episodic length : 1874, return: -12.0, exp_count :699628, averged returnover past 100 episodes : -13.79\n",
            "Q loss: 0.0013320056023076177\n",
            "Episode : 496 , episodic length : 2403, return: -13.0, exp_count :702032, averged returnover past 100 episodes : -13.79\n",
            "Episode : 497 , episodic length : 2992, return: -9.0, exp_count :705025, averged returnover past 100 episodes : -13.75\n",
            "Q loss: 0.0040916381403803825\n",
            "Episode : 498 , episodic length : 3029, return: -5.0, exp_count :708055, averged returnover past 100 episodes : -13.64\n",
            "Q loss: 0.002509526675567031\n",
            "Episode : 499 , episodic length : 2813, return: -8.0, exp_count :710869, averged returnover past 100 episodes : -13.56\n",
            "-----start Testing------\n",
            "Testing result, Returns: [  2.   2.   4. -18. -16. -19.  -8.  -8. -18. -19. -18.  -8.  -8. -19.\n",
            " -19.]\n",
            "Episode : 500 , episodic length : 2496, return: -13.0, exp_count :713366, averged returnover past 100 episodes : -13.58\n",
            "Q loss: 0.005860878620296717\n",
            "Episode : 501 , episodic length : 2122, return: -14.0, exp_count :715489, averged returnover past 100 episodes : -13.61\n",
            "Episode : 502 , episodic length : 2398, return: -14.0, exp_count :717888, averged returnover past 100 episodes : -13.58\n",
            "Q loss: 0.004032772034406662\n",
            "Episode : 503 , episodic length : 2138, return: -14.0, exp_count :720027, averged returnover past 100 episodes : -13.55\n",
            "Q loss: 0.0019245254807174206\n",
            "Episode : 504 , episodic length : 2647, return: -13.0, exp_count :722675, averged returnover past 100 episodes : -13.52\n",
            "Episode : 505 , episodic length : 2780, return: -11.0, exp_count :725456, averged returnover past 100 episodes : -13.46\n",
            "Q loss: 0.0029724137857556343\n",
            "Episode : 506 , episodic length : 2384, return: -12.0, exp_count :727841, averged returnover past 100 episodes : -13.42\n",
            "Q loss: 0.00284669641405344\n",
            "Episode : 507 , episodic length : 2625, return: -11.0, exp_count :730467, averged returnover past 100 episodes : -13.41\n",
            "Episode : 508 , episodic length : 2466, return: -9.0, exp_count :732934, averged returnover past 100 episodes : -13.34\n",
            "Q loss: 0.008468253538012505\n",
            "Episode : 509 , episodic length : 2611, return: -7.0, exp_count :735546, averged returnover past 100 episodes : -13.28\n",
            "Episode : 510 , episodic length : 2304, return: -12.0, exp_count :737851, averged returnover past 100 episodes : -13.28\n",
            "Q loss: 0.0009175714221782982\n",
            "Episode : 511 , episodic length : 2437, return: -11.0, exp_count :740289, averged returnover past 100 episodes : -13.24\n",
            "Q loss: 0.0021642190404236317\n",
            "Episode : 512 , episodic length : 2859, return: -10.0, exp_count :743149, averged returnover past 100 episodes : -13.16\n",
            "Episode : 513 , episodic length : 1738, return: -15.0, exp_count :744888, averged returnover past 100 episodes : -13.17\n",
            "Q loss: 0.0017480768729001284\n",
            "Episode : 514 , episodic length : 2645, return: -8.0, exp_count :747534, averged returnover past 100 episodes : -13.16\n",
            "Q loss: 0.0018212184077128768\n",
            "Episode : 515 , episodic length : 2589, return: -10.0, exp_count :750124, averged returnover past 100 episodes : -13.13\n",
            "Episode : 516 , episodic length : 3524, return: -5.0, exp_count :753649, averged returnover past 100 episodes : -13.0\n",
            "Q loss: 0.0019163871183991432\n",
            "Episode : 517 , episodic length : 2532, return: -7.0, exp_count :756182, averged returnover past 100 episodes : -12.95\n",
            "Q loss: 0.0042997682467103004\n",
            "Episode : 518 , episodic length : 2479, return: -11.0, exp_count :758662, averged returnover past 100 episodes : -12.86\n",
            "Episode : 519 , episodic length : 2331, return: -14.0, exp_count :760994, averged returnover past 100 episodes : -12.9\n",
            "Q loss: 0.005040372721850872\n",
            "Episode : 520 , episodic length : 2793, return: -11.0, exp_count :763788, averged returnover past 100 episodes : -12.91\n",
            "Q loss: 0.001968895550817251\n",
            "Episode : 521 , episodic length : 3390, return: -7.0, exp_count :767179, averged returnover past 100 episodes : -12.81\n",
            "Episode : 522 , episodic length : 2809, return: -8.0, exp_count :769989, averged returnover past 100 episodes : -12.73\n",
            "Q loss: 0.0037334319204092026\n",
            "Episode : 523 , episodic length : 3693, return: -2.0, exp_count :773683, averged returnover past 100 episodes : -12.59\n",
            "Q loss: 0.004591837991029024\n",
            "Episode : 524 , episodic length : 2713, return: -9.0, exp_count :776397, averged returnover past 100 episodes : -12.56\n",
            "Q loss: 0.0013893847353756428\n",
            "Episode : 525 , episodic length : 3310, return: -5.0, exp_count :779708, averged returnover past 100 episodes : -12.45\n",
            "Q loss: 0.005515190772712231\n",
            "Episode : 526 , episodic length : 2834, return: -8.0, exp_count :782543, averged returnover past 100 episodes : -12.37\n",
            "Episode : 527 , episodic length : 2684, return: -13.0, exp_count :785228, averged returnover past 100 episodes : -12.36\n",
            "Q loss: 0.0037497244775295258\n",
            "Episode : 528 , episodic length : 2971, return: -9.0, exp_count :788200, averged returnover past 100 episodes : -12.37\n",
            "Q loss: 0.006878534331917763\n",
            "Episode : 529 , episodic length : 3078, return: -8.0, exp_count :791279, averged returnover past 100 episodes : -12.25\n",
            "Q loss: 0.005836512427777052\n",
            "Episode : 530 , episodic length : 3017, return: -8.0, exp_count :794297, averged returnover past 100 episodes : -12.21\n",
            "Episode : 531 , episodic length : 2774, return: -9.0, exp_count :797072, averged returnover past 100 episodes : -12.16\n",
            "Q loss: 0.004967613145709038\n",
            "Episode : 532 , episodic length : 2796, return: -10.0, exp_count :799869, averged returnover past 100 episodes : -12.14\n",
            "Q loss: 0.004815609659999609\n",
            "Episode : 533 , episodic length : 2685, return: -10.0, exp_count :802555, averged returnover past 100 episodes : -12.13\n",
            "Episode : 534 , episodic length : 2084, return: -15.0, exp_count :804640, averged returnover past 100 episodes : -12.09\n",
            "Q loss: 0.0033356233034282923\n",
            "Episode : 535 , episodic length : 3108, return: -9.0, exp_count :807749, averged returnover past 100 episodes : -12.05\n",
            "Q loss: 0.001605090219527483\n",
            "Episode : 536 , episodic length : 3341, return: -9.0, exp_count :811091, averged returnover past 100 episodes : -11.94\n",
            "Episode : 537 , episodic length : 2737, return: -6.0, exp_count :813829, averged returnover past 100 episodes : -11.83\n",
            "Q loss: 0.0056077237240970135\n",
            "Episode : 538 , episodic length : 3354, return: -4.0, exp_count :817184, averged returnover past 100 episodes : -11.68\n",
            "Q loss: 0.001939459703862667\n",
            "Episode : 539 , episodic length : 2759, return: -6.0, exp_count :819944, averged returnover past 100 episodes : -11.6\n",
            "Q loss: 0.002016107551753521\n",
            "Episode : 540 , episodic length : 3416, return: -3.0, exp_count :823361, averged returnover past 100 episodes : -11.48\n",
            "Q loss: 0.008065568283200264\n",
            "Episode : 541 , episodic length : 2712, return: -7.0, exp_count :826074, averged returnover past 100 episodes : -11.36\n",
            "Episode : 542 , episodic length : 2825, return: -6.0, exp_count :828900, averged returnover past 100 episodes : -11.28\n",
            "Q loss: 0.0018714151810854673\n",
            "Episode : 543 , episodic length : 3388, return: -3.0, exp_count :832289, averged returnover past 100 episodes : -11.14\n",
            "Q loss: 0.00569755956530571\n",
            "Episode : 544 , episodic length : 3422, return: 3.0, exp_count :835712, averged returnover past 100 episodes : -10.98\n",
            "Q loss: 0.0020577218383550644\n",
            "Episode : 545 , episodic length : 3734, return: -4.0, exp_count :839447, averged returnover past 100 episodes : -10.87\n",
            "Q loss: 0.00121488596778363\n",
            "Episode : 546 , episodic length : 2869, return: -4.0, exp_count :842317, averged returnover past 100 episodes : -10.83\n",
            "Episode : 547 , episodic length : 3537, return: 1.0, exp_count :845855, averged returnover past 100 episodes : -10.68\n",
            "Q loss: 0.006221043411642313\n",
            "Episode : 548 , episodic length : 3245, return: 2.0, exp_count :849101, averged returnover past 100 episodes : -10.57\n",
            "Q loss: 0.003102784976363182\n",
            "Episode : 549 , episodic length : 3431, return: 2.0, exp_count :852533, averged returnover past 100 episodes : -10.37\n",
            "Q loss: 0.010153956711292267\n",
            "Episode : 550 , episodic length : 3327, return: 7.0, exp_count :855861, averged returnover past 100 episodes : -10.16\n",
            "Q loss: 0.008679728955030441\n",
            "Episode : 551 , episodic length : 3584, return: -4.0, exp_count :859446, averged returnover past 100 episodes : -10.01\n",
            "Q loss: 0.004087700974196196\n",
            "Episode : 552 , episodic length : 3094, return: -4.0, exp_count :862541, averged returnover past 100 episodes : -9.88\n",
            "Episode : 553 , episodic length : 2414, return: -9.0, exp_count :864956, averged returnover past 100 episodes : -9.86\n",
            "Q loss: 0.0038388646207749844\n",
            "Episode : 554 , episodic length : 3521, return: -2.0, exp_count :868478, averged returnover past 100 episodes : -9.79\n",
            "Q loss: 0.0036134892143309116\n",
            "Episode : 555 , episodic length : 3265, return: -5.0, exp_count :871744, averged returnover past 100 episodes : -9.66\n",
            "Q loss: 0.006545362062752247\n",
            "Episode : 556 , episodic length : 2423, return: -10.0, exp_count :874168, averged returnover past 100 episodes : -9.68\n",
            "Episode : 557 , episodic length : 2569, return: -10.0, exp_count :876738, averged returnover past 100 episodes : -9.6\n",
            "Q loss: 0.005076775327324867\n",
            "Episode : 558 , episodic length : 3832, return: -1.0, exp_count :880571, averged returnover past 100 episodes : -9.5\n",
            "Q loss: 0.001629569916985929\n",
            "Episode : 559 , episodic length : 2941, return: -11.0, exp_count :883513, averged returnover past 100 episodes : -9.47\n",
            "Q loss: 0.002482606330886483\n",
            "Episode : 560 , episodic length : 3194, return: -7.0, exp_count :886708, averged returnover past 100 episodes : -9.47\n",
            "Episode : 561 , episodic length : 2793, return: -4.0, exp_count :889502, averged returnover past 100 episodes : -9.37\n",
            "Q loss: 0.004132568836212158\n",
            "Episode : 562 , episodic length : 2447, return: -7.0, exp_count :891950, averged returnover past 100 episodes : -9.31\n",
            "Q loss: 0.013076290488243103\n",
            "Episode : 563 , episodic length : 3745, return: -2.0, exp_count :895696, averged returnover past 100 episodes : -9.19\n",
            "Q loss: 0.003032800741493702\n",
            "Episode : 564 , episodic length : 3094, return: -7.0, exp_count :898791, averged returnover past 100 episodes : -9.06\n",
            "Q loss: 0.005463829264044762\n",
            "Episode : 565 , episodic length : 3530, return: -3.0, exp_count :902322, averged returnover past 100 episodes : -8.91\n",
            "Episode : 566 , episodic length : 2408, return: -9.0, exp_count :904731, averged returnover past 100 episodes : -8.82\n",
            "Q loss: 0.0036004073917865753\n",
            "Episode : 567 , episodic length : 3590, return: -4.0, exp_count :908322, averged returnover past 100 episodes : -8.68\n",
            "Q loss: 0.007549606263637543\n",
            "Episode : 568 , episodic length : 3508, return: -2.0, exp_count :911831, averged returnover past 100 episodes : -8.54\n",
            "Q loss: 0.0011474551865831017\n",
            "Episode : 569 , episodic length : 3309, return: -7.0, exp_count :915141, averged returnover past 100 episodes : -8.46\n",
            "Q loss: 0.002650023903697729\n",
            "Episode : 570 , episodic length : 4095, return: 1.0, exp_count :919237, averged returnover past 100 episodes : -8.32\n",
            "Q loss: 0.004482252988964319\n",
            "Episode : 571 , episodic length : 3458, return: 5.0, exp_count :922696, averged returnover past 100 episodes : -8.18\n",
            "Episode : 572 , episodic length : 2874, return: -7.0, exp_count :925571, averged returnover past 100 episodes : -8.09\n",
            "Q loss: 0.002532130340114236\n",
            "Episode : 573 , episodic length : 3429, return: -4.0, exp_count :929001, averged returnover past 100 episodes : -8.0\n",
            "Q loss: 0.005805634893476963\n",
            "Episode : 574 , episodic length : 2969, return: -7.0, exp_count :931971, averged returnover past 100 episodes : -7.95\n",
            "Q loss: 0.0029564457945525646\n",
            "Episode : 575 , episodic length : 3307, return: -7.0, exp_count :935279, averged returnover past 100 episodes : -7.85\n",
            "Q loss: 0.008544012904167175\n",
            "Episode : 576 , episodic length : 3801, return: 2.0, exp_count :939081, averged returnover past 100 episodes : -7.8\n",
            "Q loss: 0.003652461338788271\n",
            "Episode : 577 , episodic length : 3166, return: 6.0, exp_count :942248, averged returnover past 100 episodes : -7.54\n",
            "Episode : 578 , episodic length : 3041, return: -7.0, exp_count :945290, averged returnover past 100 episodes : -7.43\n",
            "Q loss: 0.011560851708054543\n",
            "Episode : 579 , episodic length : 3124, return: 2.0, exp_count :948415, averged returnover past 100 episodes : -7.32\n",
            "Q loss: 0.0035925176925957203\n",
            "Episode : 580 , episodic length : 3484, return: -1.0, exp_count :951900, averged returnover past 100 episodes : -7.24\n",
            "Q loss: 0.002620808780193329\n",
            "Episode : 581 , episodic length : 3007, return: -3.0, exp_count :954908, averged returnover past 100 episodes : -7.11\n",
            "Episode : 582 , episodic length : 1892, return: -12.0, exp_count :956801, averged returnover past 100 episodes : -7.06\n",
            "Q loss: 0.0023237511049956083\n",
            "Episode : 583 , episodic length : 2879, return: -6.0, exp_count :959681, averged returnover past 100 episodes : -7.01\n",
            "Q loss: 0.0011055031791329384\n",
            "Episode : 584 , episodic length : 3590, return: -1.0, exp_count :963272, averged returnover past 100 episodes : -6.92\n",
            "Q loss: 0.0026912493631243706\n",
            "Episode : 585 , episodic length : 3773, return: 4.0, exp_count :967046, averged returnover past 100 episodes : -6.73\n",
            "Q loss: 0.0026497473008930683\n",
            "Episode : 586 , episodic length : 3542, return: -2.0, exp_count :970589, averged returnover past 100 episodes : -6.57\n",
            "Episode : 587 , episodic length : 3401, return: -9.0, exp_count :973991, averged returnover past 100 episodes : -6.59\n",
            "Q loss: 0.0027318529319018126\n",
            "Episode : 588 , episodic length : 1465, return: -16.0, exp_count :975457, averged returnover past 100 episodes : -6.72\n",
            "Q loss: 0.006845082622021437\n",
            "Episode : 589 , episodic length : 4129, return: 1.0, exp_count :979587, averged returnover past 100 episodes : -6.6\n",
            "Q loss: 0.0025070456322282553\n",
            "Episode : 590 , episodic length : 3886, return: 7.0, exp_count :983474, averged returnover past 100 episodes : -6.43\n",
            "Q loss: 0.007542037405073643\n",
            "Episode : 591 , episodic length : 3399, return: 7.0, exp_count :986874, averged returnover past 100 episodes : -6.34\n",
            "Episode : 592 , episodic length : 3033, return: 4.0, exp_count :989908, averged returnover past 100 episodes : -6.22\n",
            "Q loss: 0.0006609178381040692\n",
            "Episode : 593 , episodic length : 3871, return: -2.0, exp_count :993780, averged returnover past 100 episodes : -6.11\n",
            "Q loss: 0.01503622904419899\n",
            "Episode : 594 , episodic length : 3713, return: 2.0, exp_count :997494, averged returnover past 100 episodes : -5.97\n",
            "Q loss: 0.005184801295399666\n",
            "Episode : 595 , episodic length : 3553, return: 2.0, exp_count :1001048, averged returnover past 100 episodes : -5.83\n",
            "Q loss: 0.0015573471318930387\n",
            "Episode : 596 , episodic length : 3239, return: -2.0, exp_count :1004288, averged returnover past 100 episodes : -5.72\n",
            "Q loss: 0.002925420179963112\n",
            "Episode : 597 , episodic length : 3699, return: -1.0, exp_count :1007988, averged returnover past 100 episodes : -5.64\n",
            "Q loss: 0.0032095760107040405\n",
            "Episode : 598 , episodic length : 3252, return: -2.0, exp_count :1011241, averged returnover past 100 episodes : -5.61\n",
            "Episode : 599 , episodic length : 2276, return: -10.0, exp_count :1013518, averged returnover past 100 episodes : -5.63\n",
            "-----start Testing------\n",
            "Testing result, Returns: [  7. -12. -12. -12. -15. -12. -12.  -7. -12.  -7.   7. -12.   7.  -7.\n",
            "   7.]\n",
            "Q loss: 0.008714058436453342\n",
            "Episode : 600 , episodic length : 2692, return: -4.0, exp_count :1016211, averged returnover past 100 episodes : -5.54\n",
            "Q loss: 0.004436442628502846\n",
            "Episode : 601 , episodic length : 2341, return: -11.0, exp_count :1018553, averged returnover past 100 episodes : -5.51\n",
            "Episode : 602 , episodic length : 1275, return: -19.0, exp_count :1019829, averged returnover past 100 episodes : -5.56\n",
            "Q loss: 0.0014973627403378487\n",
            "Episode : 603 , episodic length : 3212, return: -1.0, exp_count :1023042, averged returnover past 100 episodes : -5.43\n",
            "Q loss: 0.003701560664921999\n",
            "Episode : 604 , episodic length : 3094, return: -8.0, exp_count :1026137, averged returnover past 100 episodes : -5.38\n",
            "Episode : 605 , episodic length : 3106, return: 7.0, exp_count :1029244, averged returnover past 100 episodes : -5.2\n",
            "Q loss: 0.0016664710128679872\n",
            "Episode : 606 , episodic length : 3356, return: 5.0, exp_count :1032601, averged returnover past 100 episodes : -5.03\n",
            "Q loss: 0.002820937428623438\n",
            "Episode : 607 , episodic length : 3175, return: 3.0, exp_count :1035777, averged returnover past 100 episodes : -4.89\n",
            "Q loss: 0.0016644038259983063\n",
            "Episode : 608 , episodic length : 3378, return: 3.0, exp_count :1039156, averged returnover past 100 episodes : -4.77\n",
            "Q loss: 0.006754787173122168\n",
            "Episode : 609 , episodic length : 3171, return: 5.0, exp_count :1042328, averged returnover past 100 episodes : -4.65\n",
            "Episode : 610 , episodic length : 3023, return: -6.0, exp_count :1045352, averged returnover past 100 episodes : -4.59\n",
            "Q loss: 0.005163189489394426\n",
            "Episode : 611 , episodic length : 3305, return: 5.0, exp_count :1048658, averged returnover past 100 episodes : -4.43\n",
            "Q loss: 0.0016357417916879058\n",
            "Episode : 612 , episodic length : 2639, return: -10.0, exp_count :1051298, averged returnover past 100 episodes : -4.43\n",
            "Q loss: 0.0023694415576756\n",
            "Episode : 613 , episodic length : 3752, return: -1.0, exp_count :1055051, averged returnover past 100 episodes : -4.29\n",
            "Q loss: 0.0019162304233759642\n",
            "Episode : 614 , episodic length : 2979, return: -6.0, exp_count :1058031, averged returnover past 100 episodes : -4.27\n",
            "Episode : 615 , episodic length : 3164, return: -1.0, exp_count :1061196, averged returnover past 100 episodes : -4.18\n",
            "Q loss: 0.005917258560657501\n",
            "Episode : 616 , episodic length : 2590, return: -7.0, exp_count :1063787, averged returnover past 100 episodes : -4.2\n",
            "Episode : 617 , episodic length : 1132, return: -19.0, exp_count :1064920, averged returnover past 100 episodes : -4.32\n",
            "Q loss: 0.005262492224574089\n",
            "Episode : 618 , episodic length : 2277, return: -9.0, exp_count :1067198, averged returnover past 100 episodes : -4.3\n",
            "Episode : 619 , episodic length : 1766, return: -12.0, exp_count :1068965, averged returnover past 100 episodes : -4.28\n",
            "Q loss: 0.001953430939465761\n",
            "Episode : 620 , episodic length : 1762, return: -13.0, exp_count :1070728, averged returnover past 100 episodes : -4.3\n",
            "Episode : 621 , episodic length : 1969, return: -12.0, exp_count :1072698, averged returnover past 100 episodes : -4.35\n",
            "Q loss: 0.0016077676555141807\n",
            "Episode : 622 , episodic length : 2849, return: -3.0, exp_count :1075548, averged returnover past 100 episodes : -4.3\n",
            "Episode : 623 , episodic length : 1125, return: -17.0, exp_count :1076674, averged returnover past 100 episodes : -4.45\n",
            "Q loss: 0.006992971058934927\n",
            "Episode : 624 , episodic length : 1842, return: -13.0, exp_count :1078517, averged returnover past 100 episodes : -4.49\n",
            "Episode : 625 , episodic length : 3438, return: 3.0, exp_count :1081956, averged returnover past 100 episodes : -4.41\n",
            "Q loss: 0.0024566121865063906\n",
            "Episode : 626 , episodic length : 1408, return: -17.0, exp_count :1083365, averged returnover past 100 episodes : -4.5\n",
            "Q loss: 0.002088382374495268\n",
            "Episode : 627 , episodic length : 3668, return: -1.0, exp_count :1087034, averged returnover past 100 episodes : -4.38\n",
            "Q loss: 0.0025131108704954386\n",
            "Episode : 628 , episodic length : 3090, return: 6.0, exp_count :1090125, averged returnover past 100 episodes : -4.23\n",
            "Episode : 629 , episodic length : 2610, return: -7.0, exp_count :1092736, averged returnover past 100 episodes : -4.22\n",
            "Q loss: 0.005947674624621868\n",
            "Episode : 630 , episodic length : 3471, return: -4.0, exp_count :1096208, averged returnover past 100 episodes : -4.18\n",
            "Q loss: 0.0028481241315603256\n",
            "Episode : 631 , episodic length : 3238, return: 2.0, exp_count :1099447, averged returnover past 100 episodes : -4.07\n",
            "Q loss: 0.007075452245771885\n",
            "Episode : 632 , episodic length : 3709, return: -2.0, exp_count :1103157, averged returnover past 100 episodes : -3.99\n",
            "Q loss: 0.0033716962207108736\n",
            "Episode : 633 , episodic length : 3585, return: -3.0, exp_count :1106743, averged returnover past 100 episodes : -3.92\n",
            "Episode : 634 , episodic length : 3039, return: -4.0, exp_count :1109783, averged returnover past 100 episodes : -3.81\n",
            "Q loss: 0.0022755993995815516\n",
            "Episode : 635 , episodic length : 3350, return: -3.0, exp_count :1113134, averged returnover past 100 episodes : -3.75\n",
            "Q loss: 0.0020497411023825407\n",
            "Episode : 636 , episodic length : 3752, return: -5.0, exp_count :1116887, averged returnover past 100 episodes : -3.71\n",
            "Q loss: 0.0011046500876545906\n",
            "Episode : 637 , episodic length : 3423, return: 1.0, exp_count :1120311, averged returnover past 100 episodes : -3.64\n",
            "Episode : 638 , episodic length : 1590, return: -15.0, exp_count :1121902, averged returnover past 100 episodes : -3.75\n",
            "Q loss: 0.0017171730287373066\n",
            "Episode : 639 , episodic length : 2811, return: -7.0, exp_count :1124714, averged returnover past 100 episodes : -3.76\n",
            "Q loss: 0.002772759646177292\n",
            "Episode : 640 , episodic length : 3060, return: -7.0, exp_count :1127775, averged returnover past 100 episodes : -3.8\n",
            "Q loss: 0.005974029656499624\n",
            "Episode : 641 , episodic length : 3300, return: 5.0, exp_count :1131076, averged returnover past 100 episodes : -3.68\n",
            "Q loss: 0.0012691854499280453\n",
            "Episode : 642 , episodic length : 3598, return: 2.0, exp_count :1134675, averged returnover past 100 episodes : -3.6\n",
            "Episode : 643 , episodic length : 2584, return: -11.0, exp_count :1137260, averged returnover past 100 episodes : -3.68\n",
            "Q loss: 0.003915248904377222\n",
            "Episode : 644 , episodic length : 3399, return: -2.0, exp_count :1140660, averged returnover past 100 episodes : -3.73\n",
            "Q loss: 0.002871578559279442\n",
            "Episode : 645 , episodic length : 3443, return: -4.0, exp_count :1144104, averged returnover past 100 episodes : -3.73\n",
            "Q loss: 0.009561551734805107\n",
            "Episode : 646 , episodic length : 2261, return: -11.0, exp_count :1146366, averged returnover past 100 episodes : -3.8\n",
            "Episode : 647 , episodic length : 2933, return: -5.0, exp_count :1149300, averged returnover past 100 episodes : -3.86\n",
            "Q loss: 0.00619198102504015\n",
            "Episode : 648 , episodic length : 3386, return: -7.0, exp_count :1152687, averged returnover past 100 episodes : -3.95\n",
            "Q loss: 0.0047992197796702385\n",
            "Episode : 649 , episodic length : 3362, return: -2.0, exp_count :1156050, averged returnover past 100 episodes : -3.99\n",
            "Q loss: 0.0030413686763495207\n",
            "Episode : 650 , episodic length : 3040, return: 6.0, exp_count :1159091, averged returnover past 100 episodes : -4.0\n",
            "Q loss: 0.0029888497665524483\n",
            "Episode : 651 , episodic length : 3236, return: 7.0, exp_count :1162328, averged returnover past 100 episodes : -3.89\n",
            "Episode : 652 , episodic length : 3582, return: -2.0, exp_count :1165911, averged returnover past 100 episodes : -3.87\n",
            "Q loss: 0.015187372453510761\n",
            "Episode : 653 , episodic length : 2612, return: 10.0, exp_count :1168524, averged returnover past 100 episodes : -3.68\n",
            "Q loss: 0.0048372503370046616\n",
            "Episode : 654 , episodic length : 2086, return: -12.0, exp_count :1170611, averged returnover past 100 episodes : -3.78\n",
            "Episode : 655 , episodic length : 2988, return: -2.0, exp_count :1173600, averged returnover past 100 episodes : -3.75\n",
            "Q loss: 0.012957993894815445\n",
            "Episode : 656 , episodic length : 4008, return: -4.0, exp_count :1177609, averged returnover past 100 episodes : -3.69\n",
            "Q loss: 0.001341664232313633\n",
            "Episode : 657 , episodic length : 2650, return: -10.0, exp_count :1180260, averged returnover past 100 episodes : -3.69\n",
            "Q loss: 0.006183450575917959\n",
            "Episode : 658 , episodic length : 3692, return: -2.0, exp_count :1183953, averged returnover past 100 episodes : -3.7\n",
            "Q loss: 0.0016257748939096928\n",
            "Episode : 659 , episodic length : 2967, return: -6.0, exp_count :1186921, averged returnover past 100 episodes : -3.65\n",
            "Q loss: 0.005849933251738548\n",
            "Episode : 660 , episodic length : 3845, return: 3.0, exp_count :1190767, averged returnover past 100 episodes : -3.55\n",
            "Q loss: 0.004773667082190514\n",
            "Episode : 661 , episodic length : 3562, return: 1.0, exp_count :1194330, averged returnover past 100 episodes : -3.5\n",
            "Episode : 662 , episodic length : 1127, return: -19.0, exp_count :1195458, averged returnover past 100 episodes : -3.62\n",
            "Q loss: 0.013866162858903408\n",
            "Episode : 663 , episodic length : 2798, return: -7.0, exp_count :1198257, averged returnover past 100 episodes : -3.67\n",
            "Q loss: 0.00797022134065628\n",
            "Episode : 664 , episodic length : 3990, return: -2.0, exp_count :1202248, averged returnover past 100 episodes : -3.62\n",
            "Episode : 665 , episodic length : 3729, return: -2.0, exp_count :1205978, averged returnover past 100 episodes : -3.61\n",
            "Q loss: 0.002885016379877925\n",
            "Episode : 666 , episodic length : 3753, return: 1.0, exp_count :1209732, averged returnover past 100 episodes : -3.51\n",
            "Q loss: 0.015700779855251312\n",
            "Episode : 667 , episodic length : 1894, return: -14.0, exp_count :1211627, averged returnover past 100 episodes : -3.61\n",
            "Q loss: 0.010249924845993519\n",
            "Episode : 668 , episodic length : 3285, return: 2.0, exp_count :1214913, averged returnover past 100 episodes : -3.57\n",
            "Q loss: 0.0006457740091718733\n",
            "Episode : 669 , episodic length : 3122, return: 2.0, exp_count :1218036, averged returnover past 100 episodes : -3.48\n",
            "Episode : 670 , episodic length : 3213, return: 2.0, exp_count :1221250, averged returnover past 100 episodes : -3.47\n",
            "Q loss: 0.0037973341532051563\n",
            "Episode : 671 , episodic length : 3521, return: 4.0, exp_count :1224772, averged returnover past 100 episodes : -3.48\n",
            "Q loss: 0.0026187484618276358\n",
            "Episode : 672 , episodic length : 3449, return: 7.0, exp_count :1228222, averged returnover past 100 episodes : -3.34\n",
            "Q loss: 0.01650434359908104\n",
            "Episode : 673 , episodic length : 3427, return: 6.0, exp_count :1231650, averged returnover past 100 episodes : -3.24\n",
            "Q loss: 0.0017160382121801376\n",
            "Episode : 674 , episodic length : 3839, return: -2.0, exp_count :1235490, averged returnover past 100 episodes : -3.19\n",
            "Q loss: 0.0013048293767496943\n",
            "Episode : 675 , episodic length : 3287, return: -5.0, exp_count :1238778, averged returnover past 100 episodes : -3.17\n",
            "Episode : 676 , episodic length : 3189, return: 6.0, exp_count :1241968, averged returnover past 100 episodes : -3.13\n",
            "Q loss: 0.0012065162882208824\n",
            "Episode : 677 , episodic length : 3511, return: -2.0, exp_count :1245480, averged returnover past 100 episodes : -3.21\n",
            "Q loss: 0.0035526989959180355\n",
            "Episode : 678 , episodic length : 3577, return: 1.0, exp_count :1249058, averged returnover past 100 episodes : -3.13\n",
            "Q loss: 0.0012211172142997384\n",
            "Episode : 679 , episodic length : 2687, return: 11.0, exp_count :1251746, averged returnover past 100 episodes : -3.04\n",
            "Q loss: 0.0008732877904549241\n",
            "Episode : 680 , episodic length : 3624, return: 9.0, exp_count :1255371, averged returnover past 100 episodes : -2.94\n",
            "Q loss: 0.0014336617896333337\n",
            "Episode : 681 , episodic length : 3347, return: 8.0, exp_count :1258719, averged returnover past 100 episodes : -2.83\n",
            "Q loss: 0.007169303949922323\n",
            "Episode : 682 , episodic length : 3911, return: 3.0, exp_count :1262631, averged returnover past 100 episodes : -2.68\n",
            "Episode : 683 , episodic length : 3144, return: 10.0, exp_count :1265776, averged returnover past 100 episodes : -2.52\n",
            "Q loss: 0.0016614818014204502\n",
            "Episode : 684 , episodic length : 2777, return: 11.0, exp_count :1268554, averged returnover past 100 episodes : -2.4\n",
            "Q loss: 0.003756405785679817\n",
            "Episode : 685 , episodic length : 2720, return: 10.0, exp_count :1271275, averged returnover past 100 episodes : -2.34\n",
            "Q loss: 0.014215785078704357\n",
            "Episode : 686 , episodic length : 3488, return: 1.0, exp_count :1274764, averged returnover past 100 episodes : -2.31\n",
            "Q loss: 0.002366489963606\n",
            "Episode : 687 , episodic length : 3386, return: -4.0, exp_count :1278151, averged returnover past 100 episodes : -2.26\n",
            "Episode : 688 , episodic length : 3039, return: 7.0, exp_count :1281191, averged returnover past 100 episodes : -2.03\n",
            "Q loss: 0.003426614683121443\n",
            "Episode : 689 , episodic length : 2745, return: 9.0, exp_count :1283937, averged returnover past 100 episodes : -1.95\n",
            "Q loss: 0.0010418331949040294\n",
            "Episode : 690 , episodic length : 2916, return: 10.0, exp_count :1286854, averged returnover past 100 episodes : -1.92\n",
            "Episode : 691 , episodic length : 2286, return: 16.0, exp_count :1289141, averged returnover past 100 episodes : -1.83\n",
            "Q loss: 0.001441361615434289\n",
            "Episode : 692 , episodic length : 3660, return: 5.0, exp_count :1292802, averged returnover past 100 episodes : -1.82\n",
            "Q loss: 0.003917106427252293\n",
            "Episode : 693 , episodic length : 2523, return: 8.0, exp_count :1295326, averged returnover past 100 episodes : -1.72\n",
            "Q loss: 0.002229659352451563\n",
            "Episode : 694 , episodic length : 3068, return: 7.0, exp_count :1298395, averged returnover past 100 episodes : -1.67\n",
            "Episode : 695 , episodic length : 2950, return: 7.0, exp_count :1301346, averged returnover past 100 episodes : -1.62\n",
            "Q loss: 0.002831521909683943\n",
            "Episode : 696 , episodic length : 2597, return: 14.0, exp_count :1303944, averged returnover past 100 episodes : -1.46\n",
            "Q loss: 0.009578408673405647\n",
            "Episode : 697 , episodic length : 3504, return: 6.0, exp_count :1307449, averged returnover past 100 episodes : -1.39\n",
            "Q loss: 0.004129723180085421\n",
            "Episode : 698 , episodic length : 4003, return: 2.0, exp_count :1311453, averged returnover past 100 episodes : -1.35\n",
            "Q loss: 0.00086515600560233\n",
            "Episode : 699 , episodic length : 3150, return: 5.0, exp_count :1314604, averged returnover past 100 episodes : -1.2\n",
            "-----start Testing------\n",
            "Testing result, Returns: [12. 11. 17. 17. 17. 14. 12. 11. 12. 17. 11. 12. 17. 11. 12.]\n",
            "Q loss: 0.0006547466618940234\n",
            "Episode : 700 , episodic length : 4006, return: -1.0, exp_count :1318611, averged returnover past 100 episodes : -1.17\n",
            "Episode : 701 , episodic length : 3132, return: 9.0, exp_count :1321744, averged returnover past 100 episodes : -0.97\n",
            "Q loss: 0.006073975469917059\n",
            "Episode : 702 , episodic length : 2588, return: 14.0, exp_count :1324333, averged returnover past 100 episodes : -0.64\n",
            "Q loss: 0.00070769595913589\n",
            "Episode : 703 , episodic length : 4204, return: 3.0, exp_count :1328538, averged returnover past 100 episodes : -0.6\n",
            "Q loss: 0.004523187875747681\n",
            "Episode : 704 , episodic length : 2992, return: 12.0, exp_count :1331531, averged returnover past 100 episodes : -0.4\n",
            "Q loss: 0.0016604444244876504\n",
            "Episode : 705 , episodic length : 2907, return: 13.0, exp_count :1334439, averged returnover past 100 episodes : -0.34\n",
            "Episode : 706 , episodic length : 2289, return: 14.0, exp_count :1336729, averged returnover past 100 episodes : -0.25\n",
            "Q loss: 0.007522688712924719\n",
            "Episode : 707 , episodic length : 3349, return: 8.0, exp_count :1340079, averged returnover past 100 episodes : -0.2\n",
            "Q loss: 0.004517233930528164\n",
            "Episode : 708 , episodic length : 2457, return: 9.0, exp_count :1342537, averged returnover past 100 episodes : -0.14\n",
            "Episode : 709 , episodic length : 2793, return: 11.0, exp_count :1345331, averged returnover past 100 episodes : -0.08\n",
            "Q loss: 0.0012153395218774676\n",
            "Episode : 710 , episodic length : 2182, return: 15.0, exp_count :1347514, averged returnover past 100 episodes : 0.13\n",
            "Q loss: 0.002756098285317421\n",
            "Episode : 711 , episodic length : 2881, return: 9.0, exp_count :1350396, averged returnover past 100 episodes : 0.17\n",
            "Q loss: 0.002521422691643238\n",
            "Episode : 712 , episodic length : 3898, return: 3.0, exp_count :1354295, averged returnover past 100 episodes : 0.3\n",
            "Episode : 713 , episodic length : 2962, return: 9.0, exp_count :1357258, averged returnover past 100 episodes : 0.4\n",
            "Q loss: 0.002347906120121479\n",
            "Episode : 714 , episodic length : 2752, return: 6.0, exp_count :1360011, averged returnover past 100 episodes : 0.52\n",
            "Q loss: 0.0027775485068559647\n",
            "Episode : 715 , episodic length : 2848, return: 9.0, exp_count :1362860, averged returnover past 100 episodes : 0.62\n",
            "Episode : 716 , episodic length : 2307, return: 15.0, exp_count :1365168, averged returnover past 100 episodes : 0.84\n",
            "Q loss: 0.001218608464114368\n",
            "Episode : 717 , episodic length : 2322, return: 15.0, exp_count :1367491, averged returnover past 100 episodes : 1.18\n",
            "Q loss: 0.005355420056730509\n",
            "Episode : 718 , episodic length : 3296, return: -3.0, exp_count :1370788, averged returnover past 100 episodes : 1.24\n",
            "Episode : 719 , episodic length : 3063, return: 8.0, exp_count :1373852, averged returnover past 100 episodes : 1.44\n",
            "Q loss: 0.0017389515414834023\n",
            "Episode : 720 , episodic length : 3403, return: 8.0, exp_count :1377256, averged returnover past 100 episodes : 1.65\n",
            "Q loss: 0.006141130346804857\n",
            "Episode : 721 , episodic length : 3091, return: 10.0, exp_count :1380348, averged returnover past 100 episodes : 1.87\n",
            "Q loss: 0.0019445258658379316\n",
            "Episode : 722 , episodic length : 2809, return: 11.0, exp_count :1383158, averged returnover past 100 episodes : 2.01\n",
            "Episode : 723 , episodic length : 2699, return: 12.0, exp_count :1385858, averged returnover past 100 episodes : 2.3\n",
            "Q loss: 0.003998917527496815\n",
            "Episode : 724 , episodic length : 3101, return: 6.0, exp_count :1388960, averged returnover past 100 episodes : 2.49\n",
            "Q loss: 0.0018036607652902603\n",
            "Episode : 725 , episodic length : 2800, return: 10.0, exp_count :1391761, averged returnover past 100 episodes : 2.56\n",
            "Q loss: 0.00328170252032578\n",
            "Episode : 726 , episodic length : 2885, return: 10.0, exp_count :1394647, averged returnover past 100 episodes : 2.83\n",
            "Episode : 727 , episodic length : 2973, return: 9.0, exp_count :1397621, averged returnover past 100 episodes : 2.93\n",
            "Q loss: 0.010143127292394638\n",
            "Episode : 728 , episodic length : 1987, return: 19.0, exp_count :1399609, averged returnover past 100 episodes : 3.06\n",
            "Q loss: 0.003008214756846428\n",
            "Episode : 729 , episodic length : 2739, return: 13.0, exp_count :1402349, averged returnover past 100 episodes : 3.26\n",
            "Episode : 730 , episodic length : 3558, return: 10.0, exp_count :1405908, averged returnover past 100 episodes : 3.4\n",
            "Q loss: 0.002149739768356085\n",
            "Episode : 731 , episodic length : 3366, return: 5.0, exp_count :1409275, averged returnover past 100 episodes : 3.43\n",
            "Q loss: 0.0011125104501843452\n",
            "Episode : 732 , episodic length : 3970, return: 7.0, exp_count :1413246, averged returnover past 100 episodes : 3.52\n",
            "Q loss: 0.0033669453114271164\n",
            "Episode : 733 , episodic length : 2487, return: 10.0, exp_count :1415734, averged returnover past 100 episodes : 3.65\n",
            "Q loss: 0.0010224867146462202\n",
            "Episode : 734 , episodic length : 2386, return: 10.0, exp_count :1418121, averged returnover past 100 episodes : 3.79\n",
            "Episode : 735 , episodic length : 2372, return: 14.0, exp_count :1420494, averged returnover past 100 episodes : 3.96\n",
            "Q loss: 0.0023586112074553967\n",
            "Episode : 736 , episodic length : 2436, return: 9.0, exp_count :1422931, averged returnover past 100 episodes : 4.1\n",
            "Episode : 737 , episodic length : 2034, return: 17.0, exp_count :1424966, averged returnover past 100 episodes : 4.26\n",
            "Q loss: 0.0019663095008581877\n",
            "Episode : 738 , episodic length : 2860, return: 10.0, exp_count :1427827, averged returnover past 100 episodes : 4.51\n",
            "Q loss: 0.005895169917494059\n",
            "Episode : 739 , episodic length : 2725, return: 10.0, exp_count :1430553, averged returnover past 100 episodes : 4.68\n",
            "Episode : 740 , episodic length : 2178, return: 17.0, exp_count :1432732, averged returnover past 100 episodes : 4.92\n",
            "Q loss: 0.0017220299923792481\n",
            "Episode : 741 , episodic length : 2751, return: 15.0, exp_count :1435484, averged returnover past 100 episodes : 5.02\n",
            "Q loss: 0.0013410963583737612\n",
            "Episode : 742 , episodic length : 3423, return: 10.0, exp_count :1438908, averged returnover past 100 episodes : 5.1\n",
            "Episode : 743 , episodic length : 1875, return: 19.0, exp_count :1440784, averged returnover past 100 episodes : 5.4\n",
            "Q loss: 0.0009368635946884751\n",
            "Episode : 744 , episodic length : 1933, return: 18.0, exp_count :1442718, averged returnover past 100 episodes : 5.6\n",
            "Episode : 745 , episodic length : 2525, return: 16.0, exp_count :1445244, averged returnover past 100 episodes : 5.8\n",
            "Q loss: 0.0027745864354074\n",
            "Episode : 746 , episodic length : 2310, return: 16.0, exp_count :1447555, averged returnover past 100 episodes : 6.07\n",
            "Episode : 747 , episodic length : 2439, return: 10.0, exp_count :1449995, averged returnover past 100 episodes : 6.22\n",
            "Q loss: 0.0013702847063541412\n",
            "Episode : 748 , episodic length : 2721, return: 16.0, exp_count :1452717, averged returnover past 100 episodes : 6.45\n",
            "Q loss: 0.0013978707138448954\n",
            "Episode : 749 , episodic length : 3260, return: 10.0, exp_count :1455978, averged returnover past 100 episodes : 6.57\n",
            "Q loss: 0.0014568628976121545\n",
            "Episode : 750 , episodic length : 2448, return: 16.0, exp_count :1458427, averged returnover past 100 episodes : 6.67\n",
            "Episode : 751 , episodic length : 3243, return: 10.0, exp_count :1461671, averged returnover past 100 episodes : 6.7\n",
            "Q loss: 0.0009387276950292289\n",
            "Episode : 752 , episodic length : 2779, return: 13.0, exp_count :1464451, averged returnover past 100 episodes : 6.85\n",
            "Q loss: 0.0014173948438838124\n",
            "Episode : 753 , episodic length : 3690, return: 7.0, exp_count :1468142, averged returnover past 100 episodes : 6.82\n",
            "Q loss: 0.002744222991168499\n",
            "Episode : 754 , episodic length : 3503, return: 8.0, exp_count :1471646, averged returnover past 100 episodes : 7.02\n",
            "Q loss: 0.0035875632893294096\n",
            "Episode : 755 , episodic length : 3083, return: 12.0, exp_count :1474730, averged returnover past 100 episodes : 7.16\n",
            "Episode : 756 , episodic length : 3066, return: 10.0, exp_count :1477797, averged returnover past 100 episodes : 7.3\n",
            "Q loss: 0.0017885126871988177\n",
            "Episode : 757 , episodic length : 2370, return: 13.0, exp_count :1480168, averged returnover past 100 episodes : 7.53\n",
            "Q loss: 0.003783497028052807\n",
            "Episode : 758 , episodic length : 2765, return: 8.0, exp_count :1482934, averged returnover past 100 episodes : 7.63\n",
            "Q loss: 0.0027088639326393604\n",
            "Episode : 759 , episodic length : 3893, return: 6.0, exp_count :1486828, averged returnover past 100 episodes : 7.75\n",
            "Q loss: 0.02302619442343712\n",
            "Episode : 760 , episodic length : 3217, return: 10.0, exp_count :1490046, averged returnover past 100 episodes : 7.82\n",
            "Episode : 761 , episodic length : 3108, return: 8.0, exp_count :1493155, averged returnover past 100 episodes : 7.89\n",
            "Q loss: 0.0011371382279321551\n",
            "Episode : 762 , episodic length : 3056, return: 3.0, exp_count :1496212, averged returnover past 100 episodes : 8.11\n",
            "Q loss: 0.0010304258903488517\n",
            "Episode : 763 , episodic length : 2699, return: 12.0, exp_count :1498912, averged returnover past 100 episodes : 8.3\n",
            "Episode : 764 , episodic length : 2879, return: 11.0, exp_count :1501792, averged returnover past 100 episodes : 8.43\n",
            "Q loss: 0.002313405741006136\n",
            "Episode : 765 , episodic length : 2214, return: 16.0, exp_count :1504007, averged returnover past 100 episodes : 8.61\n",
            "Q loss: 0.002141552744433284\n",
            "Episode : 766 , episodic length : 2866, return: 10.0, exp_count :1506874, averged returnover past 100 episodes : 8.7\n",
            "Q loss: 0.0007730037905275822\n",
            "Episode : 767 , episodic length : 3672, return: 5.0, exp_count :1510547, averged returnover past 100 episodes : 8.89\n",
            "Episode : 768 , episodic length : 3369, return: 5.0, exp_count :1513917, averged returnover past 100 episodes : 8.92\n",
            "Q loss: 0.0031471382826566696\n",
            "Episode : 769 , episodic length : 2429, return: 15.0, exp_count :1516347, averged returnover past 100 episodes : 9.05\n",
            "Q loss: 0.0036085485480725765\n",
            "Episode : 770 , episodic length : 2380, return: 15.0, exp_count :1518728, averged returnover past 100 episodes : 9.18\n",
            "Episode : 771 , episodic length : 3196, return: 8.0, exp_count :1521925, averged returnover past 100 episodes : 9.22\n",
            "Q loss: 0.0020259437151253223\n",
            "Episode : 772 , episodic length : 2899, return: 13.0, exp_count :1524825, averged returnover past 100 episodes : 9.28\n",
            "Q loss: 0.0020312934648245573\n",
            "Episode : 773 , episodic length : 2712, return: 14.0, exp_count :1527538, averged returnover past 100 episodes : 9.36\n",
            "Q loss: 0.004642711021006107\n",
            "Episode : 774 , episodic length : 2837, return: 10.0, exp_count :1530376, averged returnover past 100 episodes : 9.48\n",
            "Episode : 775 , episodic length : 2486, return: 17.0, exp_count :1532863, averged returnover past 100 episodes : 9.7\n",
            "Q loss: 0.007696306332945824\n",
            "Episode : 776 , episodic length : 3563, return: 7.0, exp_count :1536427, averged returnover past 100 episodes : 9.71\n",
            "Q loss: 0.0028640551026910543\n",
            "Episode : 777 , episodic length : 3202, return: 7.0, exp_count :1539630, averged returnover past 100 episodes : 9.8\n",
            "Q loss: 0.0019817142747342587\n",
            "Episode : 778 , episodic length : 2891, return: 11.0, exp_count :1542522, averged returnover past 100 episodes : 9.9\n",
            "Episode : 779 , episodic length : 2525, return: 13.0, exp_count :1545048, averged returnover past 100 episodes : 9.92\n",
            "Q loss: 0.0026098983362317085\n",
            "Episode : 780 , episodic length : 2450, return: 14.0, exp_count :1547499, averged returnover past 100 episodes : 9.97\n",
            "Q loss: 0.002185444114729762\n",
            "Episode : 781 , episodic length : 2778, return: 6.0, exp_count :1550278, averged returnover past 100 episodes : 9.95\n",
            "Episode : 782 , episodic length : 2705, return: 10.0, exp_count :1552984, averged returnover past 100 episodes : 10.02\n",
            "Q loss: 0.004169700667262077\n",
            "Episode : 783 , episodic length : 2224, return: 16.0, exp_count :1555209, averged returnover past 100 episodes : 10.08\n",
            "Episode : 784 , episodic length : 2435, return: 14.0, exp_count :1557645, averged returnover past 100 episodes : 10.11\n",
            "Q loss: 0.003295816481113434\n",
            "Episode : 785 , episodic length : 2427, return: 14.0, exp_count :1560073, averged returnover past 100 episodes : 10.15\n",
            "Q loss: 0.0018396960804238915\n",
            "Episode : 786 , episodic length : 3060, return: 7.0, exp_count :1563134, averged returnover past 100 episodes : 10.21\n",
            "Episode : 787 , episodic length : 2665, return: 10.0, exp_count :1565800, averged returnover past 100 episodes : 10.35\n",
            "Q loss: 0.0011970959603786469\n",
            "Episode : 788 , episodic length : 2357, return: -8.0, exp_count :1568158, averged returnover past 100 episodes : 10.2\n",
            "Episode : 789 , episodic length : 1193, return: -18.0, exp_count :1569352, averged returnover past 100 episodes : 9.93\n",
            "Q loss: 0.001233067363500595\n",
            "Episode : 790 , episodic length : 3111, return: 7.0, exp_count :1572464, averged returnover past 100 episodes : 9.9\n",
            "Q loss: 0.0007230212795548141\n",
            "Episode : 791 , episodic length : 3791, return: 3.0, exp_count :1576256, averged returnover past 100 episodes : 9.77\n",
            "Q loss: 0.0050863055512309074\n",
            "Episode : 792 , episodic length : 3131, return: -2.0, exp_count :1579388, averged returnover past 100 episodes : 9.7\n",
            "Episode : 793 , episodic length : 2591, return: 17.0, exp_count :1581980, averged returnover past 100 episodes : 9.79\n",
            "Q loss: 0.002735363319516182\n",
            "Episode : 794 , episodic length : 3196, return: 10.0, exp_count :1585177, averged returnover past 100 episodes : 9.82\n",
            "Q loss: 0.0019765582401305437\n",
            "Episode : 795 , episodic length : 2200, return: 17.0, exp_count :1587378, averged returnover past 100 episodes : 9.92\n",
            "Episode : 796 , episodic length : 2049, return: 17.0, exp_count :1589428, averged returnover past 100 episodes : 9.95\n",
            "Q loss: 0.0014735253062099218\n",
            "Episode : 797 , episodic length : 2088, return: 15.0, exp_count :1591517, averged returnover past 100 episodes : 10.04\n",
            "Q loss: 0.001615710323676467\n",
            "Episode : 798 , episodic length : 2502, return: 18.0, exp_count :1594020, averged returnover past 100 episodes : 10.2\n",
            "Episode : 799 , episodic length : 3186, return: 2.0, exp_count :1597207, averged returnover past 100 episodes : 10.17\n",
            "-----start Testing------\n",
            "Testing result, Returns: [15. 15. 15. 20. 15. 20. 16. 21. 14. 15. 20. 20. 14. 21. 14.]\n",
            "Q loss: 0.0014839801006019115\n",
            "Episode : 800 , episodic length : 2276, return: 16.0, exp_count :1599484, averged returnover past 100 episodes : 10.34\n",
            "Q loss: 0.0020465590059757233\n",
            "Episode : 801 , episodic length : 3316, return: -1.0, exp_count :1602801, averged returnover past 100 episodes : 10.24\n",
            "Episode : 802 , episodic length : 1957, return: 15.0, exp_count :1604759, averged returnover past 100 episodes : 10.25\n",
            "Q loss: 0.006791525520384312\n",
            "Episode : 803 , episodic length : 2137, return: 10.0, exp_count :1606897, averged returnover past 100 episodes : 10.32\n",
            "Episode : 804 , episodic length : 2439, return: -8.0, exp_count :1609337, averged returnover past 100 episodes : 10.12\n",
            "Q loss: 0.0009059957810677588\n",
            "Episode : 805 , episodic length : 2246, return: 14.0, exp_count :1611584, averged returnover past 100 episodes : 10.13\n",
            "Q loss: 0.0016382555477321148\n",
            "Episode : 806 , episodic length : 2642, return: 11.0, exp_count :1614227, averged returnover past 100 episodes : 10.1\n",
            "Episode : 807 , episodic length : 2348, return: 12.0, exp_count :1616576, averged returnover past 100 episodes : 10.14\n",
            "Q loss: 0.0038148360326886177\n",
            "Episode : 808 , episodic length : 2882, return: 9.0, exp_count :1619459, averged returnover past 100 episodes : 10.14\n",
            "Episode : 809 , episodic length : 2457, return: 11.0, exp_count :1621917, averged returnover past 100 episodes : 10.14\n",
            "Q loss: 0.004032274708151817\n",
            "Episode : 810 , episodic length : 2284, return: 12.0, exp_count :1624202, averged returnover past 100 episodes : 10.11\n",
            "Q loss: 0.00912958662956953\n",
            "Episode : 811 , episodic length : 3148, return: 9.0, exp_count :1627351, averged returnover past 100 episodes : 10.11\n",
            "Episode : 812 , episodic length : 2639, return: 10.0, exp_count :1629991, averged returnover past 100 episodes : 10.18\n",
            "Q loss: 0.002848634961992502\n",
            "Episode : 813 , episodic length : 2516, return: 8.0, exp_count :1632508, averged returnover past 100 episodes : 10.17\n",
            "Q loss: 0.01740446127951145\n",
            "Episode : 814 , episodic length : 2165, return: 17.0, exp_count :1634674, averged returnover past 100 episodes : 10.28\n",
            "Episode : 815 , episodic length : 2376, return: 12.0, exp_count :1637051, averged returnover past 100 episodes : 10.31\n",
            "Q loss: 0.0004456600290723145\n",
            "Episode : 816 , episodic length : 2556, return: 15.0, exp_count :1639608, averged returnover past 100 episodes : 10.31\n",
            "Q loss: 0.0035252729430794716\n",
            "Episode : 817 , episodic length : 2416, return: 13.0, exp_count :1642025, averged returnover past 100 episodes : 10.29\n",
            "Episode : 818 , episodic length : 2423, return: 16.0, exp_count :1644449, averged returnover past 100 episodes : 10.48\n",
            "Episode : 819 , episodic length : 775, return: -21.0, exp_count :1645225, averged returnover past 100 episodes : 10.19\n",
            "Q loss: 0.01930776797235012\n",
            "Episode : 820 , episodic length : 2421, return: 11.0, exp_count :1647647, averged returnover past 100 episodes : 10.22\n",
            "Q loss: 0.0066672726534307\n",
            "Episode : 821 , episodic length : 2431, return: 16.0, exp_count :1650079, averged returnover past 100 episodes : 10.28\n",
            "Episode : 822 , episodic length : 2148, return: 18.0, exp_count :1652228, averged returnover past 100 episodes : 10.35\n",
            "Q loss: 0.008963284082710743\n",
            "Episode : 823 , episodic length : 2447, return: 12.0, exp_count :1654676, averged returnover past 100 episodes : 10.35\n",
            "Episode : 824 , episodic length : 2648, return: 13.0, exp_count :1657325, averged returnover past 100 episodes : 10.42\n",
            "Q loss: 0.0022175381891429424\n",
            "Episode : 825 , episodic length : 3053, return: -4.0, exp_count :1660379, averged returnover past 100 episodes : 10.28\n",
            "Q loss: 0.003273339243605733\n",
            "Episode : 826 , episodic length : 3346, return: 5.0, exp_count :1663726, averged returnover past 100 episodes : 10.23\n",
            "Q loss: 0.00777046475559473\n",
            "Episode : 827 , episodic length : 3217, return: 6.0, exp_count :1666944, averged returnover past 100 episodes : 10.2\n",
            "Episode : 828 , episodic length : 2306, return: 14.0, exp_count :1669251, averged returnover past 100 episodes : 10.15\n",
            "Q loss: 0.004294341895729303\n",
            "Episode : 829 , episodic length : 2336, return: 13.0, exp_count :1671588, averged returnover past 100 episodes : 10.15\n",
            "Q loss: 0.001887909253127873\n",
            "Episode : 830 , episodic length : 2455, return: 8.0, exp_count :1674044, averged returnover past 100 episodes : 10.13\n",
            "Episode : 831 , episodic length : 2311, return: 15.0, exp_count :1676356, averged returnover past 100 episodes : 10.23\n",
            "Q loss: 0.004181689117103815\n",
            "Episode : 832 , episodic length : 2043, return: 17.0, exp_count :1678400, averged returnover past 100 episodes : 10.33\n",
            "Episode : 833 , episodic length : 2239, return: 13.0, exp_count :1680640, averged returnover past 100 episodes : 10.36\n",
            "Q loss: 0.001373977167531848\n",
            "Episode : 834 , episodic length : 2429, return: 12.0, exp_count :1683070, averged returnover past 100 episodes : 10.38\n",
            "Episode : 835 , episodic length : 2535, return: 13.0, exp_count :1685606, averged returnover past 100 episodes : 10.37\n",
            "Q loss: 0.002144560916349292\n",
            "Episode : 836 , episodic length : 2248, return: 15.0, exp_count :1687855, averged returnover past 100 episodes : 10.43\n",
            "Q loss: 0.0066201756708323956\n",
            "Episode : 837 , episodic length : 2491, return: 11.0, exp_count :1690347, averged returnover past 100 episodes : 10.37\n",
            "Episode : 838 , episodic length : 3118, return: 3.0, exp_count :1693466, averged returnover past 100 episodes : 10.3\n",
            "Q loss: 0.024851657450199127\n",
            "Episode : 839 , episodic length : 2552, return: 16.0, exp_count :1696019, averged returnover past 100 episodes : 10.36\n",
            "Q loss: 0.001504884334281087\n",
            "Episode : 840 , episodic length : 2958, return: 10.0, exp_count :1698978, averged returnover past 100 episodes : 10.29\n",
            "Q loss: 0.0013446554075926542\n",
            "Episode : 841 , episodic length : 3297, return: 12.0, exp_count :1702276, averged returnover past 100 episodes : 10.26\n",
            "Episode : 842 , episodic length : 3205, return: 6.0, exp_count :1705482, averged returnover past 100 episodes : 10.22\n",
            "Q loss: 0.005829585250467062\n",
            "Episode : 843 , episodic length : 2818, return: 13.0, exp_count :1708301, averged returnover past 100 episodes : 10.16\n",
            "Q loss: 0.0011448714649304748\n",
            "Episode : 844 , episodic length : 3237, return: 8.0, exp_count :1711539, averged returnover past 100 episodes : 10.06\n",
            "Q loss: 0.015282205305993557\n",
            "Episode : 845 , episodic length : 2505, return: 12.0, exp_count :1714045, averged returnover past 100 episodes : 10.02\n",
            "Episode : 846 , episodic length : 2317, return: 14.0, exp_count :1716363, averged returnover past 100 episodes : 10.0\n",
            "Q loss: 0.001336190733127296\n",
            "Episode : 847 , episodic length : 1971, return: 16.0, exp_count :1718335, averged returnover past 100 episodes : 10.06\n",
            "Episode : 848 , episodic length : 2466, return: 12.0, exp_count :1720802, averged returnover past 100 episodes : 10.02\n",
            "Q loss: 0.0012676478363573551\n",
            "Episode : 849 , episodic length : 2258, return: 15.0, exp_count :1723061, averged returnover past 100 episodes : 10.07\n",
            "Episode : 850 , episodic length : 2171, return: 18.0, exp_count :1725233, averged returnover past 100 episodes : 10.09\n",
            "Q loss: 0.0019645977299660444\n",
            "Episode : 851 , episodic length : 2086, return: 17.0, exp_count :1727320, averged returnover past 100 episodes : 10.16\n",
            "Episode : 852 , episodic length : 2131, return: 16.0, exp_count :1729452, averged returnover past 100 episodes : 10.19\n",
            "Q loss: 0.002287966199219227\n",
            "Episode : 853 , episodic length : 2456, return: 14.0, exp_count :1731909, averged returnover past 100 episodes : 10.26\n",
            "Q loss: 0.0013533160090446472\n",
            "Episode : 854 , episodic length : 2438, return: 13.0, exp_count :1734348, averged returnover past 100 episodes : 10.31\n",
            "Episode : 855 , episodic length : 2415, return: 13.0, exp_count :1736764, averged returnover past 100 episodes : 10.32\n",
            "Q loss: 0.0013153976760804653\n",
            "Episode : 856 , episodic length : 3377, return: 3.0, exp_count :1740142, averged returnover past 100 episodes : 10.25\n",
            "Q loss: 0.0011631054803729057\n",
            "Episode : 857 , episodic length : 2465, return: 13.0, exp_count :1742608, averged returnover past 100 episodes : 10.25\n",
            "Episode : 858 , episodic length : 2885, return: 7.0, exp_count :1745494, averged returnover past 100 episodes : 10.24\n",
            "Q loss: 0.002759173046797514\n",
            "Episode : 859 , episodic length : 2150, return: 16.0, exp_count :1747645, averged returnover past 100 episodes : 10.34\n",
            "Q loss: 0.0014966251328587532\n",
            "Episode : 860 , episodic length : 2574, return: 11.0, exp_count :1750220, averged returnover past 100 episodes : 10.35\n",
            "Episode : 861 , episodic length : 2180, return: 14.0, exp_count :1752401, averged returnover past 100 episodes : 10.41\n",
            "Q loss: 0.0032442505471408367\n",
            "Episode : 862 , episodic length : 3319, return: 10.0, exp_count :1755721, averged returnover past 100 episodes : 10.48\n",
            "Q loss: 0.0013030772097408772\n",
            "Episode : 863 , episodic length : 2966, return: 12.0, exp_count :1758688, averged returnover past 100 episodes : 10.48\n",
            "Episode : 864 , episodic length : 2414, return: 13.0, exp_count :1761103, averged returnover past 100 episodes : 10.5\n",
            "Q loss: 0.0034026100765913725\n",
            "Episode : 865 , episodic length : 2515, return: 16.0, exp_count :1763619, averged returnover past 100 episodes : 10.5\n",
            "Q loss: 0.0023624927271157503\n",
            "Episode : 866 , episodic length : 3540, return: 7.0, exp_count :1767160, averged returnover past 100 episodes : 10.47\n",
            "Episode : 867 , episodic length : 2656, return: 14.0, exp_count :1769817, averged returnover past 100 episodes : 10.56\n",
            "Q loss: 0.00626467727124691\n",
            "Episode : 868 , episodic length : 2327, return: 11.0, exp_count :1772145, averged returnover past 100 episodes : 10.62\n",
            "Q loss: 0.0017458780203014612\n",
            "Episode : 869 , episodic length : 3088, return: -4.0, exp_count :1775234, averged returnover past 100 episodes : 10.43\n",
            "Episode : 870 , episodic length : 2600, return: 12.0, exp_count :1777835, averged returnover past 100 episodes : 10.4\n",
            "Q loss: 0.0012686856789514422\n",
            "Episode : 871 , episodic length : 2891, return: 9.0, exp_count :1780727, averged returnover past 100 episodes : 10.41\n",
            "Q loss: 0.002933627925813198\n",
            "Episode : 872 , episodic length : 2356, return: 12.0, exp_count :1783084, averged returnover past 100 episodes : 10.4\n",
            "Episode : 873 , episodic length : 2172, return: 15.0, exp_count :1785257, averged returnover past 100 episodes : 10.41\n",
            "Q loss: 0.002247463446110487\n",
            "Episode : 874 , episodic length : 3044, return: 10.0, exp_count :1788302, averged returnover past 100 episodes : 10.41\n",
            "Q loss: 0.0025031098630279303\n",
            "Episode : 875 , episodic length : 2418, return: 11.0, exp_count :1790721, averged returnover past 100 episodes : 10.35\n",
            "Q loss: 0.002876611426472664\n",
            "Episode : 876 , episodic length : 3586, return: 5.0, exp_count :1794308, averged returnover past 100 episodes : 10.33\n",
            "Episode : 877 , episodic length : 2606, return: 14.0, exp_count :1796915, averged returnover past 100 episodes : 10.4\n",
            "Q loss: 0.0015407135942950845\n",
            "Episode : 878 , episodic length : 3625, return: -5.0, exp_count :1800541, averged returnover past 100 episodes : 10.24\n",
            "Q loss: 0.002162462566047907\n",
            "Episode : 879 , episodic length : 2864, return: 9.0, exp_count :1803406, averged returnover past 100 episodes : 10.2\n",
            "Q loss: 0.002384927123785019\n",
            "Episode : 880 , episodic length : 2651, return: 13.0, exp_count :1806058, averged returnover past 100 episodes : 10.19\n",
            "Episode : 881 , episodic length : 2012, return: 19.0, exp_count :1808071, averged returnover past 100 episodes : 10.32\n",
            "Q loss: 0.006627161055803299\n",
            "Episode : 882 , episodic length : 3262, return: 7.0, exp_count :1811334, averged returnover past 100 episodes : 10.29\n",
            "Episode : 883 , episodic length : 2557, return: 14.0, exp_count :1813892, averged returnover past 100 episodes : 10.27\n",
            "Q loss: 0.0012698783539235592\n",
            "Episode : 884 , episodic length : 2784, return: 14.0, exp_count :1816677, averged returnover past 100 episodes : 10.27\n",
            "Q loss: 0.0018548101652413607\n",
            "Episode : 885 , episodic length : 2808, return: 10.0, exp_count :1819486, averged returnover past 100 episodes : 10.23\n",
            "Episode : 886 , episodic length : 2359, return: 12.0, exp_count :1821846, averged returnover past 100 episodes : 10.28\n",
            "Q loss: 0.004964138846844435\n",
            "Episode : 887 , episodic length : 2766, return: 10.0, exp_count :1824613, averged returnover past 100 episodes : 10.28\n",
            "Q loss: 0.0033368063159286976\n",
            "Episode : 888 , episodic length : 2969, return: 9.0, exp_count :1827583, averged returnover past 100 episodes : 10.45\n",
            "Q loss: 0.001334618660621345\n",
            "Episode : 889 , episodic length : 3991, return: 2.0, exp_count :1831575, averged returnover past 100 episodes : 10.65\n",
            "Q loss: 0.002214256441220641\n",
            "Episode : 890 , episodic length : 2777, return: 11.0, exp_count :1834353, averged returnover past 100 episodes : 10.69\n",
            "Q loss: 0.002897923579439521\n",
            "Episode : 891 , episodic length : 3702, return: 4.0, exp_count :1838056, averged returnover past 100 episodes : 10.7\n",
            "Episode : 892 , episodic length : 3834, return: 2.0, exp_count :1841891, averged returnover past 100 episodes : 10.74\n",
            "Q loss: 0.0014397422783076763\n",
            "Q loss: 0.0020230382215231657\n",
            "Episode : 893 , episodic length : 4169, return: -1.0, exp_count :1846061, averged returnover past 100 episodes : 10.56\n",
            "Episode : 894 , episodic length : 2594, return: 11.0, exp_count :1848656, averged returnover past 100 episodes : 10.57\n",
            "Q loss: 0.0013585491105914116\n",
            "Episode : 895 , episodic length : 2587, return: 11.0, exp_count :1851244, averged returnover past 100 episodes : 10.51\n",
            "Episode : 896 , episodic length : 2188, return: 17.0, exp_count :1853433, averged returnover past 100 episodes : 10.51\n",
            "Q loss: 0.0018401127308607101\n",
            "Episode : 897 , episodic length : 2826, return: 12.0, exp_count :1856260, averged returnover past 100 episodes : 10.48\n",
            "Q loss: 0.005004520528018475\n",
            "Episode : 898 , episodic length : 2351, return: 14.0, exp_count :1858612, averged returnover past 100 episodes : 10.44\n",
            "Episode : 899 , episodic length : 2978, return: 9.0, exp_count :1861591, averged returnover past 100 episodes : 10.51\n",
            "-----start Testing------\n",
            "Testing result, Returns: [18. 12. 12. 12. 19. 17. 19. 17. 17. 17. 17. 17. 17. 17. 18.]\n",
            "Q loss: 0.0016582815442234278\n",
            "Episode : 900 , episodic length : 2622, return: 10.0, exp_count :1864214, averged returnover past 100 episodes : 10.45\n",
            "Q loss: 0.0008434524643234909\n",
            "Episode : 901 , episodic length : 3194, return: 4.0, exp_count :1867409, averged returnover past 100 episodes : 10.5\n",
            "Episode : 902 , episodic length : 2569, return: 12.0, exp_count :1869979, averged returnover past 100 episodes : 10.47\n",
            "Q loss: 0.001975312363356352\n",
            "Episode : 903 , episodic length : 2190, return: 19.0, exp_count :1872170, averged returnover past 100 episodes : 10.56\n",
            "Q loss: 0.0018485147738829255\n",
            "Episode : 904 , episodic length : 2430, return: 14.0, exp_count :1874601, averged returnover past 100 episodes : 10.78\n",
            "Episode : 905 , episodic length : 2078, return: 15.0, exp_count :1876680, averged returnover past 100 episodes : 10.79\n",
            "Q loss: 0.00223957234993577\n",
            "Episode : 906 , episodic length : 2125, return: 15.0, exp_count :1878806, averged returnover past 100 episodes : 10.83\n",
            "Episode : 907 , episodic length : 1860, return: 20.0, exp_count :1880667, averged returnover past 100 episodes : 10.91\n",
            "Q loss: 0.0009400722337886691\n",
            "Episode : 908 , episodic length : 3021, return: 14.0, exp_count :1883689, averged returnover past 100 episodes : 10.96\n",
            "Q loss: 0.0004303583991713822\n",
            "Episode : 909 , episodic length : 2412, return: 15.0, exp_count :1886102, averged returnover past 100 episodes : 11.0\n",
            "Episode : 910 , episodic length : 2370, return: 16.0, exp_count :1888473, averged returnover past 100 episodes : 11.04\n",
            "Q loss: 0.00464037898927927\n",
            "Episode : 911 , episodic length : 2332, return: 14.0, exp_count :1890806, averged returnover past 100 episodes : 11.09\n",
            "Episode : 912 , episodic length : 2449, return: 11.0, exp_count :1893256, averged returnover past 100 episodes : 11.1\n",
            "Q loss: 0.0007686703465878963\n",
            "Episode : 913 , episodic length : 2514, return: 14.0, exp_count :1895771, averged returnover past 100 episodes : 11.16\n",
            "Q loss: 0.0029024635441601276\n",
            "Episode : 914 , episodic length : 2365, return: 18.0, exp_count :1898137, averged returnover past 100 episodes : 11.17\n",
            "Episode : 915 , episodic length : 2203, return: 14.0, exp_count :1900341, averged returnover past 100 episodes : 11.19\n",
            "Q loss: 0.0010400093160569668\n",
            "Episode : 916 , episodic length : 2071, return: 17.0, exp_count :1902413, averged returnover past 100 episodes : 11.21\n",
            "Episode : 917 , episodic length : 2701, return: 10.0, exp_count :1905115, averged returnover past 100 episodes : 11.18\n",
            "Q loss: 0.0010368186049163342\n",
            "Episode : 918 , episodic length : 2139, return: 15.0, exp_count :1907255, averged returnover past 100 episodes : 11.17\n",
            "Episode : 919 , episodic length : 2408, return: 13.0, exp_count :1909664, averged returnover past 100 episodes : 11.51\n",
            "Q loss: 0.00112430052831769\n",
            "Episode : 920 , episodic length : 2582, return: 11.0, exp_count :1912247, averged returnover past 100 episodes : 11.51\n",
            "Q loss: 0.003094952553510666\n",
            "Episode : 921 , episodic length : 2087, return: 18.0, exp_count :1914335, averged returnover past 100 episodes : 11.53\n",
            "Episode : 922 , episodic length : 1869, return: 20.0, exp_count :1916205, averged returnover past 100 episodes : 11.55\n",
            "Q loss: 0.0006140954792499542\n",
            "Episode : 923 , episodic length : 2034, return: 18.0, exp_count :1918240, averged returnover past 100 episodes : 11.61\n",
            "Episode : 924 , episodic length : 2350, return: 13.0, exp_count :1920591, averged returnover past 100 episodes : 11.61\n",
            "Q loss: 0.0013875911245122552\n",
            "Episode : 925 , episodic length : 2740, return: 14.0, exp_count :1923332, averged returnover past 100 episodes : 11.79\n",
            "Episode : 926 , episodic length : 1990, return: 17.0, exp_count :1925323, averged returnover past 100 episodes : 11.91\n",
            "Q loss: 0.009659729897975922\n",
            "Episode : 927 , episodic length : 3302, return: 8.0, exp_count :1928626, averged returnover past 100 episodes : 11.93\n",
            "Q loss: 0.002133847214281559\n",
            "Episode : 928 , episodic length : 2362, return: 14.0, exp_count :1930989, averged returnover past 100 episodes : 11.93\n",
            "Q loss: 0.005088278092443943\n",
            "Episode : 929 , episodic length : 3259, return: 8.0, exp_count :1934249, averged returnover past 100 episodes : 11.88\n",
            "Episode : 930 , episodic length : 3473, return: 7.0, exp_count :1937723, averged returnover past 100 episodes : 11.87\n",
            "Q loss: 0.0019378490978851914\n",
            "Episode : 931 , episodic length : 2865, return: 9.0, exp_count :1940589, averged returnover past 100 episodes : 11.81\n",
            "Q loss: 0.0015079835429787636\n",
            "Episode : 932 , episodic length : 2257, return: 14.0, exp_count :1942847, averged returnover past 100 episodes : 11.78\n",
            "Episode : 933 , episodic length : 2346, return: 14.0, exp_count :1945194, averged returnover past 100 episodes : 11.79\n",
            "Q loss: 0.004523707088083029\n",
            "Episode : 934 , episodic length : 2290, return: 13.0, exp_count :1947485, averged returnover past 100 episodes : 11.8\n",
            "Q loss: 0.0011311995331197977\n",
            "Episode : 935 , episodic length : 3115, return: 7.0, exp_count :1950601, averged returnover past 100 episodes : 11.74\n",
            "Episode : 936 , episodic length : 3009, return: 13.0, exp_count :1953611, averged returnover past 100 episodes : 11.72\n",
            "Q loss: 0.0011823198292404413\n",
            "Episode : 937 , episodic length : 2402, return: 14.0, exp_count :1956014, averged returnover past 100 episodes : 11.75\n",
            "Q loss: 0.0008193349931389093\n",
            "Episode : 938 , episodic length : 2846, return: 11.0, exp_count :1958861, averged returnover past 100 episodes : 11.83\n",
            "Episode : 939 , episodic length : 2645, return: 9.0, exp_count :1961507, averged returnover past 100 episodes : 11.76\n",
            "Q loss: 0.0013584891567006707\n",
            "Episode : 940 , episodic length : 2144, return: 16.0, exp_count :1963652, averged returnover past 100 episodes : 11.82\n",
            "Q loss: 0.001185624161735177\n",
            "Episode : 941 , episodic length : 2732, return: 10.0, exp_count :1966385, averged returnover past 100 episodes : 11.8\n",
            "Episode : 942 , episodic length : 2414, return: 13.0, exp_count :1968800, averged returnover past 100 episodes : 11.87\n",
            "Q loss: 0.0019204572308808565\n",
            "Episode : 943 , episodic length : 2742, return: 11.0, exp_count :1971543, averged returnover past 100 episodes : 11.85\n",
            "Episode : 944 , episodic length : 2167, return: 15.0, exp_count :1973711, averged returnover past 100 episodes : 11.92\n",
            "Q loss: 0.0008485067519359291\n",
            "Episode : 945 , episodic length : 2268, return: 12.0, exp_count :1975980, averged returnover past 100 episodes : 11.92\n",
            "Episode : 946 , episodic length : 1891, return: 18.0, exp_count :1977872, averged returnover past 100 episodes : 11.96\n",
            "Q loss: 0.0014371592551469803\n",
            "Episode : 947 , episodic length : 2048, return: 17.0, exp_count :1979921, averged returnover past 100 episodes : 11.97\n",
            "Q loss: 0.0011890329187735915\n",
            "Episode : 948 , episodic length : 2266, return: 12.0, exp_count :1982188, averged returnover past 100 episodes : 11.97\n",
            "Episode : 949 , episodic length : 2700, return: 14.0, exp_count :1984889, averged returnover past 100 episodes : 11.96\n",
            "Q loss: 0.004986905958503485\n",
            "Episode : 950 , episodic length : 2837, return: 10.0, exp_count :1987727, averged returnover past 100 episodes : 11.88\n",
            "Episode : 951 , episodic length : 2222, return: 15.0, exp_count :1989950, averged returnover past 100 episodes : 11.86\n",
            "Q loss: 0.00211296952329576\n",
            "Episode : 952 , episodic length : 2821, return: 8.0, exp_count :1992772, averged returnover past 100 episodes : 11.78\n",
            "Q loss: 0.004400233738124371\n",
            "Episode : 953 , episodic length : 2817, return: 10.0, exp_count :1995590, averged returnover past 100 episodes : 11.74\n",
            "Episode : 954 , episodic length : 2241, return: 16.0, exp_count :1997832, averged returnover past 100 episodes : 11.77\n",
            "Q loss: 0.001139591564424336\n",
            "Episode : 955 , episodic length : 2588, return: 8.0, exp_count :2000421, averged returnover past 100 episodes : 11.72\n",
            "Q loss: 0.003255167743191123\n",
            "Episode : 956 , episodic length : 2346, return: 10.0, exp_count :2002768, averged returnover past 100 episodes : 11.79\n",
            "Episode : 957 , episodic length : 2461, return: 16.0, exp_count :2005230, averged returnover past 100 episodes : 11.82\n",
            "Q loss: 0.0012462773593142629\n",
            "Episode : 958 , episodic length : 2303, return: 14.0, exp_count :2007534, averged returnover past 100 episodes : 11.89\n",
            "Episode : 959 , episodic length : 2442, return: 13.0, exp_count :2009977, averged returnover past 100 episodes : 11.86\n",
            "Q loss: 0.0012994497083127499\n",
            "Episode : 960 , episodic length : 2228, return: 13.0, exp_count :2012206, averged returnover past 100 episodes : 11.88\n",
            "Q loss: 0.0011670584790408611\n",
            "Episode : 961 , episodic length : 3009, return: 6.0, exp_count :2015216, averged returnover past 100 episodes : 11.8\n",
            "Episode : 962 , episodic length : 2723, return: 7.0, exp_count :2017940, averged returnover past 100 episodes : 11.77\n",
            "Q loss: 0.016871070489287376\n",
            "Episode : 963 , episodic length : 2907, return: 8.0, exp_count :2020848, averged returnover past 100 episodes : 11.73\n",
            "Episode : 964 , episodic length : 957, return: -20.0, exp_count :2021806, averged returnover past 100 episodes : 11.4\n",
            "Q loss: 0.002880408428609371\n",
            "Episode : 965 , episodic length : 2621, return: 11.0, exp_count :2024428, averged returnover past 100 episodes : 11.35\n",
            "Q loss: 0.002365182852372527\n",
            "Episode : 966 , episodic length : 3320, return: 2.0, exp_count :2027749, averged returnover past 100 episodes : 11.3\n",
            "Q loss: 0.0007089002756401896\n",
            "Episode : 967 , episodic length : 2590, return: 4.0, exp_count :2030340, averged returnover past 100 episodes : 11.2\n",
            "Episode : 968 , episodic length : 2685, return: 10.0, exp_count :2033026, averged returnover past 100 episodes : 11.19\n",
            "Q loss: 0.004754011984914541\n",
            "Episode : 969 , episodic length : 2387, return: 15.0, exp_count :2035414, averged returnover past 100 episodes : 11.38\n",
            "Q loss: 0.0009251906303688884\n",
            "Episode : 970 , episodic length : 2846, return: 11.0, exp_count :2038261, averged returnover past 100 episodes : 11.37\n",
            "Episode : 971 , episodic length : 2522, return: 14.0, exp_count :2040784, averged returnover past 100 episodes : 11.42\n",
            "Q loss: 0.0010949759744107723\n",
            "Episode : 972 , episodic length : 2314, return: 13.0, exp_count :2043099, averged returnover past 100 episodes : 11.43\n",
            "Q loss: 0.0061083161272108555\n",
            "Episode : 973 , episodic length : 3414, return: 3.0, exp_count :2046514, averged returnover past 100 episodes : 11.31\n",
            "Episode : 974 , episodic length : 2529, return: 12.0, exp_count :2049044, averged returnover past 100 episodes : 11.33\n",
            "Q loss: 0.0010208359453827143\n",
            "Episode : 975 , episodic length : 2555, return: 12.0, exp_count :2051600, averged returnover past 100 episodes : 11.34\n",
            "Q loss: 0.006195072550326586\n",
            "Episode : 976 , episodic length : 2626, return: 13.0, exp_count :2054227, averged returnover past 100 episodes : 11.42\n",
            "Episode : 977 , episodic length : 3019, return: 8.0, exp_count :2057247, averged returnover past 100 episodes : 11.36\n",
            "Q loss: 0.0007340875454246998\n",
            "Episode : 978 , episodic length : 2866, return: 12.0, exp_count :2060114, averged returnover past 100 episodes : 11.53\n",
            "Q loss: 0.0017795269377529621\n",
            "Episode : 979 , episodic length : 3265, return: 5.0, exp_count :2063380, averged returnover past 100 episodes : 11.49\n",
            "Q loss: 0.0010027362732216716\n",
            "Episode : 980 , episodic length : 2839, return: 13.0, exp_count :2066220, averged returnover past 100 episodes : 11.49\n",
            "Episode : 981 , episodic length : 2282, return: 14.0, exp_count :2068503, averged returnover past 100 episodes : 11.44\n",
            "Q loss: 0.001419350504875183\n",
            "Episode : 982 , episodic length : 2311, return: 13.0, exp_count :2070815, averged returnover past 100 episodes : 11.5\n",
            "Q loss: 0.001370514975860715\n",
            "Episode : 983 , episodic length : 3974, return: 3.0, exp_count :2074790, averged returnover past 100 episodes : 11.39\n",
            "Episode : 984 , episodic length : 2746, return: 11.0, exp_count :2077537, averged returnover past 100 episodes : 11.36\n",
            "Q loss: 0.0019132227171212435\n",
            "Episode : 985 , episodic length : 2137, return: 17.0, exp_count :2079675, averged returnover past 100 episodes : 11.43\n",
            "Q loss: 0.002242851071059704\n",
            "Episode : 986 , episodic length : 2379, return: 17.0, exp_count :2082055, averged returnover past 100 episodes : 11.48\n",
            "Episode : 987 , episodic length : 2785, return: 10.0, exp_count :2084841, averged returnover past 100 episodes : 11.48\n",
            "Q loss: 0.0027061221189796925\n",
            "Episode : 988 , episodic length : 2315, return: 15.0, exp_count :2087157, averged returnover past 100 episodes : 11.54\n",
            "Q loss: 0.0007022902718745172\n",
            "Episode : 989 , episodic length : 2902, return: 10.0, exp_count :2090060, averged returnover past 100 episodes : 11.62\n",
            "Episode : 990 , episodic length : 1973, return: 19.0, exp_count :2092034, averged returnover past 100 episodes : 11.7\n",
            "Q loss: 0.001033975393511355\n",
            "Episode : 991 , episodic length : 2203, return: 16.0, exp_count :2094238, averged returnover past 100 episodes : 11.82\n",
            "Episode : 992 , episodic length : 2702, return: 12.0, exp_count :2096941, averged returnover past 100 episodes : 11.92\n",
            "Q loss: 0.0011075757211074233\n",
            "Episode : 993 , episodic length : 1995, return: 17.0, exp_count :2098937, averged returnover past 100 episodes : 12.1\n",
            "Episode : 994 , episodic length : 2151, return: 13.0, exp_count :2101089, averged returnover past 100 episodes : 12.12\n",
            "Q loss: 0.0016642094124108553\n",
            "Episode : 995 , episodic length : 2628, return: 12.0, exp_count :2103718, averged returnover past 100 episodes : 12.13\n",
            "Q loss: 0.01261135097593069\n",
            "Episode : 996 , episodic length : 2678, return: 13.0, exp_count :2106397, averged returnover past 100 episodes : 12.09\n",
            "Episode : 997 , episodic length : 2932, return: 13.0, exp_count :2109330, averged returnover past 100 episodes : 12.1\n",
            "Q loss: 0.0011485298164188862\n",
            "Episode : 998 , episodic length : 2865, return: 13.0, exp_count :2112196, averged returnover past 100 episodes : 12.09\n",
            "Q loss: 0.0015548255760222673\n",
            "Episode : 999 , episodic length : 2007, return: 19.0, exp_count :2114204, averged returnover past 100 episodes : 12.19\n",
            "-----start Testing------\n",
            "Testing result, Returns: [21. 21. 21. 21. 21. 19. 19. 18. 18. 21. 18. 19. 21. 18. 18.]\n",
            "Episode : 1000 , episodic length : 3026, return: 6.0, exp_count :2117231, averged returnover past 100 episodes : 12.15\n",
            "Q loss: 0.000704366946592927\n",
            "Episode : 1001 , episodic length : 2278, return: 15.0, exp_count :2119510, averged returnover past 100 episodes : 12.26\n",
            "Episode : 1002 , episodic length : 2481, return: 13.0, exp_count :2121992, averged returnover past 100 episodes : 12.27\n",
            "Q loss: 0.0008911484619602561\n",
            "Episode : 1003 , episodic length : 2450, return: 15.0, exp_count :2124443, averged returnover past 100 episodes : 12.23\n",
            "Q loss: 0.0012561376206576824\n",
            "Episode : 1004 , episodic length : 2147, return: 17.0, exp_count :2126591, averged returnover past 100 episodes : 12.26\n",
            "Episode : 1005 , episodic length : 2804, return: 12.0, exp_count :2129396, averged returnover past 100 episodes : 12.23\n",
            "Q loss: 0.000972188834566623\n",
            "Episode : 1006 , episodic length : 2527, return: -8.0, exp_count :2131924, averged returnover past 100 episodes : 12.0\n",
            "Q loss: 0.0008440415840595961\n",
            "Episode : 1007 , episodic length : 2794, return: 13.0, exp_count :2134719, averged returnover past 100 episodes : 11.93\n",
            "Episode : 1008 , episodic length : 3016, return: 11.0, exp_count :2137736, averged returnover past 100 episodes : 11.9\n",
            "Q loss: 0.0023010103031992912\n",
            "Episode : 1009 , episodic length : 1887, return: 19.0, exp_count :2139624, averged returnover past 100 episodes : 11.94\n",
            "Episode : 1010 , episodic length : 1848, return: 18.0, exp_count :2141473, averged returnover past 100 episodes : 11.96\n",
            "Q loss: 0.001506459666416049\n",
            "Episode : 1011 , episodic length : 1890, return: 18.0, exp_count :2143364, averged returnover past 100 episodes : 12.0\n",
            "Episode : 1012 , episodic length : 2518, return: 14.0, exp_count :2145883, averged returnover past 100 episodes : 12.03\n",
            "Q loss: 0.001029334613122046\n",
            "Episode : 1013 , episodic length : 1924, return: 19.0, exp_count :2147808, averged returnover past 100 episodes : 12.08\n",
            "Q loss: 0.0013116293121129274\n",
            "Episode : 1014 , episodic length : 2530, return: 11.0, exp_count :2150339, averged returnover past 100 episodes : 12.01\n",
            "Episode : 1015 , episodic length : 2629, return: 12.0, exp_count :2152969, averged returnover past 100 episodes : 11.99\n",
            "Q loss: 0.004393667448312044\n",
            "Episode : 1016 , episodic length : 2447, return: 16.0, exp_count :2155417, averged returnover past 100 episodes : 11.98\n",
            "Episode : 1017 , episodic length : 2306, return: 16.0, exp_count :2157724, averged returnover past 100 episodes : 12.04\n",
            "Q loss: 0.001227772794663906\n",
            "Episode : 1018 , episodic length : 2152, return: 13.0, exp_count :2159877, averged returnover past 100 episodes : 12.02\n",
            "Episode : 1019 , episodic length : 2019, return: 19.0, exp_count :2161897, averged returnover past 100 episodes : 12.08\n",
            "Q loss: 0.0008656168356537819\n",
            "Episode : 1020 , episodic length : 2440, return: 12.0, exp_count :2164338, averged returnover past 100 episodes : 12.09\n",
            "Q loss: 0.013200832530856133\n",
            "Episode : 1021 , episodic length : 2160, return: 16.0, exp_count :2166499, averged returnover past 100 episodes : 12.07\n",
            "Episode : 1022 , episodic length : 2438, return: 13.0, exp_count :2168938, averged returnover past 100 episodes : 12.0\n",
            "Q loss: 0.0007364271441474557\n",
            "Episode : 1023 , episodic length : 2209, return: 16.0, exp_count :2171148, averged returnover past 100 episodes : 11.98\n",
            "Episode : 1024 , episodic length : 1864, return: 17.0, exp_count :2173013, averged returnover past 100 episodes : 12.02\n",
            "Q loss: 0.0010289351921528578\n",
            "Episode : 1025 , episodic length : 2033, return: 16.0, exp_count :2175047, averged returnover past 100 episodes : 12.04\n",
            "Episode : 1026 , episodic length : 2496, return: 13.0, exp_count :2177544, averged returnover past 100 episodes : 12.0\n",
            "Q loss: 0.004067818634212017\n",
            "Episode : 1027 , episodic length : 3317, return: 12.0, exp_count :2180862, averged returnover past 100 episodes : 12.04\n",
            "Q loss: 0.0008917109807953238\n",
            "Episode : 1028 , episodic length : 1981, return: 18.0, exp_count :2182844, averged returnover past 100 episodes : 12.08\n",
            "Episode : 1029 , episodic length : 2291, return: 14.0, exp_count :2185136, averged returnover past 100 episodes : 12.14\n",
            "Q loss: 0.0012450392823666334\n",
            "Episode : 1030 , episodic length : 2701, return: 12.0, exp_count :2187838, averged returnover past 100 episodes : 12.19\n",
            "Episode : 1031 , episodic length : 2088, return: 17.0, exp_count :2189927, averged returnover past 100 episodes : 12.27\n",
            "Q loss: 0.002515691565349698\n",
            "Episode : 1032 , episodic length : 2042, return: 18.0, exp_count :2191970, averged returnover past 100 episodes : 12.31\n",
            "Q loss: 0.0009371709893457592\n",
            "Episode : 1033 , episodic length : 3414, return: 8.0, exp_count :2195385, averged returnover past 100 episodes : 12.25\n",
            "Episode : 1034 , episodic length : 2484, return: 13.0, exp_count :2197870, averged returnover past 100 episodes : 12.25\n",
            "Q loss: 0.014070221222937107\n",
            "Episode : 1035 , episodic length : 2070, return: 16.0, exp_count :2199941, averged returnover past 100 episodes : 12.34\n",
            "Q loss: 0.0017462116666138172\n",
            "Episode : 1036 , episodic length : 2529, return: 11.0, exp_count :2202471, averged returnover past 100 episodes : 12.32\n",
            "Episode : 1037 , episodic length : 2226, return: 13.0, exp_count :2204698, averged returnover past 100 episodes : 12.31\n",
            "Q loss: 0.0010992103489115834\n",
            "Episode : 1038 , episodic length : 2546, return: 16.0, exp_count :2207245, averged returnover past 100 episodes : 12.36\n",
            "Episode : 1039 , episodic length : 2324, return: 18.0, exp_count :2209570, averged returnover past 100 episodes : 12.45\n",
            "Q loss: 0.0006295478669926524\n",
            "Episode : 1040 , episodic length : 2326, return: 14.0, exp_count :2211897, averged returnover past 100 episodes : 12.43\n",
            "Q loss: 0.0013638325035572052\n",
            "Episode : 1041 , episodic length : 2260, return: 12.0, exp_count :2214158, averged returnover past 100 episodes : 12.45\n",
            "Episode : 1042 , episodic length : 2220, return: 17.0, exp_count :2216379, averged returnover past 100 episodes : 12.49\n",
            "Q loss: 0.006076853256672621\n",
            "Episode : 1043 , episodic length : 2084, return: 18.0, exp_count :2218464, averged returnover past 100 episodes : 12.56\n",
            "Episode : 1044 , episodic length : 2402, return: 14.0, exp_count :2220867, averged returnover past 100 episodes : 12.55\n",
            "Q loss: 0.0012967807706445456\n",
            "Episode : 1045 , episodic length : 3253, return: -3.0, exp_count :2224121, averged returnover past 100 episodes : 12.4\n",
            "Q loss: 0.0024851919151842594\n",
            "Episode : 1046 , episodic length : 2496, return: 8.0, exp_count :2226618, averged returnover past 100 episodes : 12.3\n",
            "Episode : 1047 , episodic length : 2028, return: 17.0, exp_count :2228647, averged returnover past 100 episodes : 12.3\n",
            "Q loss: 0.0024146707728505135\n",
            "Episode : 1048 , episodic length : 2661, return: 14.0, exp_count :2231309, averged returnover past 100 episodes : 12.32\n",
            "Episode : 1049 , episodic length : 2332, return: 16.0, exp_count :2233642, averged returnover past 100 episodes : 12.34\n",
            "Q loss: 0.0015594386495649815\n",
            "Episode : 1050 , episodic length : 2037, return: 19.0, exp_count :2235680, averged returnover past 100 episodes : 12.43\n",
            "Episode : 1051 , episodic length : 2076, return: 17.0, exp_count :2237757, averged returnover past 100 episodes : 12.45\n",
            "Q loss: 0.005143921822309494\n",
            "Episode : 1052 , episodic length : 2561, return: 15.0, exp_count :2240319, averged returnover past 100 episodes : 12.52\n",
            "Q loss: 0.004245106130838394\n",
            "Episode : 1053 , episodic length : 2558, return: 12.0, exp_count :2242878, averged returnover past 100 episodes : 12.54\n",
            "Episode : 1054 , episodic length : 2585, return: 11.0, exp_count :2245464, averged returnover past 100 episodes : 12.49\n",
            "Q loss: 0.003838564967736602\n",
            "Episode : 1055 , episodic length : 1929, return: 18.0, exp_count :2247394, averged returnover past 100 episodes : 12.59\n",
            "Episode : 1056 , episodic length : 2393, return: 14.0, exp_count :2249788, averged returnover past 100 episodes : 12.63\n",
            "Q loss: 0.0013451683335006237\n",
            "Episode : 1057 , episodic length : 2299, return: 11.0, exp_count :2252088, averged returnover past 100 episodes : 12.58\n",
            "Q loss: 0.001076473155990243\n",
            "Episode : 1058 , episodic length : 2858, return: 8.0, exp_count :2254947, averged returnover past 100 episodes : 12.52\n",
            "Episode : 1059 , episodic length : 2099, return: 18.0, exp_count :2257047, averged returnover past 100 episodes : 12.57\n",
            "Q loss: 0.0009577987948432565\n",
            "Episode : 1060 , episodic length : 2497, return: 15.0, exp_count :2259545, averged returnover past 100 episodes : 12.59\n",
            "Episode : 1061 , episodic length : 2362, return: 14.0, exp_count :2261908, averged returnover past 100 episodes : 12.67\n",
            "Q loss: 0.009808345697820187\n",
            "Episode : 1062 , episodic length : 2408, return: 14.0, exp_count :2264317, averged returnover past 100 episodes : 12.74\n",
            "Q loss: 0.002702892990782857\n",
            "Episode : 1063 , episodic length : 2020, return: 17.0, exp_count :2266338, averged returnover past 100 episodes : 12.83\n",
            "Episode : 1064 , episodic length : 2069, return: 17.0, exp_count :2268408, averged returnover past 100 episodes : 13.2\n",
            "Q loss: 0.0009087647777050734\n",
            "Episode : 1065 , episodic length : 2430, return: 12.0, exp_count :2270839, averged returnover past 100 episodes : 13.21\n",
            "Episode : 1066 , episodic length : 2915, return: 13.0, exp_count :2273755, averged returnover past 100 episodes : 13.32\n",
            "Q loss: 0.0008497174130752683\n",
            "Episode : 1067 , episodic length : 2769, return: 6.0, exp_count :2276525, averged returnover past 100 episodes : 13.34\n",
            "Q loss: 0.0013635032810270786\n",
            "Episode : 1068 , episodic length : 2847, return: 6.0, exp_count :2279373, averged returnover past 100 episodes : 13.3\n",
            "Q loss: 0.003588766325265169\n",
            "Episode : 1069 , episodic length : 2887, return: 9.0, exp_count :2282261, averged returnover past 100 episodes : 13.24\n",
            "Episode : 1070 , episodic length : 2891, return: 6.0, exp_count :2285153, averged returnover past 100 episodes : 13.19\n",
            "Q loss: 0.0013501615030691028\n",
            "Episode : 1071 , episodic length : 2400, return: 13.0, exp_count :2287554, averged returnover past 100 episodes : 13.18\n",
            "Episode : 1072 , episodic length : 2328, return: 12.0, exp_count :2289883, averged returnover past 100 episodes : 13.17\n",
            "Q loss: 0.0009137081797234714\n",
            "Episode : 1073 , episodic length : 2513, return: 10.0, exp_count :2292397, averged returnover past 100 episodes : 13.24\n",
            "Q loss: 0.0021801942493766546\n",
            "Episode : 1074 , episodic length : 2296, return: 16.0, exp_count :2294694, averged returnover past 100 episodes : 13.28\n",
            "Episode : 1075 , episodic length : 2354, return: 13.0, exp_count :2297049, averged returnover past 100 episodes : 13.29\n",
            "Q loss: 0.0015436825342476368\n",
            "Episode : 1076 , episodic length : 2821, return: 10.0, exp_count :2299871, averged returnover past 100 episodes : 13.26\n",
            "Q loss: 0.0005868367152288556\n",
            "Episode : 1077 , episodic length : 2465, return: 19.0, exp_count :2302337, averged returnover past 100 episodes : 13.37\n",
            "Episode : 1078 , episodic length : 2159, return: 16.0, exp_count :2304497, averged returnover past 100 episodes : 13.41\n",
            "Q loss: 0.0009371375199407339\n",
            "Episode : 1079 , episodic length : 2795, return: 9.0, exp_count :2307293, averged returnover past 100 episodes : 13.45\n",
            "Episode : 1080 , episodic length : 2198, return: 17.0, exp_count :2309492, averged returnover past 100 episodes : 13.49\n",
            "Q loss: 0.000947728636674583\n",
            "Episode : 1081 , episodic length : 2314, return: 15.0, exp_count :2311807, averged returnover past 100 episodes : 13.5\n",
            "Q loss: 0.005049411207437515\n",
            "Episode : 1082 , episodic length : 2407, return: 17.0, exp_count :2314215, averged returnover past 100 episodes : 13.54\n",
            "Episode : 1083 , episodic length : 2956, return: 8.0, exp_count :2317172, averged returnover past 100 episodes : 13.59\n",
            "Q loss: 0.0006433222442865372\n",
            "Episode : 1084 , episodic length : 2614, return: 12.0, exp_count :2319787, averged returnover past 100 episodes : 13.6\n",
            "Q loss: 0.0014340372290462255\n",
            "Episode : 1085 , episodic length : 2684, return: 12.0, exp_count :2322472, averged returnover past 100 episodes : 13.55\n",
            "Episode : 1086 , episodic length : 2530, return: 15.0, exp_count :2325003, averged returnover past 100 episodes : 13.53\n",
            "Q loss: 0.00325410021468997\n",
            "Episode : 1087 , episodic length : 1945, return: 18.0, exp_count :2326949, averged returnover past 100 episodes : 13.61\n",
            "Episode : 1088 , episodic length : 2370, return: 16.0, exp_count :2329320, averged returnover past 100 episodes : 13.62\n",
            "Q loss: 0.0009881104342639446\n",
            "Episode : 1089 , episodic length : 2346, return: 13.0, exp_count :2331667, averged returnover past 100 episodes : 13.65\n",
            "Q loss: 0.0008667426882311702\n",
            "Episode : 1090 , episodic length : 2534, return: 13.0, exp_count :2334202, averged returnover past 100 episodes : 13.59\n",
            "Episode : 1091 , episodic length : 2629, return: 11.0, exp_count :2336832, averged returnover past 100 episodes : 13.54\n",
            "Q loss: 0.0007412444101646543\n",
            "Episode : 1092 , episodic length : 2853, return: 11.0, exp_count :2339686, averged returnover past 100 episodes : 13.53\n",
            "Q loss: 0.020369915291666985\n",
            "Episode : 1093 , episodic length : 2335, return: 12.0, exp_count :2342022, averged returnover past 100 episodes : 13.48\n",
            "Episode : 1094 , episodic length : 2420, return: 15.0, exp_count :2344443, averged returnover past 100 episodes : 13.5\n",
            "Q loss: 0.0006584018701687455\n",
            "Episode : 1095 , episodic length : 1872, return: 18.0, exp_count :2346316, averged returnover past 100 episodes : 13.56\n",
            "Episode : 1096 , episodic length : 2483, return: 13.0, exp_count :2348800, averged returnover past 100 episodes : 13.56\n",
            "Q loss: 0.0012926231138408184\n",
            "Episode : 1097 , episodic length : 2459, return: 14.0, exp_count :2351260, averged returnover past 100 episodes : 13.57\n",
            "Episode : 1098 , episodic length : 2230, return: 16.0, exp_count :2353491, averged returnover past 100 episodes : 13.6\n",
            "Q loss: 0.0022430862300097942\n",
            "Episode : 1099 , episodic length : 1960, return: 17.0, exp_count :2355452, averged returnover past 100 episodes : 13.58\n",
            "-----start Testing------\n",
            "Testing result, Returns: [16. 19. 19. 19. 16. 17. 16. 16. 18. 16. 19. 18. 14. 16. 16.]\n",
            "Q loss: 0.000497115426696837\n",
            "Episode : 1100 , episodic length : 2552, return: 12.0, exp_count :2358005, averged returnover past 100 episodes : 13.64\n",
            "Episode : 1101 , episodic length : 2667, return: 10.0, exp_count :2360673, averged returnover past 100 episodes : 13.59\n",
            "Q loss: 0.0020524966530501842\n",
            "Episode : 1102 , episodic length : 2559, return: 14.0, exp_count :2363233, averged returnover past 100 episodes : 13.6\n",
            "Episode : 1103 , episodic length : 2198, return: 14.0, exp_count :2365432, averged returnover past 100 episodes : 13.59\n",
            "Q loss: 0.001677395310252905\n",
            "Episode : 1104 , episodic length : 2443, return: 15.0, exp_count :2367876, averged returnover past 100 episodes : 13.57\n",
            "Q loss: 0.004787107929587364\n",
            "Episode : 1105 , episodic length : 2942, return: 8.0, exp_count :2370819, averged returnover past 100 episodes : 13.53\n",
            "Episode : 1106 , episodic length : 2800, return: 10.0, exp_count :2373620, averged returnover past 100 episodes : 13.71\n",
            "Q loss: 0.001470709452405572\n",
            "Episode : 1107 , episodic length : 2021, return: 18.0, exp_count :2375642, averged returnover past 100 episodes : 13.76\n",
            "Episode : 1108 , episodic length : 2213, return: 14.0, exp_count :2377856, averged returnover past 100 episodes : 13.79\n",
            "Q loss: 0.0010362829780206084\n",
            "Episode : 1109 , episodic length : 2691, return: 13.0, exp_count :2380548, averged returnover past 100 episodes : 13.73\n",
            "Q loss: 0.001092906342819333\n",
            "Episode : 1110 , episodic length : 1731, return: 19.0, exp_count :2382280, averged returnover past 100 episodes : 13.74\n",
            "Episode : 1111 , episodic length : 2678, return: 13.0, exp_count :2384959, averged returnover past 100 episodes : 13.69\n",
            "Q loss: 0.0005863867118023336\n",
            "Episode : 1112 , episodic length : 2175, return: 16.0, exp_count :2387135, averged returnover past 100 episodes : 13.71\n",
            "Episode : 1113 , episodic length : 2756, return: 10.0, exp_count :2389892, averged returnover past 100 episodes : 13.62\n",
            "Q loss: 0.0014767020475119352\n",
            "Episode : 1114 , episodic length : 2188, return: 16.0, exp_count :2392081, averged returnover past 100 episodes : 13.67\n",
            "Q loss: 0.0012810748303309083\n",
            "Episode : 1115 , episodic length : 2180, return: 17.0, exp_count :2394262, averged returnover past 100 episodes : 13.72\n",
            "Episode : 1116 , episodic length : 2085, return: 16.0, exp_count :2396348, averged returnover past 100 episodes : 13.72\n",
            "Q loss: 0.0019275953527539968\n",
            "Episode : 1117 , episodic length : 2167, return: 16.0, exp_count :2398516, averged returnover past 100 episodes : 13.72\n",
            "Episode : 1118 , episodic length : 2149, return: 15.0, exp_count :2400666, averged returnover past 100 episodes : 13.74\n",
            "Q loss: 0.002818536479026079\n",
            "Episode : 1119 , episodic length : 2320, return: 14.0, exp_count :2402987, averged returnover past 100 episodes : 13.69\n",
            "Episode : 1120 , episodic length : 2836, return: 13.0, exp_count :2405824, averged returnover past 100 episodes : 13.7\n",
            "Q loss: 0.001737860613502562\n",
            "Episode : 1121 , episodic length : 2825, return: 11.0, exp_count :2408650, averged returnover past 100 episodes : 13.65\n",
            "Q loss: 0.009495427832007408\n",
            "Episode : 1122 , episodic length : 1836, return: 20.0, exp_count :2410487, averged returnover past 100 episodes : 13.72\n",
            "Episode : 1123 , episodic length : 2136, return: 16.0, exp_count :2412624, averged returnover past 100 episodes : 13.72\n",
            "Q loss: 0.002923309337347746\n",
            "Episode : 1124 , episodic length : 2325, return: 16.0, exp_count :2414950, averged returnover past 100 episodes : 13.71\n",
            "Episode : 1125 , episodic length : 2232, return: 14.0, exp_count :2417183, averged returnover past 100 episodes : 13.69\n",
            "Q loss: 0.001467633293941617\n",
            "Episode : 1126 , episodic length : 2396, return: 15.0, exp_count :2419580, averged returnover past 100 episodes : 13.71\n",
            "Episode : 1127 , episodic length : 2112, return: 16.0, exp_count :2421693, averged returnover past 100 episodes : 13.75\n",
            "Q loss: 0.0008942040149122477\n",
            "Episode : 1128 , episodic length : 2055, return: 16.0, exp_count :2423749, averged returnover past 100 episodes : 13.73\n",
            "Episode : 1129 , episodic length : 2039, return: 16.0, exp_count :2425789, averged returnover past 100 episodes : 13.75\n",
            "Q loss: 0.0009178674081340432\n",
            "Episode : 1130 , episodic length : 2274, return: 15.0, exp_count :2428064, averged returnover past 100 episodes : 13.78\n",
            "Q loss: 0.0015715775080025196\n",
            "Episode : 1131 , episodic length : 2613, return: 14.0, exp_count :2430678, averged returnover past 100 episodes : 13.75\n",
            "Episode : 1132 , episodic length : 3018, return: 8.0, exp_count :2433697, averged returnover past 100 episodes : 13.65\n",
            "Q loss: 0.001440864522010088\n",
            "Episode : 1133 , episodic length : 3457, return: 6.0, exp_count :2437155, averged returnover past 100 episodes : 13.63\n",
            "Q loss: 0.002155541442334652\n",
            "Episode : 1134 , episodic length : 2699, return: 10.0, exp_count :2439855, averged returnover past 100 episodes : 13.6\n",
            "Episode : 1135 , episodic length : 2098, return: 17.0, exp_count :2441954, averged returnover past 100 episodes : 13.61\n",
            "Q loss: 0.000986292026937008\n",
            "Episode : 1136 , episodic length : 3151, return: 7.0, exp_count :2445106, averged returnover past 100 episodes : 13.57\n",
            "Q loss: 0.0011889501474797726\n",
            "Episode : 1137 , episodic length : 2182, return: 13.0, exp_count :2447289, averged returnover past 100 episodes : 13.57\n",
            "Episode : 1138 , episodic length : 2046, return: 17.0, exp_count :2449336, averged returnover past 100 episodes : 13.58\n",
            "Q loss: 0.0006999476463533938\n",
            "Episode : 1139 , episodic length : 1771, return: 21.0, exp_count :2451108, averged returnover past 100 episodes : 13.61\n",
            "Episode : 1140 , episodic length : 2194, return: 19.0, exp_count :2453303, averged returnover past 100 episodes : 13.66\n",
            "Q loss: 0.0005853544571436942\n",
            "Episode : 1141 , episodic length : 2530, return: 11.0, exp_count :2455834, averged returnover past 100 episodes : 13.65\n",
            "Q loss: 0.0019375996198505163\n",
            "Episode : 1142 , episodic length : 2256, return: 12.0, exp_count :2458091, averged returnover past 100 episodes : 13.6\n",
            "Episode : 1143 , episodic length : 2296, return: 17.0, exp_count :2460388, averged returnover past 100 episodes : 13.59\n",
            "Q loss: 0.001267777755856514\n",
            "Episode : 1144 , episodic length : 2174, return: 16.0, exp_count :2462563, averged returnover past 100 episodes : 13.61\n",
            "Episode : 1145 , episodic length : 2827, return: 11.0, exp_count :2465391, averged returnover past 100 episodes : 13.75\n",
            "Q loss: 0.0004610337200574577\n",
            "Episode : 1146 , episodic length : 2401, return: 14.0, exp_count :2467793, averged returnover past 100 episodes : 13.81\n",
            "Q loss: 0.0009438767447136343\n",
            "Episode : 1147 , episodic length : 2594, return: 12.0, exp_count :2470388, averged returnover past 100 episodes : 13.76\n",
            "Episode : 1148 , episodic length : 2109, return: 16.0, exp_count :2472498, averged returnover past 100 episodes : 13.78\n",
            "Q loss: 0.0006798927788622677\n",
            "Episode : 1149 , episodic length : 2832, return: 11.0, exp_count :2475331, averged returnover past 100 episodes : 13.73\n",
            "Episode : 1150 , episodic length : 2279, return: 11.0, exp_count :2477611, averged returnover past 100 episodes : 13.65\n",
            "Q loss: 0.0016655824147164822\n",
            "Episode : 1151 , episodic length : 1793, return: 19.0, exp_count :2479405, averged returnover past 100 episodes : 13.67\n",
            "Episode : 1152 , episodic length : 2149, return: 15.0, exp_count :2481555, averged returnover past 100 episodes : 13.67\n",
            "Q loss: 0.005307858809828758\n",
            "Episode : 1153 , episodic length : 2460, return: 18.0, exp_count :2484016, averged returnover past 100 episodes : 13.73\n",
            "Q loss: 0.0014439622173085809\n",
            "Episode : 1154 , episodic length : 2076, return: 18.0, exp_count :2486093, averged returnover past 100 episodes : 13.8\n",
            "Episode : 1155 , episodic length : 2437, return: 13.0, exp_count :2488531, averged returnover past 100 episodes : 13.75\n",
            "Q loss: 0.0007215629448182881\n",
            "Episode : 1156 , episodic length : 2524, return: 12.0, exp_count :2491056, averged returnover past 100 episodes : 13.73\n",
            "Episode : 1157 , episodic length : 2152, return: 15.0, exp_count :2493209, averged returnover past 100 episodes : 13.77\n",
            "Q loss: 0.003447213675826788\n",
            "Episode : 1158 , episodic length : 1949, return: 20.0, exp_count :2495159, averged returnover past 100 episodes : 13.89\n",
            "Episode : 1159 , episodic length : 2222, return: 16.0, exp_count :2497382, averged returnover past 100 episodes : 13.87\n",
            "Q loss: 0.00042437680531293154\n",
            "Episode : 1160 , episodic length : 2437, return: 17.0, exp_count :2499820, averged returnover past 100 episodes : 13.89\n",
            "Q loss: 0.0019942710641771555\n",
            "Episode : 1161 , episodic length : 2342, return: 14.0, exp_count :2502163, averged returnover past 100 episodes : 13.89\n",
            "Episode : 1162 , episodic length : 1983, return: 17.0, exp_count :2504147, averged returnover past 100 episodes : 13.92\n",
            "Q loss: 0.0012394303921610117\n",
            "Episode : 1163 , episodic length : 2354, return: 13.0, exp_count :2506502, averged returnover past 100 episodes : 13.88\n",
            "Episode : 1164 , episodic length : 1974, return: 18.0, exp_count :2508477, averged returnover past 100 episodes : 13.89\n",
            "Q loss: 0.001187919988296926\n",
            "Episode : 1165 , episodic length : 2137, return: 17.0, exp_count :2510615, averged returnover past 100 episodes : 13.94\n",
            "Episode : 1166 , episodic length : 2484, return: 11.0, exp_count :2513100, averged returnover past 100 episodes : 13.92\n",
            "Q loss: 0.0006824721931479871\n",
            "Episode : 1167 , episodic length : 2508, return: 15.0, exp_count :2515609, averged returnover past 100 episodes : 14.01\n",
            "Episode : 1168 , episodic length : 2344, return: 15.0, exp_count :2517954, averged returnover past 100 episodes : 14.1\n",
            "Q loss: 0.0010456425370648503\n",
            "Episode : 1169 , episodic length : 2479, return: 12.0, exp_count :2520434, averged returnover past 100 episodes : 14.13\n",
            "Q loss: 0.005266512278467417\n",
            "Episode : 1170 , episodic length : 2045, return: 19.0, exp_count :2522480, averged returnover past 100 episodes : 14.26\n",
            "Episode : 1171 , episodic length : 2994, return: 4.0, exp_count :2525475, averged returnover past 100 episodes : 14.17\n",
            "Q loss: 0.0018226231914013624\n",
            "Episode : 1172 , episodic length : 1727, return: 19.0, exp_count :2527203, averged returnover past 100 episodes : 14.24\n",
            "Episode : 1173 , episodic length : 1926, return: 18.0, exp_count :2529130, averged returnover past 100 episodes : 14.32\n",
            "Q loss: 0.0034147994592785835\n",
            "Episode : 1174 , episodic length : 2177, return: 16.0, exp_count :2531308, averged returnover past 100 episodes : 14.32\n",
            "Episode : 1175 , episodic length : 2161, return: 18.0, exp_count :2533470, averged returnover past 100 episodes : 14.37\n",
            "Q loss: 0.00039937475230544806\n",
            "Episode : 1176 , episodic length : 2457, return: -5.0, exp_count :2535928, averged returnover past 100 episodes : 14.22\n",
            "Episode : 1177 , episodic length : 1914, return: 16.0, exp_count :2537843, averged returnover past 100 episodes : 14.19\n",
            "Q loss: 0.0008447442669421434\n",
            "Episode : 1178 , episodic length : 2091, return: 16.0, exp_count :2539935, averged returnover past 100 episodes : 14.19\n",
            "Episode : 1179 , episodic length : 1910, return: 20.0, exp_count :2541846, averged returnover past 100 episodes : 14.3\n",
            "Q loss: 0.002981704194098711\n",
            "Episode : 1180 , episodic length : 2172, return: 17.0, exp_count :2544019, averged returnover past 100 episodes : 14.3\n",
            "Q loss: 0.001410425640642643\n",
            "Episode : 1181 , episodic length : 2226, return: 15.0, exp_count :2546246, averged returnover past 100 episodes : 14.3\n",
            "Episode : 1182 , episodic length : 2549, return: 13.0, exp_count :2548796, averged returnover past 100 episodes : 14.26\n",
            "Q loss: 0.0022073141299188137\n",
            "Episode : 1183 , episodic length : 2015, return: 18.0, exp_count :2550812, averged returnover past 100 episodes : 14.36\n",
            "Episode : 1184 , episodic length : 2143, return: 17.0, exp_count :2552956, averged returnover past 100 episodes : 14.41\n",
            "Q loss: 0.0010616977233439684\n",
            "Episode : 1185 , episodic length : 2296, return: 16.0, exp_count :2555253, averged returnover past 100 episodes : 14.45\n",
            "Episode : 1186 , episodic length : 2382, return: 15.0, exp_count :2557636, averged returnover past 100 episodes : 14.45\n",
            "Q loss: 0.0015900570433586836\n",
            "Episode : 1187 , episodic length : 1686, return: 21.0, exp_count :2559323, averged returnover past 100 episodes : 14.48\n",
            "Episode : 1188 , episodic length : 2519, return: 16.0, exp_count :2561843, averged returnover past 100 episodes : 14.48\n",
            "Q loss: 0.001825702958740294\n",
            "Episode : 1189 , episodic length : 2162, return: 14.0, exp_count :2564006, averged returnover past 100 episodes : 14.49\n",
            "Episode : 1190 , episodic length : 1895, return: 18.0, exp_count :2565902, averged returnover past 100 episodes : 14.54\n",
            "Q loss: 0.0024573570117354393\n",
            "Episode : 1191 , episodic length : 2494, return: 15.0, exp_count :2568397, averged returnover past 100 episodes : 14.58\n",
            "Q loss: 0.0010902700014412403\n",
            "Episode : 1192 , episodic length : 1816, return: 19.0, exp_count :2570214, averged returnover past 100 episodes : 14.66\n",
            "Episode : 1193 , episodic length : 2510, return: 8.0, exp_count :2572725, averged returnover past 100 episodes : 14.62\n",
            "Q loss: 0.0006650750292465091\n",
            "Episode : 1194 , episodic length : 2531, return: 6.0, exp_count :2575257, averged returnover past 100 episodes : 14.53\n",
            "Episode : 1195 , episodic length : 2296, return: 13.0, exp_count :2577554, averged returnover past 100 episodes : 14.48\n",
            "Q loss: 0.0007883597281761467\n",
            "Episode : 1196 , episodic length : 2265, return: 13.0, exp_count :2579820, averged returnover past 100 episodes : 14.48\n",
            "Q loss: 0.000992035260424018\n",
            "Episode : 1197 , episodic length : 2612, return: 9.0, exp_count :2582433, averged returnover past 100 episodes : 14.43\n",
            "Episode : 1198 , episodic length : 2613, return: 9.0, exp_count :2585047, averged returnover past 100 episodes : 14.36\n",
            "Q loss: 0.001242316560819745\n",
            "Episode : 1199 , episodic length : 2273, return: 12.0, exp_count :2587321, averged returnover past 100 episodes : 14.31\n",
            "-----start Testing------\n",
            "Testing result, Returns: [20. 20. 20. 21. 20. 20. 21. 20. 20. 20. 19. 19. 19. 21. 20.]\n",
            "Q loss: 0.0019028093665838242\n",
            "Episode : 1200 , episodic length : 2905, return: 12.0, exp_count :2590227, averged returnover past 100 episodes : 14.31\n",
            "Episode : 1201 , episodic length : 2117, return: 18.0, exp_count :2592345, averged returnover past 100 episodes : 14.39\n",
            "Q loss: 0.0020161266438663006\n",
            "Episode : 1202 , episodic length : 2137, return: 16.0, exp_count :2594483, averged returnover past 100 episodes : 14.41\n",
            "Episode : 1203 , episodic length : 2628, return: 12.0, exp_count :2597112, averged returnover past 100 episodes : 14.39\n",
            "Q loss: 0.0009551566326990724\n",
            "Episode : 1204 , episodic length : 1794, return: 21.0, exp_count :2598907, averged returnover past 100 episodes : 14.45\n",
            "Episode : 1205 , episodic length : 2119, return: 17.0, exp_count :2601027, averged returnover past 100 episodes : 14.54\n",
            "Q loss: 0.0034056133590638638\n",
            "Episode : 1206 , episodic length : 2165, return: 11.0, exp_count :2603193, averged returnover past 100 episodes : 14.55\n",
            "Episode : 1207 , episodic length : 2233, return: 13.0, exp_count :2605427, averged returnover past 100 episodes : 14.5\n",
            "Q loss: 0.0009070242522284389\n",
            "Episode : 1208 , episodic length : 1937, return: 18.0, exp_count :2607365, averged returnover past 100 episodes : 14.54\n",
            "Episode : 1209 , episodic length : 2242, return: 13.0, exp_count :2609608, averged returnover past 100 episodes : 14.54\n",
            "Q loss: 0.0011904200073331594\n",
            "Episode : 1210 , episodic length : 2543, return: 14.0, exp_count :2612152, averged returnover past 100 episodes : 14.49\n",
            "Q loss: 0.0019476383458822966\n",
            "Episode : 1211 , episodic length : 2597, return: 14.0, exp_count :2614750, averged returnover past 100 episodes : 14.5\n",
            "Episode : 1212 , episodic length : 2141, return: 15.0, exp_count :2616892, averged returnover past 100 episodes : 14.49\n",
            "Q loss: 0.0006754177156835794\n",
            "Episode : 1213 , episodic length : 2196, return: 16.0, exp_count :2619089, averged returnover past 100 episodes : 14.55\n",
            "Episode : 1214 , episodic length : 2142, return: 16.0, exp_count :2621232, averged returnover past 100 episodes : 14.55\n",
            "Q loss: 0.0021028188057243824\n",
            "Episode : 1215 , episodic length : 2832, return: 9.0, exp_count :2624065, averged returnover past 100 episodes : 14.47\n",
            "Q loss: 0.001975995721295476\n",
            "Episode : 1216 , episodic length : 2350, return: 14.0, exp_count :2626416, averged returnover past 100 episodes : 14.45\n",
            "Episode : 1217 , episodic length : 2339, return: 14.0, exp_count :2628756, averged returnover past 100 episodes : 14.43\n",
            "Q loss: 0.0006576436571776867\n",
            "Episode : 1218 , episodic length : 1983, return: 17.0, exp_count :2630740, averged returnover past 100 episodes : 14.45\n",
            "Episode : 1219 , episodic length : 2098, return: 18.0, exp_count :2632839, averged returnover past 100 episodes : 14.49\n",
            "Q loss: 0.001241602934896946\n",
            "Episode : 1220 , episodic length : 2791, return: 10.0, exp_count :2635631, averged returnover past 100 episodes : 14.46\n",
            "Episode : 1221 , episodic length : 2024, return: 18.0, exp_count :2637656, averged returnover past 100 episodes : 14.53\n",
            "Q loss: 0.0033364733681082726\n",
            "Episode : 1222 , episodic length : 1886, return: 18.0, exp_count :2639543, averged returnover past 100 episodes : 14.51\n",
            "Episode : 1223 , episodic length : 2127, return: 19.0, exp_count :2641671, averged returnover past 100 episodes : 14.54\n",
            "Q loss: 0.002650526352226734\n",
            "Episode : 1224 , episodic length : 2600, return: 11.0, exp_count :2644272, averged returnover past 100 episodes : 14.49\n",
            "Q loss: 0.0011238764273002744\n",
            "Episode : 1225 , episodic length : 2947, return: 9.0, exp_count :2647220, averged returnover past 100 episodes : 14.44\n",
            "Episode : 1226 , episodic length : 2698, return: 13.0, exp_count :2649919, averged returnover past 100 episodes : 14.42\n",
            "Q loss: 0.0012349493335932493\n",
            "Episode : 1227 , episodic length : 2024, return: 16.0, exp_count :2651944, averged returnover past 100 episodes : 14.42\n",
            "Q loss: 0.0008155343821272254\n",
            "Episode : 1228 , episodic length : 2356, return: 13.0, exp_count :2654301, averged returnover past 100 episodes : 14.39\n",
            "Episode : 1229 , episodic length : 2418, return: 12.0, exp_count :2656720, averged returnover past 100 episodes : 14.35\n",
            "Q loss: 0.0022079285699874163\n",
            "Episode : 1230 , episodic length : 2063, return: 16.0, exp_count :2658784, averged returnover past 100 episodes : 14.36\n",
            "Episode : 1231 , episodic length : 2694, return: 10.0, exp_count :2661479, averged returnover past 100 episodes : 14.32\n",
            "Q loss: 0.004116844851523638\n",
            "Episode : 1232 , episodic length : 1624, return: 21.0, exp_count :2663104, averged returnover past 100 episodes : 14.45\n",
            "Episode : 1233 , episodic length : 2151, return: 18.0, exp_count :2665256, averged returnover past 100 episodes : 14.57\n",
            "Q loss: 0.007979906164109707\n",
            "Episode : 1234 , episodic length : 2202, return: 9.0, exp_count :2667459, averged returnover past 100 episodes : 14.56\n",
            "Episode : 1235 , episodic length : 2177, return: 16.0, exp_count :2669637, averged returnover past 100 episodes : 14.55\n",
            "Q loss: 0.0007133536273613572\n",
            "Episode : 1236 , episodic length : 2431, return: 14.0, exp_count :2672069, averged returnover past 100 episodes : 14.62\n",
            "Q loss: 0.001636897912248969\n",
            "Episode : 1237 , episodic length : 2083, return: 12.0, exp_count :2674153, averged returnover past 100 episodes : 14.61\n",
            "Episode : 1238 , episodic length : 2085, return: -5.0, exp_count :2676239, averged returnover past 100 episodes : 14.39\n",
            "Q loss: 0.0009194851154461503\n",
            "Episode : 1239 , episodic length : 2186, return: 13.0, exp_count :2678426, averged returnover past 100 episodes : 14.31\n",
            "Episode : 1240 , episodic length : 2598, return: 10.0, exp_count :2681025, averged returnover past 100 episodes : 14.22\n",
            "Q loss: 0.00212917011231184\n",
            "Episode : 1241 , episodic length : 2487, return: 13.0, exp_count :2683513, averged returnover past 100 episodes : 14.24\n",
            "Episode : 1242 , episodic length : 1885, return: 18.0, exp_count :2685399, averged returnover past 100 episodes : 14.3\n",
            "Q loss: 0.0012628325494006276\n",
            "Episode : 1243 , episodic length : 2339, return: 14.0, exp_count :2687739, averged returnover past 100 episodes : 14.27\n",
            "Q loss: 0.0004955938784405589\n",
            "Episode : 1244 , episodic length : 2677, return: 3.0, exp_count :2690417, averged returnover past 100 episodes : 14.14\n",
            "Episode : 1245 , episodic length : 2298, return: 12.0, exp_count :2692716, averged returnover past 100 episodes : 14.15\n",
            "Q loss: 0.0007143019465729594\n",
            "Episode : 1246 , episodic length : 2489, return: 13.0, exp_count :2695206, averged returnover past 100 episodes : 14.14\n",
            "Q loss: 0.005468389485031366\n",
            "Episode : 1247 , episodic length : 3124, return: 12.0, exp_count :2698331, averged returnover past 100 episodes : 14.14\n",
            "Episode : 1248 , episodic length : 2125, return: 16.0, exp_count :2700457, averged returnover past 100 episodes : 14.14\n",
            "Q loss: 0.0032312453258782625\n",
            "Episode : 1249 , episodic length : 2388, return: 15.0, exp_count :2702846, averged returnover past 100 episodes : 14.18\n",
            "Episode : 1250 , episodic length : 1750, return: 19.0, exp_count :2704597, averged returnover past 100 episodes : 14.26\n",
            "Q loss: 0.001547632273286581\n",
            "Episode : 1251 , episodic length : 1878, return: 18.0, exp_count :2706476, averged returnover past 100 episodes : 14.25\n",
            "Episode : 1252 , episodic length : 2424, return: 15.0, exp_count :2708901, averged returnover past 100 episodes : 14.25\n",
            "Q loss: 0.0009999440517276525\n",
            "Episode : 1253 , episodic length : 2420, return: 12.0, exp_count :2711322, averged returnover past 100 episodes : 14.19\n",
            "Episode : 1254 , episodic length : 2612, return: 14.0, exp_count :2713935, averged returnover past 100 episodes : 14.15\n",
            "Q loss: 0.003984014969319105\n",
            "Episode : 1255 , episodic length : 2384, return: 13.0, exp_count :2716320, averged returnover past 100 episodes : 14.15\n",
            "Q loss: 0.0011622935999184847\n",
            "Episode : 1256 , episodic length : 2463, return: 12.0, exp_count :2718784, averged returnover past 100 episodes : 14.15\n",
            "Episode : 1257 , episodic length : 2670, return: 13.0, exp_count :2721455, averged returnover past 100 episodes : 14.13\n",
            "Q loss: 0.006082436069846153\n",
            "Episode : 1258 , episodic length : 2201, return: 13.0, exp_count :2723657, averged returnover past 100 episodes : 14.06\n",
            "Episode : 1259 , episodic length : 2137, return: 16.0, exp_count :2725795, averged returnover past 100 episodes : 14.06\n",
            "Q loss: 0.0006513576954603195\n",
            "Episode : 1260 , episodic length : 2717, return: 13.0, exp_count :2728513, averged returnover past 100 episodes : 14.02\n",
            "Q loss: 0.0005500171100720763\n",
            "Episode : 1261 , episodic length : 2260, return: 14.0, exp_count :2730774, averged returnover past 100 episodes : 14.02\n",
            "Q loss: 0.0009223625529557467\n",
            "Episode : 1262 , episodic length : 3258, return: 12.0, exp_count :2734033, averged returnover past 100 episodes : 13.97\n",
            "Episode : 1263 , episodic length : 1777, return: 19.0, exp_count :2735811, averged returnover past 100 episodes : 14.03\n",
            "Q loss: 0.0005320300115272403\n",
            "Episode : 1264 , episodic length : 2199, return: 14.0, exp_count :2738011, averged returnover past 100 episodes : 13.99\n",
            "Episode : 1265 , episodic length : 3165, return: 6.0, exp_count :2741177, averged returnover past 100 episodes : 13.88\n",
            "Q loss: 0.0007575975614599884\n",
            "Episode : 1266 , episodic length : 2186, return: 17.0, exp_count :2743364, averged returnover past 100 episodes : 13.94\n",
            "Q loss: 0.000939577235840261\n",
            "Episode : 1267 , episodic length : 3133, return: 11.0, exp_count :2746498, averged returnover past 100 episodes : 13.9\n",
            "Episode : 1268 , episodic length : 2349, return: 13.0, exp_count :2748848, averged returnover past 100 episodes : 13.88\n",
            "Q loss: 0.000922533858101815\n",
            "Episode : 1269 , episodic length : 2383, return: 12.0, exp_count :2751232, averged returnover past 100 episodes : 13.88\n",
            "Episode : 1270 , episodic length : 2707, return: 9.0, exp_count :2753940, averged returnover past 100 episodes : 13.78\n",
            "Q loss: 0.00039796141209080815\n",
            "Episode : 1271 , episodic length : 2426, return: 14.0, exp_count :2756367, averged returnover past 100 episodes : 13.88\n",
            "Q loss: 0.0010213556233793497\n",
            "Episode : 1272 , episodic length : 2505, return: 14.0, exp_count :2758873, averged returnover past 100 episodes : 13.83\n",
            "Episode : 1273 , episodic length : 1878, return: 19.0, exp_count :2760752, averged returnover past 100 episodes : 13.84\n",
            "Q loss: 0.0012899537105113268\n",
            "Episode : 1274 , episodic length : 2124, return: 18.0, exp_count :2762877, averged returnover past 100 episodes : 13.86\n",
            "Episode : 1275 , episodic length : 2663, return: 7.0, exp_count :2765541, averged returnover past 100 episodes : 13.75\n",
            "Q loss: 0.0007832308765500784\n",
            "Episode : 1276 , episodic length : 2517, return: 11.0, exp_count :2768059, averged returnover past 100 episodes : 13.91\n",
            "Q loss: 0.000769082922488451\n",
            "Episode : 1277 , episodic length : 2036, return: 15.0, exp_count :2770096, averged returnover past 100 episodes : 13.9\n",
            "Episode : 1278 , episodic length : 2194, return: 15.0, exp_count :2772291, averged returnover past 100 episodes : 13.89\n",
            "Q loss: 0.0020116744562983513\n",
            "Episode : 1279 , episodic length : 2067, return: 18.0, exp_count :2774359, averged returnover past 100 episodes : 13.87\n",
            "Episode : 1280 , episodic length : 2078, return: 16.0, exp_count :2776438, averged returnover past 100 episodes : 13.86\n",
            "Q loss: 0.00402912637218833\n",
            "Episode : 1281 , episodic length : 2286, return: 16.0, exp_count :2778725, averged returnover past 100 episodes : 13.87\n",
            "Episode : 1282 , episodic length : 2604, return: 14.0, exp_count :2781330, averged returnover past 100 episodes : 13.88\n",
            "Q loss: 0.002997274976223707\n",
            "Episode : 1283 , episodic length : 2978, return: 6.0, exp_count :2784309, averged returnover past 100 episodes : 13.76\n",
            "Q loss: 0.0004076278710272163\n",
            "Episode : 1284 , episodic length : 2158, return: 13.0, exp_count :2786468, averged returnover past 100 episodes : 13.72\n",
            "Episode : 1285 , episodic length : 1931, return: 16.0, exp_count :2788400, averged returnover past 100 episodes : 13.72\n",
            "Q loss: 0.0006869226926937699\n",
            "Episode : 1286 , episodic length : 2484, return: 15.0, exp_count :2790885, averged returnover past 100 episodes : 13.72\n",
            "Episode : 1287 , episodic length : 2521, return: 13.0, exp_count :2793407, averged returnover past 100 episodes : 13.64\n",
            "Q loss: 0.0019967376720160246\n",
            "Episode : 1288 , episodic length : 2215, return: 16.0, exp_count :2795623, averged returnover past 100 episodes : 13.64\n",
            "Q loss: 0.0012588873505592346\n",
            "Episode : 1289 , episodic length : 2552, return: 16.0, exp_count :2798176, averged returnover past 100 episodes : 13.66\n",
            "Episode : 1290 , episodic length : 2286, return: 14.0, exp_count :2800463, averged returnover past 100 episodes : 13.62\n",
            "Q loss: 0.0020407941192388535\n",
            "Episode : 1291 , episodic length : 2420, return: 14.0, exp_count :2802884, averged returnover past 100 episodes : 13.61\n",
            "Episode : 1292 , episodic length : 2900, return: 6.0, exp_count :2805785, averged returnover past 100 episodes : 13.48\n",
            "Q loss: 0.0003906322526745498\n",
            "Episode : 1293 , episodic length : 2065, return: 20.0, exp_count :2807851, averged returnover past 100 episodes : 13.6\n",
            "Episode : 1294 , episodic length : 2066, return: 15.0, exp_count :2809918, averged returnover past 100 episodes : 13.69\n",
            "Q loss: 0.002868452575057745\n",
            "Episode : 1295 , episodic length : 2846, return: 10.0, exp_count :2812765, averged returnover past 100 episodes : 13.66\n",
            "Q loss: 0.0013301928993314505\n",
            "Episode : 1296 , episodic length : 2267, return: 17.0, exp_count :2815033, averged returnover past 100 episodes : 13.7\n",
            "Episode : 1297 , episodic length : 2178, return: 18.0, exp_count :2817212, averged returnover past 100 episodes : 13.79\n",
            "Q loss: 0.000526749121490866\n",
            "Episode : 1298 , episodic length : 2023, return: 16.0, exp_count :2819236, averged returnover past 100 episodes : 13.86\n",
            "Episode : 1299 , episodic length : 2284, return: 16.0, exp_count :2821521, averged returnover past 100 episodes : 13.9\n",
            "-----start Testing------\n",
            "Testing result, Returns: [20. 19. 19. 20. 20. 20. 20. 20. 20. 20. 19. 20. 20. 20. 20.]\n",
            "Q loss: 0.0009488959331065416\n",
            "Episode : 1300 , episodic length : 2277, return: 12.0, exp_count :2823799, averged returnover past 100 episodes : 13.9\n",
            "Q loss: 0.0020367950201034546\n",
            "Episode : 1301 , episodic length : 2279, return: 14.0, exp_count :2826079, averged returnover past 100 episodes : 13.86\n",
            "Episode : 1302 , episodic length : 2632, return: 10.0, exp_count :2828712, averged returnover past 100 episodes : 13.8\n",
            "Q loss: 0.0003482794272713363\n",
            "Episode : 1303 , episodic length : 2615, return: 15.0, exp_count :2831328, averged returnover past 100 episodes : 13.83\n",
            "Episode : 1304 , episodic length : 2209, return: 18.0, exp_count :2833538, averged returnover past 100 episodes : 13.8\n",
            "Q loss: 0.0009148250101134181\n",
            "Episode : 1305 , episodic length : 2200, return: 17.0, exp_count :2835739, averged returnover past 100 episodes : 13.8\n",
            "Q loss: 0.0008657816215418279\n",
            "Episode : 1306 , episodic length : 2426, return: 14.0, exp_count :2838166, averged returnover past 100 episodes : 13.83\n",
            "Episode : 1307 , episodic length : 1907, return: 19.0, exp_count :2840074, averged returnover past 100 episodes : 13.89\n",
            "Q loss: 0.0029576951637864113\n",
            "Episode : 1308 , episodic length : 2325, return: 14.0, exp_count :2842400, averged returnover past 100 episodes : 13.85\n",
            "Episode : 1309 , episodic length : 2338, return: 14.0, exp_count :2844739, averged returnover past 100 episodes : 13.86\n",
            "Q loss: 0.0022594216279685497\n",
            "Episode : 1310 , episodic length : 2261, return: 16.0, exp_count :2847001, averged returnover past 100 episodes : 13.88\n",
            "Episode : 1311 , episodic length : 2308, return: 16.0, exp_count :2849310, averged returnover past 100 episodes : 13.9\n",
            "Q loss: 0.00273273978382349\n",
            "Episode : 1312 , episodic length : 2342, return: 17.0, exp_count :2851653, averged returnover past 100 episodes : 13.92\n",
            "Episode : 1313 , episodic length : 2182, return: 17.0, exp_count :2853836, averged returnover past 100 episodes : 13.93\n",
            "Q loss: 0.00034756920649670064\n",
            "Episode : 1314 , episodic length : 2482, return: 16.0, exp_count :2856319, averged returnover past 100 episodes : 13.93\n",
            "Q loss: 0.0006832756334915757\n",
            "Episode : 1315 , episodic length : 2110, return: 17.0, exp_count :2858430, averged returnover past 100 episodes : 14.01\n",
            "Episode : 1316 , episodic length : 3162, return: 5.0, exp_count :2861593, averged returnover past 100 episodes : 13.92\n",
            "Q loss: 0.001822211197577417\n",
            "Episode : 1317 , episodic length : 2450, return: 15.0, exp_count :2864044, averged returnover past 100 episodes : 13.93\n",
            "Q loss: 0.00551263801753521\n",
            "Episode : 1318 , episodic length : 2411, return: 14.0, exp_count :2866456, averged returnover past 100 episodes : 13.9\n",
            "Episode : 1319 , episodic length : 2333, return: 13.0, exp_count :2868790, averged returnover past 100 episodes : 13.85\n",
            "Q loss: 0.0031207911670207977\n",
            "Episode : 1320 , episodic length : 2225, return: 15.0, exp_count :2871016, averged returnover past 100 episodes : 13.9\n",
            "Episode : 1321 , episodic length : 2887, return: 15.0, exp_count :2873904, averged returnover past 100 episodes : 13.87\n",
            "Q loss: 0.0039671361446380615\n",
            "Episode : 1322 , episodic length : 2237, return: 16.0, exp_count :2876142, averged returnover past 100 episodes : 13.85\n",
            "Q loss: 0.0006905199843458831\n",
            "Episode : 1323 , episodic length : 2472, return: 15.0, exp_count :2878615, averged returnover past 100 episodes : 13.81\n",
            "Episode : 1324 , episodic length : 1805, return: 18.0, exp_count :2880421, averged returnover past 100 episodes : 13.88\n",
            "Q loss: 0.0008363830856978893\n",
            "Episode : 1325 , episodic length : 2113, return: 16.0, exp_count :2882535, averged returnover past 100 episodes : 13.95\n",
            "Episode : 1326 , episodic length : 2685, return: 12.0, exp_count :2885221, averged returnover past 100 episodes : 13.94\n",
            "Q loss: 0.0013779381988570094\n",
            "Episode : 1327 , episodic length : 2097, return: 19.0, exp_count :2887319, averged returnover past 100 episodes : 13.97\n",
            "Episode : 1328 , episodic length : 2263, return: 18.0, exp_count :2889583, averged returnover past 100 episodes : 14.02\n",
            "Q loss: 0.00224577309563756\n",
            "Episode : 1329 , episodic length : 1953, return: 18.0, exp_count :2891537, averged returnover past 100 episodes : 14.08\n",
            "Q loss: 0.002563862595707178\n",
            "Episode : 1330 , episodic length : 2532, return: 5.0, exp_count :2894070, averged returnover past 100 episodes : 13.97\n",
            "Episode : 1331 , episodic length : 2427, return: 12.0, exp_count :2896498, averged returnover past 100 episodes : 13.99\n",
            "Q loss: 0.0010346933268010616\n",
            "Episode : 1332 , episodic length : 2892, return: 12.0, exp_count :2899391, averged returnover past 100 episodes : 13.9\n",
            "Episode : 1333 , episodic length : 2388, return: 18.0, exp_count :2901780, averged returnover past 100 episodes : 13.9\n",
            "Q loss: 0.0016059188637882471\n",
            "Episode : 1334 , episodic length : 2210, return: 15.0, exp_count :2903991, averged returnover past 100 episodes : 13.96\n",
            "Q loss: 0.0005814165924675763\n",
            "Episode : 1335 , episodic length : 2225, return: 18.0, exp_count :2906217, averged returnover past 100 episodes : 13.98\n",
            "Episode : 1336 , episodic length : 2016, return: 19.0, exp_count :2908234, averged returnover past 100 episodes : 14.03\n",
            "Q loss: 0.0008495740476064384\n",
            "Episode : 1337 , episodic length : 2281, return: 17.0, exp_count :2910516, averged returnover past 100 episodes : 14.08\n",
            "Episode : 1338 , episodic length : 2445, return: 16.0, exp_count :2912962, averged returnover past 100 episodes : 14.29\n",
            "Q loss: 0.0007037713658064604\n",
            "Episode : 1339 , episodic length : 2609, return: 14.0, exp_count :2915572, averged returnover past 100 episodes : 14.3\n",
            "Episode : 1340 , episodic length : 2384, return: 15.0, exp_count :2917957, averged returnover past 100 episodes : 14.35\n",
            "Q loss: 0.004289586097002029\n",
            "Episode : 1341 , episodic length : 2531, return: 13.0, exp_count :2920489, averged returnover past 100 episodes : 14.35\n",
            "Q loss: 0.0006419971468858421\n",
            "Episode : 1342 , episodic length : 2655, return: 12.0, exp_count :2923145, averged returnover past 100 episodes : 14.29\n",
            "Episode : 1343 , episodic length : 2228, return: 16.0, exp_count :2925374, averged returnover past 100 episodes : 14.31\n",
            "Q loss: 0.0024432020727545023\n",
            "Episode : 1344 , episodic length : 2770, return: 16.0, exp_count :2928145, averged returnover past 100 episodes : 14.44\n",
            "Q loss: 0.0008072299533523619\n",
            "Episode : 1345 , episodic length : 2539, return: 13.0, exp_count :2930685, averged returnover past 100 episodes : 14.45\n",
            "Episode : 1346 , episodic length : 2153, return: 17.0, exp_count :2932839, averged returnover past 100 episodes : 14.49\n",
            "Q loss: 0.009364689700305462\n",
            "Episode : 1347 , episodic length : 2643, return: 10.0, exp_count :2935483, averged returnover past 100 episodes : 14.47\n",
            "Episode : 1348 , episodic length : 2008, return: 17.0, exp_count :2937492, averged returnover past 100 episodes : 14.48\n",
            "Q loss: 0.0009794947691261768\n",
            "Episode : 1349 , episodic length : 2749, return: 9.0, exp_count :2940242, averged returnover past 100 episodes : 14.42\n",
            "Q loss: 0.0014733908465132117\n",
            "Episode : 1350 , episodic length : 2662, return: 10.0, exp_count :2942905, averged returnover past 100 episodes : 14.33\n",
            "Episode : 1351 , episodic length : 2197, return: 14.0, exp_count :2945103, averged returnover past 100 episodes : 14.29\n",
            "Q loss: 0.0010518040508031845\n",
            "Episode : 1352 , episodic length : 1943, return: 15.0, exp_count :2947047, averged returnover past 100 episodes : 14.29\n",
            "Episode : 1353 , episodic length : 2234, return: 15.0, exp_count :2949282, averged returnover past 100 episodes : 14.32\n",
            "Q loss: 0.0010808934457600117\n",
            "Episode : 1354 , episodic length : 2620, return: 12.0, exp_count :2951903, averged returnover past 100 episodes : 14.3\n",
            "Q loss: 0.001256562303751707\n",
            "Episode : 1355 , episodic length : 2248, return: 14.0, exp_count :2954152, averged returnover past 100 episodes : 14.31\n",
            "Episode : 1356 , episodic length : 2764, return: 10.0, exp_count :2956917, averged returnover past 100 episodes : 14.29\n",
            "Q loss: 0.001147782546468079\n",
            "Episode : 1357 , episodic length : 2090, return: 17.0, exp_count :2959008, averged returnover past 100 episodes : 14.33\n",
            "Episode : 1358 , episodic length : 2581, return: 14.0, exp_count :2961590, averged returnover past 100 episodes : 14.34\n",
            "Q loss: 0.0017466103890910745\n",
            "Episode : 1359 , episodic length : 2688, return: 13.0, exp_count :2964279, averged returnover past 100 episodes : 14.31\n",
            "Q loss: 0.0009666330879554152\n",
            "Episode : 1360 , episodic length : 2113, return: 16.0, exp_count :2966393, averged returnover past 100 episodes : 14.34\n",
            "Episode : 1361 , episodic length : 2620, return: 13.0, exp_count :2969014, averged returnover past 100 episodes : 14.33\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':  \n",
        "    \n",
        "    env_id = \"PongNoFrameskip-v4\" # could change to other games, but only use 'NoFrameskip-v4' version. Some games e.g., spaceinvaders require changing the code in wrapper, i.e., frame_skip =3\n",
        "    env = make_atari(env_id)\n",
        "    env = wrap_deepmind(env)\n",
        "    env = wrap_pytorch(env) # Note the env returns the unnormalized pixel [0,255].\n",
        "    test_env = make_atari(env_id)\n",
        "    test_env = wrap_deepmind(test_env, episode_life=False, clip_rewards=False)\n",
        "    test_env = wrap_pytorch(test_env)\n",
        "    \n",
        "    # Hint: you could check the shape and content of the state, it is not yet normlized between [0,1]\n",
        "    obs = env.reset()\n",
        "    print(obs.shape)\n",
        "    for i in range(obs.shape[0]):\n",
        "        plt.imshow(obs[i])\n",
        "    \n",
        "    random_seed = None\n",
        "    if random_seed:\n",
        "        print(\"Random Seed: {}\".format(random_seed))\n",
        "        torch.manual_seed(random_seed)\n",
        "        env.seed(random_seed)\n",
        "        np.random.seed(random_seed)  \n",
        "        random.seed(random_seed)\n",
        "        \n",
        "    # DQN params\n",
        "    config = {}\n",
        "    config.update({'gamma': 0.99})\n",
        "    config.update({'learning rate': 1e-4})\n",
        "    config.update({'memory size': 300000}) # 1M frame memory buffer takes around 8GB in RAM. For local computer, you could use 1M memory size. For Colab, size should be <= 0.3M.\n",
        "    config.update({'target network update interval': 2500}) # every 10000 training steps, update the target model.\n",
        "    config.update({'max episodes': 1000000}) # you don't need to run that long, but just keep running.\n",
        "    config.update({'max steps per episode': 27500}) \n",
        "    config.update({'batch size': 32}) \n",
        "    config.update({'update every n steps': 4})\n",
        "    config.update({'number of pre-interactions to start training': 10000})\n",
        "    config.update({'training_env': env})\n",
        "    config.update({'testing_env': test_env})\n",
        "    #  agent\n",
        "    agent = LearningAgent(**config)\n",
        "    \n",
        "    # train\n",
        "    learn(agent, **config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Atari_on_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
