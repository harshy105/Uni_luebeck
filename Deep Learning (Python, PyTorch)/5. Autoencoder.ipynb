{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0dSzdreKsLf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch.nn.modules.loss import BCELoss\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(18)\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbqK7ipmxSIe",
        "outputId": "b33587b3-d116-4ff2-a511-119b903417d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<module 'torch.version' from '/usr/local/lib/python3.7/dist-packages/torch/version.py'>\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.version)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81AO_9UAYUdk"
      },
      "outputs": [],
      "source": [
        "def rotate_image(image, tar_image, deg=None):\n",
        "    if deg is None:\n",
        "        deg = np.random.randint(0,90)\n",
        "    rows, cols = image.shape\n",
        "    M = cv2.getRotationMatrix2D((cols/2,rows/2), deg, 1)\n",
        "    image = cv2.warpAffine(image, M, (cols, rows))\n",
        "    tar_image = cv2.warpAffine(tar_image, M, (cols, rows))\n",
        "    return image, tar_image\n",
        "\n",
        "# def translation_image(image,x=None,y=None):\n",
        "#     if x is None:\n",
        "#         x = np.random.randint(0,50)\n",
        "#     if y is None:\n",
        "#         y = np.random.randint(0,50)\n",
        "#     rows, cols= image.shape\n",
        "#     M = np.float32([[1, 0, x], [0, 1, y]])\n",
        "#     image = cv2.warpAffine(image, M, (cols, rows))\n",
        "#     return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOv6Hc7nLDof",
        "outputId": "c9027685-ff37-4a89-8f49-a738596e9d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9980, 192, 192)\n"
          ]
        }
      ],
      "source": [
        "success = True\n",
        "videofile = \"/content/animation.mp4\"\n",
        "vidcap = cv2.VideoCapture(videofile)\n",
        "success, tar_image = vidcap.read()\n",
        "# gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "# (thresh, blackAndWhiteImage) = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY)\n",
        "# blackAndWhiteImage = blackAndWhiteImage.astype(np.uint8)\n",
        "# print(gray_img.shape)\n",
        "# cv2_imshow(gray_img)\n",
        "# values = []\n",
        "# for i in range(200):\n",
        "#   for j in range(200):\n",
        "#     if int(gray_img[i,j]) > 0:\n",
        "#       values.append(gray_img[i,j])\n",
        "# print(values)\n",
        "# cv2_imshow(blackAndWhiteImage)\n",
        "# norm_img = cv2.normalize(blackAndWhiteImage, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "# cv2_imshow(rotate_image(blackAndWhiteImage))\n",
        "# cv2_imshow(translation_image(blackAndWhiteImage))\n",
        "\n",
        "\n",
        "images = []\n",
        "tar_images = []\n",
        "while success:\n",
        "    image = tar_image\n",
        "    success, tar_image = vidcap.read()                                 # reads next frame\n",
        "    \n",
        "    if success:\n",
        "      # Preprocessing\n",
        "      img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)              # grayscale image\n",
        "      tar_img = cv2.cvtColor(tar_image, cv2.COLOR_RGB2GRAY)              # grayscale image\n",
        "      img = cv2.resize(img, (192,192))\n",
        "      tar_img = cv2.resize(tar_img, (192,192))\n",
        "      # (thresh, img) = cv2.threshold(img, 2, 255, cv2.THRESH_BINARY)  # black and white image\n",
        "      # (thresh, tar_img) = cv2.threshold(tar_img, 2, 255, cv2.THRESH_BINARY)  # black and white image\n",
        "      images.append(img)\n",
        "      tar_images.append(tar_img)\n",
        "      for _ in range(19):\n",
        "        rot_img, tar_rot_img = rotate_image(img, tar_img)\n",
        "        images.append(rot_img)\n",
        "        tar_images.append(tar_rot_img)\n",
        "\n",
        "images = np.array(images)\n",
        "tar_images = np.array(tar_images)\n",
        "print(images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "Gak0UgEsoreP",
        "outputId": "1233d6e6-3034-4f8e-d750-62a7d255f317"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=192x192 at 0x7F6C5EE12490>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAADACAAAAAB3tzPbAAATdElEQVR4nO1daWxc13X+vvtm4cxwJ0VSq6mNFCVqs2zJ2rzDVhIljpWkTprFzR40hYsAbdE2RYFuaJM2LVKgLhy3SBohjuvKS2zHjbzVkiIpsmTK2khtpiVRosRVXIezvHdPf7zZKHHTzHsjBtAHiCJn3tx7zj3nnnPuuefeAW7hFm7hFm7hFm4hAea/S+VQO6QibgYHDjFAm3olzjR3A3CIASEF+C2WAEQIQDvU2g3AKQY0BDMa869BjjEAwFhy/2f99q/Mnyo5yID3vhkz/mJ1iCQkf5PBsY6IPwzSP2ycbTkhyKMqeRxrabPPqyGhRWW3v9aD/LHgmCOraYwHebW+vaCO37nDI3mbBU4wQIK+5caaFn/tzlXhKys7VpdS8iWC3BkgCUpFw9y37hg4v6ElEOwu/LCfiiTpSAcTI/f2RbQIPhbqr28vCEbEa/Qb++JCZcdHrgcXDg3QXaUK/t5g4eH7L42s+cEwKQKKhvsuwQEGSOLIr2KF7366pefxv1wVeDYC0VoDVCKuzwVHxocCI7jloZc+2tN211HvM+2pN4xQLOZyfOQEAwoCilH7heFgtKLt/MvJQScKH+vb1xOz41SXROEQAwKAvP2h6pcf+2aafrX6vqLeprOdJgG3fFtuDFAAMEmaUtj6R1vCKbVn9dZZWhnnjjbHtEC5Mx1yYoCECJmh5azoQcqJBTevF110NWh+sOtKXLkUIeXEgBKAkskAyCShVAs+pw1Pf+WQlHY0He2FOxLIxYySJPU1g8DU2r5krfZY0aIBr9FXuKneJfpzikZFA2IYsdQLFKUtAiRFvHUzPdoQ06OhZOCqWw4hJ0cmAs+sO4sTf9Ge1GL/Y3V9SBM2V7hwyq2YKLf1AFHw0VkL9l+0vRUFJCCEEIHb5mkKlEnEA717NV1yBDkuaPzr54Vrq1pOdEYSy0gBIEog4e5zs/yk9sSVZ2R3r2shRW5+wFj40YqoR5mdzae6dJJ+AKQQlfVLqxQElmr53+HcKR0HuUmgsGFGX4lpeqorF+xpj2akhQRg19DFZYtLRMXDR9yjP2sJUECg4VGrrM8nADGy7/3hTDUhIMq3cM3i7pp3do84QerYyFYChiVAaKPXN+C3SGgWVBhp+hPeTGLNnWc3nGmJuhRGANkyQFhKw7t+tqYBgEL0vj8AgNSgqFTUwO7B89ZV7eKiJus5IGDtarEMaqUhMJsuEAIZFXeKENHLgsTLriA7/yKAAMPBiMcyRCsLaD1lL74ksZZPgIQWcXNhn2XbIhTp/FFnxB/3wBIMtAzY4572BoDtnDPiOzeQ9eCIou74710fGkLQOncunnwd+LjfSDYrInB3XZz9HBAlOvxe2+K1RbE4D/Wn36hoXLz/vShgm1IHaJwQucwuCmB4y+6rLfjFESvlhPHtSrkafOkk7BngBJETEpHj5xUQavAf60utK7n2a8f8K3+6tWm7snQeRJArAwTE54mkB7rwR//w3ba9331ytu+580NwaxkzioAcG8i0MRR8KfrVn9WWnqgbFOPcvrPuSyBnE02BUJFQigTnV616Y4EMFCorVhasdV8AzqQWRYtQhBDeU8S+mkjHpqbSysNz3si98UmRMwMiOj3KnqVrBy88suO2hp988nJPw9PMw1aZcz0QAP91/zLjyJYmf8358tj7r7qWT7ymWwebCj5aWF7cGzI9g8WXnu92ru3x4WycpaLP7D1vxgLGlcWXTmdLPzk6IJzk6Sx7GadrEQQWPnG4pvjgzH8PZ9uKnW6dovY5O8soAJQ8XuIv/cnpLNtQ1BThVLcJnTcTpMjyZdGXhFk6MSZEedMYAEUKzahkb4Porfa2mQJg8qS8G4aaQqHksCmjZn67+72DIwJATRbPusAAaa+Nsx5/hL4UCvL8/stDFibVQ+dqJdIQSi5BnPhWFYUinvmz329pi9uynACurLdzoh+sqgvEDSC6fuv6ACer3LkJhZITgBDCt2Gz0IhblZfK2PrLrknMkdulDDcEKgWoqnVURtxT0FkRidTWZhA45mC7MQeyhb2CLro/aMH0aAYi5JkTFhKUj5Mcm1YSgID+pXNMEWWJQKv+PcMiBEGMFx5NJwYEBDwFvpiCBcLyWCfbbTs6gVGeTioEIfXI0ZHNGopCbXU0mwKIbZfHYWE6ScD24b3vPXdikKBW0txlu2ERSGjd2AxMKwlAhILYuf4FDbUGcL4lmnydaNi86I0eE8A1znl6+YEkfGVLVpYO7WhL52tKv2mYI83HOpAIVVOYRhJguuwi1tVzceXljnQ46HuoZMgzWy06ekAEo+Lc6SIBCiiKVuIvQkrM4XSaftF39q80L9x53NO3PW6OksC0YiCdYKVkxLMK6k+PfuuV8prjt0Ut/c7pUZvO08QK2W4qg7DU2CtAuCb60AtzjPY5ES2BOyt15iSeJgyIAAL7GAsAiF0GZktC9JZgb5khZvGQxz9w6eQorZkmDECA0JMLU/QLdGLHDVTcVh2/uPl4qOZQXTgceJWjFH/azAHga8Ob9u85h0TZi10pqESTlTuf2Fb21J/sVotPVEZeOzJN/YDRuLG2MzTY+WI4cwIrEVAK/+Wor+5YjRn1xU+/dk26abqoEPzLi9VwYIb+3h1kejprIWmEv36BHSGNWEFP87XpsmnDwIL6kqZPn+z6wn9+46tl6cmMRCT68s8PLO4za84ONl/7uZuvQoSAlP86EFj91O9euXTvoeLYsdfSqUXafpfeoj+IRcr+ue/aNf5EDCRCcZdT5KSA+Lq5ZKS3vjUgRZ1F/U9GkvGOTYIAClJ8V+3BpuvomSAWcnuPPdEJBIKVgdJh+DFYXLxr69HfRFVqEiTTvEIO7GrqvX5VMNEcoBa6XT4vIKCKl3uq2j0zX3y45/h3/sd7OGOUk4yIFol2aVynM+MzQFLZ/ztPdgZEAK3j5a9v6Gv95va5C39838uxRF7JPtCVJMc+bHqdRk88B2AoS9zebCeEqPtU91zpntdjSNv2lPYABSNM/TUqwMskcqK2Z9b1nDI1MIU0cdYgSC3BDYvLzerLHuNv0yRjaVFbdzRN6FgUTCwBzz3r+y/+pjsurjKQcLrVazcdXtf77Ol0rU7NltnnTp8asmCXgo1D5AQw5vxOQHsGf90yKOM24ByI+d86E31+JGWAQnduMDB8+UB7dIIdmwkZCH5q+QDoHzl7pC1quW1QQYAPn/0gZbmNBQ9WAcriviNXTdw4AxTv6i3a0IZpYKi55XLUfZcGAIqW7cLEv2UFFbQ34m07fDI6XtnU2GaUJKiqlxlQtJQgsOGB0nxEHSLQOmm46+cTlkbMq2c/8Jh/vMEbhwEFSEF9bSQYp0EtnoFiQ0kyVe8qJ6IBKhI1q0sICugxpaLPHM+GjMkAxQJYfrsuvuoTEUPHQ/t7NZho2jXakxsjAiJQt1ALFcTfVYKOfeZ44zauJ2bg7iIrXBiHUCt18kwUKafscggugAar1vcb0JZHDc/pMt69Om5QOSYxAkIMbz9p77JJ3+EeJLbuUtWt7kFA0VZPcQzKiImvt6j1g7i+sTkAgOHn374ArURBrNOtEIFA27G72wZVAHa/dSCqlOURS3Cka/wexxlMJQRY3rhJQYTtr1/UycdV3fzXXK+iIUj6566q80jcnLH3l9GJHh0TShMCBGavnRVEbE/TSOrxwsew8OnWxEfdY4RKCwsb7/Ya7H+mc4J+JlFno7iu7rYPd/akSFWN28r237nnwGVi6gUZ2YACKG/5PdVFu/ZZE4h8DAYoGRv8ylcxu+eDVAOUvw9Ha7q8XWcPDEnW5RxTBAmiobSlZ6JA7DoGKCBSFbcKAn8kg9CvzxRd2VYul8pfPEmOaxscQlLME0hgbDMqmadhoilNIRuWfxAq3bupq39d65cfDeThKhUmbm0ZF9cywFF7srR/2Is5AgWf2fHnZy58/qmFRYc29vjct6e0fdIky8brPmKUD8QTtBEJRacoEdx9+7qfbu3prG/3gT1vN7sfntLeNpsA16ZVBMDaNWf2Dqf+toNbUqj8m73v3duBoI4V+M4NN7teVWkflL3RahVV/Rl1+5+FEvvjyfcJiH4IZnxuu2fezsbwleU/E9eX+1OR8PXqZfzeyMb2gQ3bD3cig387w1ex7Y4f/d0bQ1ueX2I+e9JZWrPF9QysvKvucpEaDIRbXxxV/KhAZcodv/9/Dbw0c/DDl1083HYjuE6FQksrwx6y/7bYnKeDTB2GAUXEAg49oXtiAfQfmyb0ZzKgFKBUw6LgpYW9ndv+af28n++s0BlHqESLAOFnd5yZd2aweRrktQFkqhABagb+qkuWv/RA/5HHd8wuf+vVVLiTShMbmlj85b8ZzkOeZUrgNb99sXyGeXXh+WBBb6GM/CMInaA95bWUQGnkUBXqLEZVdJGN5WVDZlGfh+pq+dDbkvJjSJ8SECR3EPNP7RjIUHGB6CsHw5rBc7NiFz7zlvcwdPLOjlGnCyljpYlvEjKHkRQY3seL4iv2LfC8v/EHH6YTw4VGX2rjX9QU6lHzhtG7aYQINi7zzh1Awbs7k6cLyYK1ZUfPWYmnJitFzS8yYqFkVmbf2UYV8gy+Y6bfmbPON/vw6b546sHpg7FmIj0VD1f+6kQqoc7qrXM0rXPNH/aPucdwUzEmA0LeeSySiiOC6zYpkNJ/8VB7bNw08U3CeLaQUIl8MHnbRyoJiGFptfP0oJ4eDiyJsXOjhEAL7KvKfI1lHkuEJo34J5b7ptX4j5tahO0XqACZV+eLewDtEe0LD8d/GxhIGiRaIEo3hSwAoizAc+aUlY/jeTeAiTLNAgp8KxbGTf+IoTSU6n9naOoHpPKDCVPlAsA8cyZQ0FsT0VQx2X81lyParkhukkaV0PDdsbqmP2BKvKD19Y7sRt92Hq548EkKXwXU4f0Xl60gTX+4pTt7EtyaOJO2SwhU0cyN8yR+ZXtssqfHaSNR9OPG7JnawCj4199e+G/dWZJAQisRF6+ImZQARWN+VQ61N4RRUpT8tLMHUG/kyVzWkeqz6shxSTXkGKbIQKJ2K+t1DLH8i5ejIz8G4PCuwtS2TJm4uyD7rkPb9iwq9z7dEHS6gGqqEshV7A/fds/umsK28tPHjjtrjPIR1xAyc9usq0WWES4Z6ht8IezkmsLtwlcqRZDry3W0MtK3tLlsLv46kZdxBnmp3JXF98Y6H94xf/H2x1p71z9J0DnRu6xCidrZH+7epHd949XiBYdqI2d/bvdqW4ScReH2HCAAfKJqxXlfxblKyxgo73ipDUIKRZSo3HXJbRUSQORUvKPAiIfL9cXNLVfaBBRNUono3G2q+3OA5OkdL4Z0y7feLN7wvdWvil0XpEWrkC93a+S6GVVCigi+svLVLx2N1z/dlO65csXAyaFE9j5rRlxnIFXGuuSTkRKz/cfpWmLvXQ8NXXi7Ny7M5Urk/C3QGVi9Ef9xNX2Z2ILPaY8nvO9stynI3rW5ywAzKKOi977X0uFU+YP1Hk3q82cOR3K4TcxNBiiAShaEJI6EpTTKs/LuQpIwjZHBFzqyv8/NRStEAamtjFp0pr8viOVLCmGJCZiFRU/MyN4aucmAgohKy1iSX+9CAtJYS0VtxLwqUtQTyN4ju3gcVwQFFaoncQIg9YMQEouWG9CGWB4ThnXwErNe7LnJADyzHggdPNOZeiG1omTZqhINJQIjHEDrAVNlPYnd9MQMLqv1PfjwMp9K32cOABCJdwyD1MoYqh6I7Y3lkO9z1Qo1Pljosdh/uqVzRKftJ4VQ/qp75yjviFFwefbuPUO5dOIEpeOg+GOLqDTE6j7V0pXhqUhQdMXSxnK/GS/ofuVCLlsm7jFA35r7DQG0AuMXf/NB+gCAXdWGQHVjfcgs+cXB+AStTApX5gAVQaN6s1croSLgmVfiS327ERPfjRK5+OaLbcETTXGVyyi6YYUIUGBs8mrDMjSgLLZejCQtJZG8P0nHWjtXnI3ltipzx4xqRdVQZViG0kJYavBUD65L7AkEwwe1zq3qwg0VElJglBWKJYx7IUpfOhtXdoEIMztUCnErx2noyhzQoJgnfj1QGY8V93koeHdItCS+nSDTZYldZpWLDrljhezvwara3IBw2RBl98FIursZXekiKgcSXC55YhER88orr5wPjJBtJ5L0gwj98uOpmSAOJLhcXdDQM2PRmoreN0/otAt45ulHOl5/3xp9Q3gufeTexERQvoqNvhfCyThCqUfmzBlQEeO5izGH6kbczsyJ8qlYWlXmfj6+Zvfs0j0bf/1Wn3Zky8n1I1U6MqJTTthYFaj//kcGjn+xafVXVgYd6SEPaRW7hl8ESiq/f6r3Y881GJfmDqjhXU1O5KjzkFaxAwgKUPzHnTOMroqoEQ+M6As/c2TjOw/pdUn4BRRsGiky4yweic24FBp605m9pvzc7GHf31qyYLBiaGTxvtmBk6svH+9xZqcpj1eTSPehiiM1oRP3nY/NOR0+Me751BtD3lKLBIiSR4KVvqGCuIrsPuBcu3kCSdFYvmyRDg6z/SeONetUQ1PpSgAWLtrWXzjyw4hTtTf5Lh9TEN+jVQfftaZP8fKNgYrgkgo4vWGfP5BMHJBypr383/CUSu8601z+GRBKHr7Zwj1Ms7LTW7iFW7iFW7iFm4v/B3aec60M4e9mAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=192x192 at 0x7F6CEA790410>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "idx = np.random.randint(9000)\n",
        "img = images[idx]\n",
        "tar_img = tar_images[idx]\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(tar_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbpwXBSqLLN7",
        "outputId": "0973b512-dec1-4f2c-fd90-b569fd07ae1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([9000, 192, 192])\n",
            "torch.Size([9000, 192, 192])\n",
            "torch.Size([980, 192, 192])\n",
            "torch.Size([980, 192, 192])\n"
          ]
        }
      ],
      "source": [
        "images_tensor = torch.tensor(images)\n",
        "tar_images_tensor = torch.tensor(tar_images)\n",
        "rand_idx = torch.randperm(images_tensor.shape[0])\n",
        "train_data = images_tensor[rand_idx[:9000]]\n",
        "train_label = tar_images_tensor[rand_idx[:9000]]\n",
        "test_data = images_tensor[rand_idx[9000:]]\n",
        "test_label = tar_images_tensor[rand_idx[9000:]]\n",
        "print(train_data.shape)\n",
        "print(train_label.shape)\n",
        "print(test_data.shape)\n",
        "print(test_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hemUC496U3YY"
      },
      "outputs": [],
      "source": [
        "# #decoder_block\n",
        "# def decoder_block(in_channels, out_channels, scale, use_relu=True):\n",
        "#     if use_relu:\n",
        "#         block = nn.Sequential(\n",
        "#             nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False),\n",
        "#             nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "#             nn.PReLU(),\n",
        "#         )\n",
        "#     else:\n",
        "#          block = nn.Sequential(\n",
        "#             nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False),\n",
        "#             nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "#         )\n",
        "#     return block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUtx0x9yCTzz"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=2, kernel_size=3):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.residual_pass = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                                    stride = 1, padding = 1, padding_mode='replicate'),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                                    stride = 1, padding = 1, padding_mode='replicate'), \n",
        "                               )\n",
        "        self.identity_mapping = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1,\n",
        "                                                    stride = 1),\n",
        "                               )\n",
        "        self.down_dimension = nn.Sequential(nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=2,\n",
        "                                                    stride = stride, padding = 0),\n",
        "                               )                  \n",
        "        self.RelU = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = self.residual_pass(x)\n",
        "        x = self.identity_mapping(x) \n",
        "        x += residual\n",
        "        x =  self.RelU(x)\n",
        "        x = self.down_dimension(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yer5PtUiDDuj"
      },
      "outputs": [],
      "source": [
        "class AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AE, self).__init__()\n",
        "        self.fc= nn.Linear(128*3*3, 1024)\n",
        "        \n",
        "        self.encoder = nn.Sequential(\n",
        "            ResNetBlock(1, 16),\n",
        "            ResNetBlock(16, 32),\n",
        "            ResNetBlock(32, 64),\n",
        "            ResNetBlock(64, 128),\n",
        "            ResNetBlock(128, 128),\n",
        "            ResNetBlock(128, 128),\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(1024, 256,  kernel_size=2, stride=2, output_padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128,  kernel_size=3, stride=2, output_padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 128,  kernel_size=3, stride=2, output_padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64,  kernel_size=3, stride=2, output_padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32,  kernel_size=3, stride=2, output_padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16,  kernel_size=3, stride=2, output_padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1,  kernel_size=4, stride=2, output_padding=0),\n",
        "\n",
        "            # nn.ConvTranspose2d(512, 256, kernel_size=1),\n",
        "            # decoder_block(256, 128, scale=1),\n",
        "            # decoder_block(128, 64, scale=1),\n",
        "            # decoder_block(64, 32, scale=5),\n",
        "            # decoder_block(32, 1, scale=5, use_relu=False),\n",
        "        )\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        # print(x.shape)\n",
        "        x = self.fc(x.view(-1,128*3*3))\n",
        "        x = x.unsqueeze(2)\n",
        "        x = x.unsqueeze(3)\n",
        "        # print(x.shape)\n",
        "        x = self.decoder(x) \n",
        "        # print(x.shape) \n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "def countParameters(model):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KUoXySiZD0f",
        "outputId": "eff15d70-1511-4f26-d5e5-fb630c257aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3915473 1146208 1588593\n",
            "torch.Size([32, 1, 192, 192]) tensor(0.8784, device='cuda:0') tensor(0., device='cuda:0')\n",
            "torch.Size([32, 1, 192, 192]) tensor(0.5335, device='cuda:0', grad_fn=<MaxBackward1>) tensor(0.5047, device='cuda:0', grad_fn=<MinBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# model\n",
        "model = AE()\n",
        "print(countParameters(model), countParameters(model.encoder), countParameters(model.decoder))\n",
        "model = model.cuda()\n",
        "\n",
        "#test run\n",
        "input = train_data[:32].unsqueeze(1)\n",
        "input = input / 255\n",
        "input = input.cuda()\n",
        "print(input.shape, input.max(), input.min())\n",
        "output = model(input) \n",
        "print(output.shape, output.max(), output.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "No7z_1qR4izt",
        "outputId": "0c568ec4-6a29-46b9-9e90-c143d5c503ef"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "batch_size = 32\n",
        "num_epochs = 1000\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(list(model.parameters()), lr=0.001)\n",
        "\n",
        "# learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.99)\n",
        "\n",
        "# criterion\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# statistics\n",
        "losses_train = []\n",
        "losses_test = []\n",
        "\n",
        "# for num_epochs\n",
        "for epoch in range(num_epochs):\n",
        "  \n",
        "    # train mode\n",
        "    model.train()\n",
        "    \n",
        "    # random mini-batches\n",
        "    batch_train = torch.randperm(train_data.shape[0])\n",
        "    batch_train = batch_train[(batch_train.numel() % batch_size):]\n",
        "    batch_train = batch_train.view(-1, batch_size)\n",
        "    \n",
        "    # statistics\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    # for each mini-batch\n",
        "    for i in range(batch_train.size(0)):\n",
        "        \n",
        "        # mini-batch\n",
        "        input = train_data[batch_train[i], :].unsqueeze(1)\n",
        "        input = input/255\n",
        "        input = input.cuda()\n",
        "\n",
        "        label = train_label[batch_train[i], :].unsqueeze(1)\n",
        "        label = label/255\n",
        "        label = label.cuda()\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        output = model(input)\n",
        "        # print(output.max(), output.min(), input.max(), input.min())\n",
        "        # print(output.shape, input.shape)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # statistics\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    running_loss /= batch_train.size(0)\n",
        "    \n",
        "    losses_train.append(running_loss)\n",
        "    \n",
        "    # update learning rate\n",
        "    lr_scheduler.step()\n",
        "    \n",
        "    # output\n",
        "    print('Epoch {} (train) -- loss: {:.8f}'.format(epoch, running_loss))\n",
        "    \n",
        "    # validate\n",
        "    with torch.no_grad():\n",
        "      \n",
        "        # eval mode\n",
        "        model.eval()\n",
        "\n",
        "        # random mini-batches\n",
        "        batch_valid = torch.randperm(test_data.shape[0])\n",
        "        batch_valid = batch_valid[(batch_valid.numel() % batch_size):]\n",
        "        batch_valid = batch_valid.view(-1, batch_size)\n",
        "\n",
        "        # statistics\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        # for each mini-batch\n",
        "        for i in range(batch_valid.size(0)):\n",
        "\n",
        "            # mini-batch\n",
        "            input = test_data[batch_valid[i], :].unsqueeze(1)\n",
        "            input = input/255\n",
        "            input = input.cuda()\n",
        "\n",
        "            label = test_label[batch_valid[i], :].unsqueeze(1)\n",
        "            label = label/255\n",
        "            label = label.cuda()\n",
        "\n",
        "            # forward\n",
        "            output = model(input)\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        running_loss /= batch_valid.size(0)\n",
        "\n",
        "        losses_test.append(running_loss)\n",
        "\n",
        "        # output\n",
        "        print('Epoch {} (test) -- loss: {:.8f}'.format(epoch, running_loss))\n",
        "        input = input.squeeze(1).squeeze(1)[0].cpu().detach()*255\n",
        "        # label = label.squeeze(1).squeeze(1)[0].cpu().detach()*255\n",
        "        output = output.squeeze(1).squeeze(1)[0].cpu().detach()*255\n",
        "        cv2_imshow(np.array(input,dtype=np.uint8))\n",
        "        # cv2_imshow(np.array(label,dtype=np.uint8))\n",
        "        cv2_imshow(np.array(output,dtype=np.uint8))\n",
        "        \n",
        "    # plt.close()\n",
        "    # plt.subplot(1,2,1)\n",
        "    # plt.plot(losses_train)\n",
        "    # plt.title(\"traning loss\")\n",
        "    # plt.subplot(1,2,2)\n",
        "    # plt.plot(losses_test)\n",
        "    # plt.title(\"test loss\")\n",
        "    # plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
