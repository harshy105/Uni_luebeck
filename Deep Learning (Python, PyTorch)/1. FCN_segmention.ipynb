{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "MkCyEwQy4UHB",
      "metadata": {
        "id": "MkCyEwQy4UHB"
      },
      "source": [
        "# Medical Deep Learning\n",
        "\n",
        "---\n",
        "\n",
        "In this sheet we will set up the foundations to load the data, create a fully-convolutional network (FCN) for image segmentation, and train it to solve multi-class segmentation problems for medical applications. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fs1SnVCBv0Nq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs1SnVCBv0Nq",
        "outputId": "d3478018-6fac-4d96-9d56-cd4de84ab86b"
      },
      "outputs": [],
      "source": [
        "!wget https://cloud.imi.uni-luebeck.de/s/zFyEiJKNtaKKzS8/download -O AbdomenPreAffine.zip\n",
        "!unzip -o AbdomenPreAffine.zip > /dev/null  # disable the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BXdIbHDpDu_J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXdIbHDpDu_J",
        "outputId": "9c5cf14a-03c6-4cae-f1cf-3d0a8cee4036"
      },
      "outputs": [],
      "source": [
        "!wget https://cloud.imi.uni-luebeck.de/s/Fd63J7xMLmkMEzb/download -O mdl_exercise1_utils.py\n",
        "\n",
        "from mdl_exercise1_utils import init_weights, Plotter, ZeroPad, Crop, Scale, ToCuda"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IkOPbzDvbtwO",
      "metadata": {
        "id": "IkOPbzDvbtwO"
      },
      "source": [
        "Let's get started with the code and run all the imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fresh-details",
      "metadata": {
        "id": "fresh-details"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import Tensor\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import nibabel as nib\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "from typing import Callable, Any, Optional, List\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_Tn1AiXHIo_6",
      "metadata": {
        "id": "_Tn1AiXHIo_6"
      },
      "source": [
        "The **training data** is loaded from the filesystem as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YOUzC-WCMIlj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOUzC-WCMIlj",
        "outputId": "d7564a58-2ccd-4aae-869c-4a81af8284da"
      },
      "outputs": [],
      "source": [
        "imgs2 = torch.randn(20,1,128,128,128).cuda()#/500\n",
        "segs2 = torch.randint(1,(20,128,128,128)).long().cuda()\n",
        "list_train = torch.Tensor([2,3,4,5,7,8,10,21,22,24,25,27,28,30,31,33,34,36,37,39,40])\n",
        "list_test = torch.Tensor([1,4,7,10,23,26,29,32,35,38]).long()\n",
        "for i in range(20):\n",
        "    img = nib.load('/content/AbdomenPreAffine/Training/img/img00'+str(int(list_train[i])).zfill(2)+'.nii.gz').get_fdata()\n",
        "    imgs2[i:i+1] = F.interpolate(torch.from_numpy(img).cuda().unsqueeze(0).unsqueeze(1).float(),size=(128,128,128),mode='trilinear').cuda()/500\n",
        "    seg = nib.load('/content/AbdomenPreAffine/Training/label/label00'+str(int(list_train[i])).zfill(2)+'.nii.gz').get_fdata()\n",
        "    segs2[i] = F.interpolate(torch.from_numpy(seg).cuda().unsqueeze(0).unsqueeze(1).float(),size=(128,128,128),mode='nearest').squeeze().cuda().long()\n",
        "    print('Loaded', i+1, '/',20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7BpfYYqgIyYD",
      "metadata": {
        "id": "7BpfYYqgIyYD"
      },
      "source": [
        "The **validation data** is loaded from the filesystem as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aRSfkzznI9Mc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRSfkzznI9Mc",
        "outputId": "fc773239-3523-4e52-aadb-e444c3f7e2ad"
      },
      "outputs": [],
      "source": [
        "imgs_val = torch.randn(10,1,128,128,128).cuda()#/500\n",
        "segs_val = torch.randint(2,(10,128,128,128)).long().cuda()\n",
        "for i in range(10):\n",
        "    img = nib.load('/content/AbdomenPreAffine/Training/img/img00'+str(int(list_test[i])).zfill(2)+'.nii.gz').get_fdata()\n",
        "    imgs_val[i:i+1] = F.interpolate(torch.from_numpy(img).unsqueeze(0).unsqueeze(1).float(),size=(128,128,128),mode='trilinear').cuda()/500\n",
        "    seg = nib.load('/content/AbdomenPreAffine/Training/label/label00'+str(int(list_test[i])).zfill(2)+'.nii.gz').get_fdata()\n",
        "    segs_val[i] = F.interpolate(torch.from_numpy(seg).unsqueeze(0).unsqueeze(1).float(),size=(128,128,128),mode='nearest').squeeze().cuda().long()\n",
        "    print('Loaded', i+1, '/',10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n3A9BY2R2v1f",
      "metadata": {
        "id": "n3A9BY2R2v1f"
      },
      "outputs": [],
      "source": [
        "segs2 = segs2.unsqueeze(1)\n",
        "segs_val = segs_val.unsqueeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "crO5MzCTJ0D_",
      "metadata": {
        "id": "crO5MzCTJ0D_"
      },
      "source": [
        "All data is being loaded now, thus we can start with the implementation of the afine augementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JRs0tKd1xJ7H",
      "metadata": {
        "id": "JRs0tKd1xJ7H"
      },
      "outputs": [],
      "source": [
        "class AugmentAffine(object):\n",
        "  def __init__(self, strength=0.05):\n",
        "    self.strength = strength\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    B, C, D, H, W = sample# access image data\n",
        "    \n",
        "    offsets = 0.001 # random offsets\n",
        "    \n",
        "    affine_matrix = (torch.eye(3,4).unsqueeze(0) + self.strength * offsets)  \n",
        "    affine_matrix.cuda()\n",
        "\n",
        "    meshgrid = F.affine_grid(affine_matrix,sample.size())# resampling grid\n",
        "\n",
        "    sample['image'] = F.grid_sample(sample['image'],affine_matrix)# resample image\n",
        "    sample['label'] = F.grid_sample(sample['label'],affine_matrix)# resample label\n",
        "    \n",
        "    return sample\n",
        "augmentation_training = [AugmentAffine(0.1), ToCuda()]\n",
        "augmentation_validate = [ToCuda()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p9LFJifZqiM4",
      "metadata": {
        "id": "p9LFJifZqiM4"
      },
      "source": [
        "\n",
        "Define a simplified Fully-Convolutional Network (FCN) architecture\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZtuaD78Yda2y",
      "metadata": {
        "id": "ZtuaD78Yda2y"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, unet=True):\n",
        "    super().__init__()\n",
        "    #input[20,1,128,128,128]\n",
        "    self.block0 = nn.Sequential(nn.BatchNorm3d(1),\n",
        "                                nn.Conv3d(1, 16, 3, padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.BatchNorm3d(16),\n",
        "                                nn.Conv3d(16, 16, 3, padding=1),\n",
        "                                nn.ReLU()\n",
        "                               )\n",
        "                    \n",
        "    self.mp01 = nn.MaxPool3d(2, 2)\n",
        "\n",
        "    # add two more blocks and two more 2x2 poolings\n",
        "    self.block1 = nn.Sequential(nn.BatchNorm3d(16),\n",
        "                                nn.Conv3d(16,32,3,padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.BatchNorm3d(32),\n",
        "                                nn.Conv3d(32,32,3,padding=1),\n",
        "                                nn.ReLU()\n",
        "                                )\n",
        "    self.mp02 = nn.MaxPool3d(2,2)\n",
        "\n",
        "    self.block2 = nn.Sequential(nn.BatchNorm3d(32),\n",
        "                                nn.Conv3d(32,64,3,padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.BatchNorm3d(64),\n",
        "                                nn.Conv3d(64,64,3,padding=1),\n",
        "                                nn.ReLU()\n",
        "                                )\n",
        "    self.mp03 = nn.MaxPool3d(2,2)\n",
        " #output[20,64,16,16,16]\n",
        "  \n",
        "    # add final classifiation block (1x1 convs instead of linear layers)\n",
        "    self.upsample = nn.Sequential(nn.Conv3d(64,32,1),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Conv3d(32,1,1),\n",
        "                                  nn.Sigmoid(),\n",
        "                                  )\n",
        "    \n",
        "    #output [20,1,128,128,128]\n",
        "    \n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    output0 = self.block0(inputs)\n",
        "    output1 = self.mp01(output0)\n",
        "    output2 = self.block1(output1)\n",
        "    output3 = self.mp02(output2)\n",
        "    output4 = self.block2(output3)\n",
        "    output5 = self.mp03(output4)\n",
        "    \n",
        "    # Add forwards\n",
        "    \n",
        "    return F.interpolate(self.upsample(output5), scale_factor= 8)  # Add both values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5dNlP1_ZIac",
      "metadata": {
        "id": "a5dNlP1_ZIac"
      },
      "source": [
        "Let's set up the experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eEdeRNwSqbwq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ae9b2707cb654b2a8176a00a51b137ac",
            "f8633da0d2954672a80e721c9ff9376a",
            "be09547fc3f7469ba758da28a0ca3da2",
            "40b8ea2b41ea414c9f99eb481ac44c9c",
            "3ad85b3110044707851fc7ac2a7bdfd2",
            "0120a85a5b4d445cbd065686ea930fc3",
            "7786a4d41a114e178b4d6a51a4f79a56",
            "ed2ddfac74794b16821cf26fa21aa308"
          ]
        },
        "id": "eEdeRNwSqbwq",
        "outputId": "b65d81ab-1dae-4229-b69b-f52a2c380e18"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters\n",
        "n_epochs = 31\n",
        "\n",
        "# Visualise progress every 5th epoch\n",
        "every_epoch = 5\n",
        "bin_thresh = 0.3\n",
        "plotter = Plotter(n_epochs//every_epoch, z_slice=23, bin_thresh=bin_thresh)\n",
        "\n",
        "# Network initialisation\n",
        "net = Net(False).cuda()\n",
        "net.apply(init_weights)\n",
        "\n",
        "# Set up optimisation for training process\n",
        "criterion = nn.BCELoss().cuda()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
        "\n",
        "# Save loss of each epoch\n",
        "losses_training = []\n",
        "losses_validate = []\n",
        "\n",
        "# Show current progress and loss\n",
        "progress = tqdm(range(n_epochs), desc='progress')\n",
        "\n",
        "# making dict\n",
        "\n",
        "data = {\n",
        "  \"image\": imgs2,\n",
        "  \"label\": segs2,\n",
        "}\n",
        "\n",
        "data_val = {\n",
        "  \"image\": imgs_val,\n",
        "  \"label\": segs_val,\n",
        "}\n",
        "\n",
        "######################\n",
        "# MAIN TRAINING LOOP #\n",
        "######################\n",
        "\n",
        "for epoch in progress:\n",
        "  \n",
        "  ########################################\n",
        "  #               TRAINING               #\n",
        "  ########################################\n",
        "\n",
        "  sum_loss = 0\n",
        "  \n",
        "  # Parameters must be trainable\n",
        "  net.train()\n",
        "  with torch.set_grad_enabled(True):  # add bool value\n",
        "    \n",
        "    # loop to process all training samples (packed into batches)\n",
        "    \n",
        "    for i in range(20):# draw training sample\n",
        "      \n",
        "      result = net.forward(data['image'][i].unsqueeze(0))# forward run with sample\n",
        "      loss =  criterion(result, data['label'][i].unsqueeze(0).float())# compute BCE loss\n",
        "\n",
        "      # backward step to compute gradients for optimising the model weights\n",
        "\n",
        "      sum_loss += loss.item()\n",
        "  \n",
        "  losses_training.append(sum_loss / len(list_train))# add number of training samples)\n",
        "\n",
        "  if epoch % every_epoch == 0:\n",
        "    plotter.add_training_sample(data, result, epoch)\n",
        "  \n",
        "  \n",
        "  ########################################\n",
        "  #              VALIDATION              #\n",
        "  ########################################\n",
        "\n",
        "  sum_loss = 0\n",
        "  \n",
        "  # Parameters must not be trainable\n",
        "  net.eval()\n",
        "  with torch.set_grad_enabled(False):  # add bool value\n",
        "    \n",
        "    # loop to process all validation samples (packed into batches)\n",
        "    for i in range(10):# draw validation sample\n",
        "      \n",
        "      # copy and paste the lines required from the training step\n",
        "      result = net.forward(data_val['image'][i].unsqueeze(0))# forward run with sample\n",
        "\n",
        "      loss =  criterion(result,data_val['label'][i].unsqueeze(0).float())# compute BCE loss\n",
        "      \n",
        "      sum_loss += loss.item()\n",
        "  \n",
        "  losses_validate.append(sum_loss / len(list_test))# add number of validation samples))\n",
        "  \n",
        "  if epoch % every_epoch == 0:\n",
        "    plotter.add_validation_sample(data_val, result, epoch)\n",
        "  \n",
        "  progress.set_postfix(loss=losses_training[-1], val_loss=losses_validate[-1])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0120a85a5b4d445cbd065686ea930fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ad85b3110044707851fc7ac2a7bdfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "40b8ea2b41ea414c9f99eb481ac44c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed2ddfac74794b16821cf26fa21aa308",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7786a4d41a114e178b4d6a51a4f79a56",
            "value": " 31/31 [01:15&lt;00:00,  2.42s/it, loss=0.659, val_loss=0.668]"
          }
        },
        "7786a4d41a114e178b4d6a51a4f79a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae9b2707cb654b2a8176a00a51b137ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be09547fc3f7469ba758da28a0ca3da2",
              "IPY_MODEL_40b8ea2b41ea414c9f99eb481ac44c9c"
            ],
            "layout": "IPY_MODEL_f8633da0d2954672a80e721c9ff9376a"
          }
        },
        "be09547fc3f7469ba758da28a0ca3da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "progress: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0120a85a5b4d445cbd065686ea930fc3",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ad85b3110044707851fc7ac2a7bdfd2",
            "value": 31
          }
        },
        "ed2ddfac74794b16821cf26fa21aa308": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8633da0d2954672a80e721c9ff9376a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
